# 26. Docker 로그 관리

> **학습 목표**: Docker 컨테이너에서 발생하는 다양한 로그를 효과적으로 수집, 저장, 분석할 수 있으며, ELK Stack을 활용한 통합 로그 관리 시스템을 구축할 수 있습니다.

**⏱️ 예상 학습 시간**: 3-4시간
**난이도**: ⭐⭐⭐⭐☆ (4개/5개)

---

## 목차
1. [Docker 로그의 기본 이해](#docker-로그의-기본-이해)
2. [로그 드라이버 설정](#로그-드라이버-설정)
3. [ELK Stack으로 로그 수집하기](#elk-stack으로-로그-수집하기)
4. [Kibana에서 로그 검색과 시각화](#kibana에서-로그-검색과-시각화)
5. [로그 관리 모범 사례](#로그-관리-모범-사례)
6. [LK-Trade 프로젝트에 적용하기](#lk-trade-프로젝트에-적용하기)
7. [트러블슈팅](#트러블슈팅)

---

## 💡 왜 Docker 로그 관리가 필요한가?

### 실무 배경

**"어제 밤 10시에 서비스 오류 났었는데, 왜 그런지 알 수 있나요?"**

#### ❌ 로그 관리가 없으면 발생하는 문제

```
문제 1: 사후 원인 파악 불가능
- 증상: "어제 오류가 났었어요"
- 대응: "로그를 못 찾겠어요..."
- 영향: 재발 가능성 100%, 신뢰도 하락
- 비용: 장애 대응 시간 평균 4시간, 시간당 수백만원 손실

문제 2: 디스크 공간 무한 증가
- 증상: 로그 파일이 100GB 넘음
- 대응: "서버 디스크 꽉 참" → 서비스 중단
- 영향: 로그 때문에 정작 서비스가 죽음
- 비용: 긴급 디스크 증설 비용 (월 50만원+)

문제 3: 여러 컨테이너 로그 추적 불가
- 증상: "user-service에서 trade-service 호출했는데 어디서 오류?"
- 대응: 5개 컨테이너 로그 일일이 확인
- 영향: 분산 시스템 디버깅 불가능
- 비용: 개발자 1명 하루 허비 (약 30만원)
```

#### ✅ 체계적 로그 관리 시스템을 구축하면

```
해결책 1: 통합 로그 검색 (ELK Stack)
- 방법: Elasticsearch에 모든 로그 집중
- 효과: Kibana에서 5초 내 원하는 로그 검색
- 절감: 로그 검색 시간 98% 단축 (1시간 → 5초)

해결책 2: 자동 로그 로테이션
- 방법: max-size, max-file 설정
- 효과: 디스크 사용량 제한 (최대 30MB/컨테이너)
- 절감: 디스크 비용 80% 절감

해결책 3: Correlation ID로 분산 추적
- 방법: 모든 요청에 고유 ID 부여
- 효과: 여러 서비스 걸친 요청 흐름 완벽 추적
- 절감: 분산 시스템 디버깅 시간 90% 단축
```

### 수치로 보는 효과

| 지표 | Before | After | 개선율 |
|------|--------|-------|--------|
| 로그 검색 시간 | 1시간 | 5초 | **99.9%↓** |
| 디스크 사용량 | 200GB | 10GB | **95%↓** |
| 장애 원인 파악 시간 | 4시간 | 15분 | **94%↓** |
| 분산 추적 가능 비율 | 0% | 100% | **무한대↑** |
| 월 로그 인프라 비용 | 100만원 | 30만원 | **70%↓** |

---

## 🔍 실생활 비유로 이해하기

### 비유 1: 자동차 블랙박스 시스템

```
자동차 블랙박스                      Docker 로그 관리
================                      ==================
📹 전방 카메라 (항상 녹화)       →    stdout/stderr (항상 수집)
📹 후방 카메라 (추가 정보)       →    애플리케이션 로그 파일
💾 SD 카드 저장 (용량 제한)      →    로그 드라이버 (max-size)
🔄 용량 꽉 차면 덮어쓰기         →    로그 로테이션
📂 사고 시 영상 분석             →    Kibana로 로그 분석
🚨 충격 감지 시 자동 저장        →    에러 레벨 로그 자동 수집
☁️ 클라우드 업로드 (안전 보관)   →    Elasticsearch 저장소

블랙박스가 없으면 사고 원인을 알 수 없듯이,
로그 관리가 없으면 시스템 장애 원인을 찾을 수 없습니다.

사고 발생:
- 블랙박스 있음: 영상 확인 → 즉시 원인 파악 → 보험 처리
- 블랙박스 없음: "기억 안 나요..." → 증거 없음 → 손실 발생

시스템 장애:
- 로그 있음: Kibana 검색 → 5분 내 원인 파악 → 빠른 복구
- 로그 없음: "추측만..." → 재현 시도 → 시간 낭비
```

### 비유 2: CCTV 관제 센터

```
대형 빌딩 CCTV 관제 시스템        마이크로서비스 로그 관리
==========================        =======================

[문제 상황]
도둑이 물건을 훔쳐감!              API 요청이 실패함!

┌─────────────────────────────────────────────────┐
│ 각 층마다 독립된 CCTV            각 서비스마다 독립된 로그 │
├─────────────────────────────────────────────────┤
│ 1층: "수상한 사람 없음"          user-service: "정상"   │
│ 2층: "10:23분 수상한 사람 발견"  trade-service: "오류!"  │
│ 3층: "확인 못함"                 account-service: "정상" │
│ 4층: "확인 못함"                 strategy-service: "???" │
└─────────────────────────────────────────────────┘

❌ 관제 센터 없이 (통합 로그 관리 없이):
- 경비원이 4개 층 CCTV 일일이 확인 (4시간 소요)
- 2층 영상 찾았지만 1층에서 진입한 걸 못 찾음
- 전체 동선 파악 불가

✅ 관제 센터 있음 (ELK Stack):
┌─────────────────────────────────────────────────┐
│         🖥️ 통합 관제 센터 (Kibana)               │
├─────────────────────────────────────────────────┤
│ 검색: "10:20~10:30 사이 수상한 활동"             │
│                                                  │
│ 결과 (자동으로 모든 층 영상 통합):                │
│ 10:20 - 1층 정문 진입                            │
│ 10:23 - 2층 사무실 침입                          │
│ 10:25 - 3층 금고 시도 (실패)                     │
│ 10:27 - 1층 후문 탈출                            │
└─────────────────────────────────────────────────┘

Docker 로그도 마찬가지:
- Correlation ID = 범인 얼굴 인식 (동일 요청 추적)
- Elasticsearch = 통합 영상 데이터베이스
- Kibana = 관제 센터 모니터
- 5분 만에 전체 흐름 파악!
```

### 비유 3: 도서관 사서의 책 정리 시스템

```
도서관 책 관리                     Docker 로그 관리
==============                     ================

📚 문제: 책이 무한정 쌓임           로그가 무한정 쌓임

❌ 정리 안 하면:
┌─────────────────────────────────────┐
│ 책이 바닥에 산더미로 쌓임           │
│ → 찾고 싶은 책 못 찾음              │
│ → 도서관 공간 부족                  │
│ → 도서관 문 닫아야 함               │
└─────────────────────────────────────┘

✅ 체계적 관리 (로그 로테이션):

1. 분류 (Log Level)
   - 신간 (ERROR): 별도 책장에 보관
   - 베스트셀러 (WARN): 쉽게 접근 가능한 곳
   - 일반 도서 (INFO): 일반 서가
   - 참고 자료 (DEBUG): 창고

2. 보관 기간 (Retention)
   - 최근 1주일: 메인 서가 (빠른 접근)
   - 1주~1개월: 보조 서가
   - 1개월~1년: 창고
   - 1년 이상: 폐기 (또는 아카이브)

3. 인덱싱 (Elasticsearch)
   - 모든 책에 바코드 부착
   - 컴퓨터로 5초 내 검색
   - 키워드만 입력하면 즉시 찾기

Docker 로그:
- json-file driver: 자동 분류
- max-size, max-file: 보관 기간 제한
- Elasticsearch: 검색 인덱스
- Kibana: 사서 검색 시스템

"30일 전 ERROR 로그 찾기"
→ Kibana에 검색: level:ERROR AND date:30daysAgo
→ 1초 만에 결과 확인!
```

---

## Docker 로그의 기본 이해

### 1. Docker 로그 수집 메커니즘

```
Container 내부                         Docker Daemon                    로그 저장소
==============                         ==============                   ===========

Application
    |
    | stdout (System.out)
    ├──────────────────────>
    |                                  Log Driver
    | stderr (System.err)              (json-file,
    └──────────────────────>           syslog, etc.)
                                           |
                                           | 포맷 변환
                                           | 버퍼링
                                           ↓
                                       로그 파일
                                       (/var/lib/docker/containers/
                                        <container-id>/<container-id>-json.log)
                                           |
                                           | (옵션) 원격 전송
                                           ↓
                                       Elasticsearch
                                       Fluentd
                                       Splunk
                                       등등...
```

### 2. 로그 드라이버 종류

Docker는 다양한 로그 드라이버를 지원합니다:

| 드라이버 | 설명 | 사용 시나리오 |
|---------|------|-------------|
| **json-file** | JSON 형식 로컬 파일 (기본값) | 개발 환경, 소규모 운영 |
| **journald** | systemd 저널에 전송 | Linux systemd 환경 |
| **syslog** | Syslog 서버로 전송 | 기존 syslog 인프라 활용 |
| **fluentd** | Fluentd로 전송 | 대규모 로그 수집 |
| **gelf** | Graylog로 전송 | Graylog 사용 시 |
| **awslogs** | AWS CloudWatch로 전송 | AWS 환경 |
| **gcplogs** | Google Cloud Logging | GCP 환경 |
| **splunk** | Splunk로 전송 | Splunk 사용 기업 |
| **none** | 로그 수집 안 함 | 로그 불필요한 컨테이너 |

---

## 로그 드라이버 설정

### 1. json-file 드라이버 (기본값)

가장 많이 사용되는 드라이버입니다.

#### docker-compose.yml 설정

```yaml
# docker-compose.yml
version: '3.8'

services:
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "json-file"
      options:
        max-size: "10m"        # 로그 파일 최대 크기
        max-file: "3"          # 로그 파일 최대 개수
        labels: "service=user" # 메타데이터 추가
        env: "ENVIRONMENT"     # 환경변수 포함
```

#### 동작 방식

```
로그 파일 로테이션
==================

user-service-json.log          (10MB 도달)
    ↓
user-service-json.log.1        (이름 변경)
user-service-json.log          (새 파일 생성)
    ↓
user-service-json.log.2        (이름 변경)
user-service-json.log.1        (이름 변경)
user-service-json.log          (새 파일 생성)
    ↓
user-service-json.log.2        (삭제, max-file=3 초과)
user-service-json.log.1        (이름 변경)
user-service-json.log          (새 파일 생성)
```

#### 로그 파일 위치

```bash
# 컨테이너 로그 파일 위치 확인
docker inspect --format='{{.LogPath}}' user-service

# 출력 예시:
# /var/lib/docker/containers/abc123.../abc123...-json.log

# 로그 파일 직접 보기 (Linux/Mac)
sudo tail -f /var/lib/docker/containers/abc123.../abc123...-json.log

# 로그 파일 내용 예시
{"log":"2025-09-30 10:15:32.123 INFO  [main] Application started\n","stream":"stdout","time":"2025-09-30T01:15:32.123456789Z"}
{"log":"2025-09-30 10:15:33.456 ERROR [http-nio-8080-exec-1] Connection refused\n","stream":"stderr","time":"2025-09-30T01:15:33.456789012Z"}
```

### 2. syslog 드라이버

기존 syslog 인프라가 있을 때 유용합니다.

```yaml
# docker-compose.yml
services:
  trade-service:
    image: lk-trade/trade-service:latest
    logging:
      driver: "syslog"
      options:
        syslog-address: "tcp://syslog-server:514"
        syslog-facility: "daemon"
        tag: "{{.Name}}/{{.ID}}"
```

### 3. fluentd 드라이버 (권장 - 대규모 환경)

Fluentd는 강력한 로그 수집기입니다.

```yaml
# docker-compose.yml
services:
  # Fluentd 컨테이너
  fluentd:
    image: fluent/fluentd:v1.16-1
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    volumes:
      - ./fluentd/conf:/fluentd/etc
      - ./fluentd/logs:/fluentd/log
    networks:
      - lk-trade-network

  # 애플리케이션 컨테이너
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "localhost:24224"
        tag: "lk-trade.user-service"
        fluentd-async: "true"      # 비동기 전송
        fluentd-buffer-limit: "1m" # 버퍼 크기
    depends_on:
      - fluentd
    networks:
      - lk-trade-network
```

#### Fluentd 설정 파일

```ruby
# fluentd/conf/fluent.conf

# 입력: Docker 컨테이너로부터 로그 수신
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# 필터: JSON 파싱
<filter lk-trade.**>
  @type parser
  key_name log
  <parse>
    @type json
  </parse>
</filter>

# 필터: 로그 레벨 추출
<filter lk-trade.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    level ${record["level"] || "INFO"}
  </record>
</filter>

# 출력 1: Elasticsearch로 전송
<match lk-trade.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix lk-trade
  <buffer>
    @type file
    path /fluentd/log/buffer
    flush_interval 10s
  </buffer>
</match>

# 출력 2: 파일로도 백업 저장
<match lk-trade.**>
  @type copy
  <store>
    @type file
    path /fluentd/log/${tag}/%Y%m%d
    <buffer tag,time>
      timekey 1d
      timekey_wait 10m
    </buffer>
  </store>
</match>
```

---

## ELK Stack으로 로그 수집하기

ELK = **E**lasticsearch + **L**ogstash + **K**ibana

```
전체 아키텍처
=============

Docker Containers                     Filebeat                  Logstash                Elasticsearch         Kibana
=================                     ========                  ========                =============         ======

[user-service]
   stdout/stderr  ────┐
                      │
[trade-service]       ├───> Filebeat ───> Logstash ───> Elasticsearch ───> Kibana
   stdout/stderr  ────┤      (수집)        (가공)         (저장)           (시각화)
                      │
[account-service]     │
   stdout/stderr  ────┘

각 역할:
- Filebeat: 로그 파일을 실시간으로 읽어서 Logstash로 전송
- Logstash: 로그를 파싱하고 필터링하여 구조화
- Elasticsearch: 로그를 색인하고 저장
- Kibana: 로그를 검색하고 시각화
```

### 1. ELK Stack docker-compose 구성

```yaml
# docker-compose.elk.yml
version: '3.8'

services:
  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"  # JVM 힙 크기
      - xpack.security.enabled=false   # 개발 환경에서는 보안 비활성화
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - elk-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"  # Filebeat 입력
      - "9600:9600"  # Logstash API
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
    networks:
      - elk-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  # Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - elk-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  # Filebeat
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: filebeat
    user: root  # Docker 소켓 접근 권한 필요
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data:/usr/share/filebeat/data
    command: filebeat -e -strict.perms=false
    networks:
      - elk-network
    depends_on:
      - logstash

volumes:
  elasticsearch-data:
    driver: local
  filebeat-data:
    driver: local

networks:
  elk-network:
    driver: bridge
```

### 2. Filebeat 설정

Filebeat는 Docker 컨테이너의 로그를 수집합니다.

```yaml
# filebeat/filebeat.yml
filebeat.inputs:
  # Docker 컨테이너 로그 자동 수집
  - type: container
    enabled: true
    paths:
      - '/var/lib/docker/containers/*/*.log'

    # JSON 로그 파싱
    json.keys_under_root: true
    json.add_error_key: true
    json.message_key: log

    # Docker 메타데이터 추가
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"

      - decode_json_fields:
          fields: ["message"]
          target: ""
          overwrite_keys: true

      # 불필요한 필드 제거
      - drop_fields:
          fields: ["agent", "ecs", "host", "input"]

# Logstash로 출력
output.logstash:
  hosts: ["logstash:5044"]

# 로그 레벨 설정
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

### 3. Logstash 파이프라인 설정

Logstash는 로그를 파싱하고 가공합니다.

```ruby
# logstash/pipeline/logstash.conf

input {
  beats {
    port => 5044
  }
}

filter {
  # Docker 컨테이너 로그 필터
  if [container] {
    # 컨테이너 이름에서 서비스 이름 추출
    grok {
      match => {
        "[container][name]" => "^/?(%{DATA:service_name})[-_]"
      }
    }

    # Spring Boot 로그 파싱
    if [service_name] =~ /user|trade|account|strategy/ {
      grok {
        match => {
          "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} +\[%{DATA:thread}\] %{DATA:logger} : %{GREEDYDATA:log_message}"
        }
      }

      # 타임스탬프 파싱
      date {
        match => ["timestamp", "ISO8601"]
        target => "@timestamp"
      }
    }

    # 에러 로그 태그 추가
    if [log_level] == "ERROR" or [log_level] == "FATAL" {
      mutate {
        add_tag => ["error"]
      }
    }

    # 성능 관련 로그 태그
    if [message] =~ /took \d+ms/ or [message] =~ /response time/ {
      grok {
        match => {
          "message" => "took %{NUMBER:response_time_ms:int}ms"
        }
      }
      mutate {
        add_tag => ["performance"]
      }
    }
  }

  # 불필요한 필드 제거
  mutate {
    remove_field => ["agent", "ecs", "input", "host"]
  }
}

output {
  # Elasticsearch로 출력
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "lk-trade-%{+YYYY.MM.dd}"

    # 템플릿 설정
    template_name => "lk-trade"
    template_pattern => "lk-trade-*"
  }

  # 디버깅용 stdout (개발 환경에서만)
  stdout {
    codec => rubydebug
  }
}
```

### 4. 애플리케이션의 구조화된 로그 출력

Spring Boot 애플리케이션에서 JSON 형식으로 로그를 출력하면 파싱이 쉬워집니다.

#### Logback 설정 (JSON 로그)

```xml
<!-- src/main/resources/logback-spring.xml -->
<configuration>
    <springProperty scope="context" name="serviceName" source="spring.application.name"/>

    <!-- JSON Encoder 의존성 필요: net.logstash.logback:logstash-logback-encoder -->
    <appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>{"service":"${serviceName}"}</customFields>
            <fieldNames>
                <timestamp>timestamp</timestamp>
                <message>message</message>
                <logger>logger</logger>
                <thread>thread</thread>
                <level>level</level>
                <stackTrace>stack_trace</stackTrace>
            </fieldNames>
        </encoder>
    </appender>

    <root level="INFO">
        <appender-ref ref="JSON"/>
    </root>
</configuration>
```

#### Gradle 의존성 추가

```kotlin
// build.gradle.kts
dependencies {
    // JSON 로그 출력
    implementation("net.logstash.logback:logstash-logback-encoder:7.4")
}
```

#### 로그 출력 예시

```kotlin
// UserService.kt
import org.slf4j.LoggerFactory
import org.slf4j.MDC

class UserService {
    private val logger = LoggerFactory.getLogger(UserService::class.java)

    fun createUser(request: CreateUserRequest): User {
        // MDC로 추적 ID 추가 (전체 요청에서 추적 가능)
        MDC.put("userId", request.email)
        MDC.put("requestId", UUID.randomUUID().toString())

        try {
            logger.info("Creating user: {}", request.email)

            val user = userRepository.save(User(email = request.email))

            logger.info("User created successfully: {}", user.id)
            return user

        } catch (e: Exception) {
            logger.error("Failed to create user: {}", request.email, e)
            throw e
        } finally {
            MDC.clear()
        }
    }
}
```

#### JSON 로그 출력 예시

```json
{
  "timestamp": "2025-09-30T10:15:32.123+09:00",
  "level": "INFO",
  "thread": "http-nio-8080-exec-1",
  "logger": "com.lk.trade.user.service.UserService",
  "message": "Creating user: test@example.com",
  "service": "user-service",
  "userId": "test@example.com",
  "requestId": "abc-123-def-456"
}
```

---

## Kibana에서 로그 검색과 시각화

### 1. Kibana 접속 및 Index Pattern 설정

```bash
# Kibana 접속
http://localhost:5601

# 최초 접속 시 Index Pattern 생성
1. Management > Stack Management > Index Patterns
2. "Create index pattern" 클릭
3. Index pattern name: lk-trade-*
4. Time field: @timestamp
5. "Create index pattern" 클릭
```

### 2. 기본 로그 검색

```
Kibana Discover 화면
====================

검색 쿼리 예시:

1. 특정 서비스 로그 검색
   service_name: "user-service"

2. 에러 로그만 검색
   log_level: "ERROR"

3. 특정 사용자 관련 로그
   userId: "test@example.com"

4. 특정 시간대 로그
   @timestamp: [2025-09-30T00:00:00 TO 2025-09-30T23:59:59]

5. 복합 조건 (AND, OR)
   service_name: "trade-service" AND log_level: "ERROR"

6. 응답 시간이 느린 요청
   response_time_ms: >1000

7. 특정 메시지 포함
   message: *"Connection refused"*
```

### 3. 시각화 대시보드 구성

Kibana에서 유용한 시각화:

#### 로그 레벨별 분포 (Pie Chart)

```
Visualization Type: Pie Chart
Metrics: Count
Buckets:
  - Split slices
  - Aggregation: Terms
  - Field: log_level.keyword
  - Size: 10
```

#### 시간대별 에러 발생 추이 (Line Chart)

```
Visualization Type: Line Chart
Metrics: Count
Buckets:
  - X-Axis
  - Aggregation: Date Histogram
  - Field: @timestamp
  - Interval: Auto

Filters: log_level: "ERROR"
```

#### 서비스별 로그 양 (Bar Chart)

```
Visualization Type: Bar Chart (Vertical)
Metrics: Count
Buckets:
  - X-Axis
  - Aggregation: Terms
  - Field: service_name.keyword
  - Order By: metric: Count
  - Order: Descending
  - Size: 10
```

#### 응답 시간 분포 (Histogram)

```
Visualization Type: Histogram
Metrics: Average response_time_ms
Buckets:
  - X-Axis
  - Aggregation: Histogram
  - Field: response_time_ms
  - Interval: 100
```

### 4. 대시보드 구성 예시

```
LK-Trade 로그 모니터링 대시보드
====================================

┌─────────────────────────────────────────────────────────────┐
│  시간 범위: Last 24 hours                  🔄 Auto-refresh  │
└─────────────────────────────────────────────────────────────┘

┌──────────────────┬──────────────────┬──────────────────────┐
│  총 로그 수      │  에러 수         │  평균 응답 시간      │
│  1,234,567       │  42 (0.003%)     │  123ms               │
└──────────────────┴──────────────────┴──────────────────────┘

┌─────────────────────────────┬─────────────────────────────┐
│  시간대별 로그 발생량       │  서비스별 로그 분포         │
│  [Line Chart]               │  [Pie Chart]                │
│                             │  - user-service: 35%        │
│     ╱╲                      │  - trade-service: 28%       │
│    ╱  ╲      ╱╲            │  - account-service: 20%     │
│   ╱    ╲    ╱  ╲           │  - strategy-service: 17%    │
│  ╱      ╲  ╱    ╲          │                             │
└─────────────────────────────┴─────────────────────────────┘

┌─────────────────────────────┬─────────────────────────────┐
│  에러 로그 추이             │  응답 시간 분포             │
│  [Area Chart]               │  [Histogram]                │
│                             │                             │
│      ╱╲                     │      ┃                      │
│     ╱  ╲╱╲                  │      ┃                      │
│    ╱       ╲╱╲              │  ┃   ┃                      │
│   ╱            ╲            │  ┃   ┃  ┃                   │
└─────────────────────────────┴─────────────────────────────┘

┌───────────────────────────────────────────────────────────┐
│  최근 에러 로그 (실시간)                                  │
├───────────────────────────────────────────────────────────┤
│  [10:15:32] user-service | ERROR | Connection refused     │
│  [10:14:28] trade-service | ERROR | Insufficient balance │
│  [10:13:45] account-service | ERROR | API rate limit     │
└───────────────────────────────────────────────────────────┘
```

---

## 로그 관리 모범 사례

### 1. 로그 레벨 전략

```kotlin
// ❌ 나쁜 예
logger.info("User: $user, Password: ${user.password}, Request: $request")
// 문제: 민감 정보 노출, 너무 상세

logger.debug("Step 1")
logger.debug("Step 2")
logger.debug("Step 3")
// 문제: 의미 없는 로그

logger.error("Error occurred")
// 문제: 구체적인 정보 없음


// ✅ 좋은 예
// INFO: 비즈니스 중요 이벤트
logger.info("User registered successfully",
    kv("userId", user.id),
    kv("email", user.email.maskEmail())  // 이메일 마스킹
)

// DEBUG: 디버깅에 필요한 상세 정보
logger.debug("Processing order",
    kv("orderId", order.id),
    kv("items", order.items.size),
    kv("totalAmount", order.totalAmount)
)

// ERROR: 예외 상황, 스택 트레이스 포함
logger.error("Failed to process payment",
    kv("orderId", order.id),
    kv("errorCode", errorCode),
    e  // Exception 객체
)
```

### 2. 로그 레벨 가이드라인

| 레벨 | 용도 | 예시 |
|-----|------|-----|
| **TRACE** | 매우 상세한 디버그 정보 | "Entering method", "Loop iteration 5" |
| **DEBUG** | 디버깅에 필요한 정보 | "Query: SELECT * FROM users WHERE...", "Cache hit" |
| **INFO** | 중요 비즈니스 이벤트 | "User login successful", "Order created" |
| **WARN** | 잠재적 문제 상황 | "API rate limit 80% reached", "Retrying connection" |
| **ERROR** | 에러 발생, 복구 가능 | "Payment failed", "External API timeout" |
| **FATAL** | 치명적 오류, 복구 불가 | "Database connection lost", "Out of memory" |

### 3. 구조화된 로깅 (Structured Logging)

```kotlin
// ❌ 비구조화된 로그 (파싱 어려움)
logger.info("User test@example.com created order #12345 with amount $99.99")

// ✅ 구조화된 로그 (검색 쉬움)
logger.info("Order created",
    kv("userId", user.id),
    kv("userEmail", user.email),
    kv("orderId", order.id),
    kv("amount", order.amount),
    kv("currency", "USD")
)

// JSON 출력 예시:
// {
//   "message": "Order created",
//   "userId": 123,
//   "userEmail": "test@example.com",
//   "orderId": 12345,
//   "amount": 99.99,
//   "currency": "USD"
// }
```

### 4. 상관 관계 추적 (Correlation ID)

요청 전체를 추적하기 위한 상관 ID 사용:

```kotlin
// Spring Boot Interceptor
@Component
class CorrelationIdInterceptor : HandlerInterceptor {
    companion object {
        const val CORRELATION_ID_HEADER = "X-Correlation-ID"
        const val CORRELATION_ID_MDC_KEY = "correlationId"
    }

    override fun preHandle(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any
    ): Boolean {
        // 헤더에서 Correlation ID 가져오기 or 새로 생성
        val correlationId = request.getHeader(CORRELATION_ID_HEADER)
            ?: UUID.randomUUID().toString()

        // MDC에 저장 (모든 로그에 자동 포함됨)
        MDC.put(CORRELATION_ID_MDC_KEY, correlationId)

        // 응답 헤더에도 추가
        response.setHeader(CORRELATION_ID_HEADER, correlationId)

        return true
    }

    override fun afterCompletion(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any,
        ex: Exception?
    ) {
        // 요청 완료 후 MDC 정리
        MDC.clear()
    }
}

// 사용 예시
class OrderService {
    private val logger = LoggerFactory.getLogger(OrderService::class.java)

    fun createOrder(request: CreateOrderRequest): Order {
        // correlationId는 자동으로 모든 로그에 포함됨
        logger.info("Creating order for user {}", request.userId)

        // 다른 서비스 호출 시에도 Correlation ID 전달
        val user = userClient.getUser(request.userId)

        logger.info("Order created successfully")
        return order
    }
}

// Feign Client에서 Correlation ID 전달
@Component
class CorrelationIdFeignInterceptor : RequestInterceptor {
    override fun apply(template: RequestTemplate) {
        val correlationId = MDC.get(CorrelationIdInterceptor.CORRELATION_ID_MDC_KEY)
        if (correlationId != null) {
            template.header(
                CorrelationIdInterceptor.CORRELATION_ID_HEADER,
                correlationId
            )
        }
    }
}
```

이렇게 하면 Kibana에서 `correlationId`로 검색하여 전체 요청 흐름을 추적할 수 있습니다:

```
Kibana 검색:
correlationId: "abc-123-def-456"

결과:
┌──────────────────────────────────────────────────────────────┐
│ 10:15:32.123 | user-service     | Authenticating user       │
│ 10:15:32.234 | user-service     | User authenticated        │
│ 10:15:32.345 | account-service  | Fetching account balance  │
│ 10:15:32.456 | account-service  | Balance: $1,000           │
│ 10:15:32.567 | trade-service    | Creating order            │
│ 10:15:32.678 | trade-service    | Order created: #12345     │
│ 10:15:32.789 | notification     | Sending email             │
└──────────────────────────────────────────────────────────────┘
```

### 5. 민감 정보 보호

```kotlin
// 이메일 마스킹
fun String.maskEmail(): String {
    val parts = this.split("@")
    if (parts.size != 2) return "***"
    val local = parts[0]
    val domain = parts[1]
    val masked = local.take(2) + "*".repeat(local.length - 2)
    return "$masked@$domain"
}

// 전화번호 마스킹
fun String.maskPhone(): String {
    return this.replaceRange(4, this.length - 4, "*".repeat(this.length - 8))
}

// 카드 번호 마스킹
fun String.maskCardNumber(): String {
    return this.replaceRange(4, 12, "****-****")
}

// 사용 예시
logger.info("User registered",
    kv("email", user.email.maskEmail()),  // te**@example.com
    kv("phone", user.phone.maskPhone())   // 010-****-5678
)
```

---

## LK-Trade 프로젝트에 적용하기

### 1. 전체 docker-compose 통합

```yaml
# docker-compose.yml (전체 통합 버전)
version: '3.8'

services:
  # ========================================
  # ELK Stack
  # ========================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: lk-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - lk-trade-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: lk-logstash
    volumes:
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5044:5044"
      - "9600:9600"
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
    networks:
      - lk-trade-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: lk-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - lk-trade-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: lk-filebeat
    user: root
    volumes:
      - ./elk/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data:/usr/share/filebeat/data
    command: filebeat -e -strict.perms=false
    networks:
      - lk-trade-network
    depends_on:
      - logstash

  # ========================================
  # Application Services (로그 설정 포함)
  # ========================================
  user-service:
    build:
      context: ./modules/user/api
      dockerfile: Dockerfile
    container_name: lk-user-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=user"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/lk_trade
    ports:
      - "8081:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres
      - redis

  trade-service:
    build:
      context: ./modules/trade/api
      dockerfile: Dockerfile
    container_name: lk-trade-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=trade"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8082:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres
      - redis

  account-service:
    build:
      context: ./modules/account/api
      dockerfile: Dockerfile
    container_name: lk-account-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=account"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8083:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres

  strategy-service:
    build:
      context: ./modules/strategy/api
      dockerfile: Dockerfile
    container_name: lk-strategy-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=strategy"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8084:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres

  # ========================================
  # Infrastructure
  # ========================================
  postgres:
    image: postgres:16-alpine
    container_name: lk-postgres
    environment:
      - POSTGRES_DB=lk_trade
      - POSTGRES_USER=lk_admin
      - POSTGRES_PASSWORD=secure_password
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - lk-trade-network

  redis:
    image: redis:7-alpine
    container_name: lk-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - lk-trade-network

volumes:
  elasticsearch-data:
  filebeat-data:
  postgres-data:
  redis-data:

networks:
  lk-trade-network:
    driver: bridge
```

### 2. 디렉토리 구조

```
C:\trade\backend1\
├── elk/
│   ├── filebeat/
│   │   └── filebeat.yml
│   └── logstash/
│       ├── config/
│       │   └── logstash.yml
│       └── pipeline/
│           └── logstash.conf
├── modules/
│   ├── user/api/
│   │   └── src/main/resources/
│   │       └── logback-spring.xml
│   ├── trade/api/
│   │   └── src/main/resources/
│   │       └── logback-spring.xml
│   └── ...
└── scripts/
    ├── start-elk.sh
    └── stop-elk.sh
```

### 3. 시작/중지 스크립트

```bash
#!/bin/bash
# scripts/start-elk.sh

echo "🚀 Starting ELK Stack..."

# Elasticsearch 시작
docker-compose up -d elasticsearch
echo "⏳ Waiting for Elasticsearch to be healthy..."
until docker exec lk-elasticsearch curl -s http://localhost:9200 > /dev/null; do
    sleep 5
done
echo "✅ Elasticsearch is ready"

# Logstash 시작
docker-compose up -d logstash
echo "⏳ Waiting for Logstash..."
sleep 30
echo "✅ Logstash is ready"

# Kibana 시작
docker-compose up -d kibana
echo "⏳ Waiting for Kibana..."
sleep 30
echo "✅ Kibana is ready"

# Filebeat 시작
docker-compose up -d filebeat
echo "✅ Filebeat is ready"

echo "
========================================
ELK Stack started successfully! 🎉
========================================

📊 Kibana: http://localhost:5601
🔍 Elasticsearch: http://localhost:9200
📝 Logstash: http://localhost:9600

Next steps:
1. Open Kibana: http://localhost:5601
2. Create index pattern: lk-trade-*
3. Start exploring logs in Discover
========================================
"
```

```bash
#!/bin/bash
# scripts/stop-elk.sh

echo "🛑 Stopping ELK Stack..."

docker-compose stop filebeat
docker-compose stop kibana
docker-compose stop logstash
docker-compose stop elasticsearch

echo "✅ ELK Stack stopped"
```

### 4. Makefile 통합

```makefile
# Makefile
.PHONY: elk-start elk-stop elk-logs elk-status logs-view logs-search

# ELK Stack 관리
elk-start:
	@echo "🚀 Starting ELK Stack..."
	@bash scripts/start-elk.sh

elk-stop:
	@echo "🛑 Stopping ELK Stack..."
	@bash scripts/stop-elk.sh

elk-logs:
	@docker-compose logs -f elasticsearch logstash kibana filebeat

elk-status:
	@echo "📊 Elasticsearch:"
	@curl -s http://localhost:9200 | jq
	@echo "\n📝 Logstash:"
	@curl -s http://localhost:9600 | jq
	@echo "\n🔍 Kibana:"
	@curl -s http://localhost:5601/api/status | jq

# 로그 조회
logs-view:
	@echo "Select service:"
	@echo "1) user-service"
	@echo "2) trade-service"
	@echo "3) account-service"
	@echo "4) strategy-service"
	@echo "5) all services"
	@read -p "Enter number: " choice; \
	case $$choice in \
		1) docker-compose logs -f user-service ;; \
		2) docker-compose logs -f trade-service ;; \
		3) docker-compose logs -f account-service ;; \
		4) docker-compose logs -f strategy-service ;; \
		5) docker-compose logs -f ;; \
		*) echo "Invalid choice" ;; \
	esac

# Kibana에서 최근 에러 검색
logs-search-errors:
	@echo "🔍 Searching for recent errors in Kibana..."
	@curl -s -X GET "http://localhost:9200/lk-trade-*/_search" \
		-H 'Content-Type: application/json' \
		-d '{"query":{"match":{"log_level":"ERROR"}},"size":10,"sort":[{"@timestamp":{"order":"desc"}}]}' \
		| jq '.hits.hits[]._source | {time: .timestamp, service: .service_name, message: .message}'
```

---

## 트러블슈팅

### 문제 1: Filebeat가 로그를 수집하지 못함

```bash
# 증상
Kibana에 로그가 나타나지 않음

# 원인 확인
docker logs lk-filebeat

# 일반적인 원인:
# 1. Docker 소켓 권한 문제
# 2. 로그 경로 마운트 오류
# 3. Logstash 연결 실패

# 해결책 1: 권한 확인
docker exec lk-filebeat ls -la /var/run/docker.sock
# 출력: srw-rw---- 1 root docker 0 Sep 30 10:00 /var/run/docker.sock

# 해결책 2: Logstash 연결 확인
docker exec lk-filebeat cat /usr/share/filebeat/filebeat.yml | grep logstash
# output.logstash.hosts가 올바른지 확인

# 해결책 3: Filebeat 재시작
docker-compose restart filebeat
```

### 문제 2: Logstash가 로그를 파싱하지 못함

```bash
# 증상
Elasticsearch에 로그가 저장되지만 필드가 파싱되지 않음

# 원인 확인
docker logs lk-logstash

# 일반적인 원인:
# - grok 패턴 오류
# - JSON 파싱 실패

# 해결책: Logstash 파이프라인 테스트
docker exec -it lk-logstash bash

# 샘플 로그로 테스트
echo '{"log":"2025-09-30 10:15:32.123 INFO [main] Application started\n","stream":"stdout"}' \
  | /usr/share/logstash/bin/logstash -f /usr/share/logstash/pipeline/logstash.conf --config.test_and_exit

# 출력에서 파싱 결과 확인
```

### 문제 3: Elasticsearch 디스크 공간 부족

```bash
# 증상
Elasticsearch가 read-only 모드로 전환

# 확인
curl -X GET "http://localhost:9200/_cluster/health?pretty"

# 해결책 1: 오래된 인덱스 삭제
# 30일 이전 인덱스 삭제
curl -X DELETE "http://localhost:9200/lk-trade-2025.08.*"

# 해결책 2: Index Lifecycle Management (ILM) 설정
curl -X PUT "http://localhost:9200/_ilm/policy/lk-trade-policy" -H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_size": "50gb",
            "max_age": "7d"
          }
        }
      },
      "delete": {
        "min_age": "30d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
'

# 해결책 3: read-only 모드 해제
curl -X PUT "http://localhost:9200/_cluster/settings" -H 'Content-Type: application/json' -d'
{
  "persistent": {
    "cluster.routing.allocation.disk.threshold_enabled": false
  }
}
'
curl -X PUT "http://localhost:9200/*/_settings" -H 'Content-Type: application/json' -d'
{
  "index.blocks.read_only_allow_delete": null
}
'
```

### 문제 4: Kibana가 느림

```bash
# 증상
Kibana 대시보드 로딩이 매우 느림

# 원인:
# - 너무 많은 데이터 조회
# - 인덱스가 최적화되지 않음

# 해결책 1: 시간 범위 줄이기
# Kibana에서 "Last 15 minutes" 등으로 범위 축소

# 해결책 2: 인덱스 최적화
curl -X POST "http://localhost:9200/lk-trade-*/_forcemerge?max_num_segments=1"

# 해결책 3: Kibana 메모리 증가
# docker-compose.yml에서:
kibana:
  environment:
    - NODE_OPTIONS="--max-old-space-size=4096"
```

---

## 👨‍💻 주니어 개발자 시나리오

### 시나리오 1: 첫 로그 디버깅 - 에러 로그를 못 찾겠어요

**상황**:
```
팀장: "user-service에서 오류 났는데 확인 좀 해봐요."
주니어 A (당황): "어... 로그를 어디서 봐야 하나요?"
팀장: "docker logs 명령어 써보세요."
주니어 A: "네! (그런데 docker logs가 뭐지...?)"
```

**단계별 해결**:
```bash
# Step 1: 실행 중인 컨테이너 확인
$ docker ps
CONTAINER ID   NAME           STATUS
abc123def456   user-service   Up 10 minutes

# Step 2: 로그 확인 (가장 기본!)
$ docker logs user-service

# 출력:
2025-09-30 10:15:32.123 INFO  [main] Application started
2025-09-30 10:16:45.456 ERROR [http-thread-1] NullPointerException at UserService.java:123
...
(너무 많아서 스크롤이 계속 올라감... 😵)

# Step 3: 최근 로그만 보기 (tail 옵션)
$ docker logs --tail 50 user-service
# 최근 50줄만 출력 → 훨씬 보기 쉬움!

# Step 4: 실시간 로그 보기 (follow 옵션)
$ docker logs -f user-service
# tail -f처럼 새 로그가 계속 출력됨

# Step 5: 에러만 필터링
$ docker logs user-service 2>&1 | grep ERROR
2025-09-30 10:16:45.456 ERROR [http-thread-1] NullPointerException
2025-09-30 10:17:12.789 ERROR [http-thread-2] Database connection failed
# 아하! 에러만 골라서 볼 수 있구나!

# Step 6: 타임스탬프 포함해서 보기
$ docker logs -t --tail 100 user-service | grep ERROR
2025-09-30T10:16:45.456789Z 2025-09-30 10:16:45.456 ERROR ...
# 정확한 시간 확인 가능!

✅ 해결!
```

**배운 점**:
- `docker logs <container>`: 기본 로그 확인
- `--tail N`: 최근 N줄만 보기
- `-f`: 실시간 로그 스트리밍
- `-t`: 타임스탬프 포함
- `grep`으로 필터링 가능

---

### 시나리오 2: 로그가 너무 많아서 디스크가 꽉 참

**상황**:
```
시니어: "서버 디스크 사용률이 95%인데, 뭐가 문제죠?"
주니어 B: "확인해보겠습니다!"

$ df -h
/dev/sda1  100G   95G   5G  95% /

$ du -sh /var/lib/docker/containers/*
15G  /var/lib/docker/containers/abc123...  # user-service
8G   /var/lib/docker/containers/def456...  # trade-service
...

주니어 B (놀람): "로그 파일이 15GB나 돼요!!"
시니어: "로그 로테이션 설정 안 했나봐요. 고쳐볼까요?"
```

**단계별 해결**:
```bash
# Step 1: 로그 크기 확인
$ docker inspect user-service | grep LogPath
"LogPath": "/var/lib/docker/containers/abc123.../abc123...-json.log"

$ sudo ls -lh /var/lib/docker/containers/abc123.../*-json.log
-rw-r----- 1 root root 15G Sep 30 10:00 abc123...-json.log
# 15GB!! 😱

# Step 2: docker-compose.yml에 로그 로테이션 설정
# docker-compose.yml 수정:
services:
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # 최대 10MB
        max-file: "3"     # 최대 3개 파일
        # → 총 최대 30MB로 제한!

# Step 3: 서비스 재시작
$ docker-compose down
$ docker-compose up -d

# Step 4: 기존 로그 파일 정리 (주의!)
$ docker system prune -a --volumes
# 또는 수동으로:
$ sudo rm /var/lib/docker/containers/abc123.../*-json.log.1
$ sudo rm /var/lib/docker/containers/abc123.../*-json.log.2

# Step 5: 확인
$ docker logs user-service
# 로그가 초기화됨 (이전 로그는 사라짐)

# 며칠 후 다시 확인:
$ sudo ls -lh /var/lib/docker/containers/abc123.../*
-rw-r----- 1 root root 10M Oct 3 15:00 abc123...-json.log
-rw-r----- 1 root root 10M Oct 3 14:00 abc123...-json.log.1
-rw-r----- 1 root root 10M Oct 3 13:00 abc123...-json.log.2
# 총 30MB로 유지됨! ✅
```

**배운 점**:
- 로그 로테이션 설정 필수 (max-size, max-file)
- 설정 안 하면 디스크 꽉 참
- 개발 환경: 10MB x 3개 = 30MB
- 프로덕션: 100MB x 5개 = 500MB 권장

---

### 시나리오 3: ELK Stack 설치했는데 로그가 안 보임

**상황**:
```
주니어 C: "ELK Stack 설치 완료했어요!"
팀장: "Kibana에서 로그 보이나요?"
주니어 C: (Kibana 접속) "아무것도 안 보여요... 😢"
팀장: "Filebeat 설정 확인해봤어요?"
주니어 C: "???"
```

**단계별 해결**:
```bash
# Step 1: Elasticsearch 정상 작동 확인
$ curl http://localhost:9200
{
  "name" : "elasticsearch",
  "cluster_name" : "docker-cluster",
  "version" : { ... }
}
# ✅ Elasticsearch 정상

# Step 2: Filebeat 로그 확인
$ docker logs lk-filebeat
ERROR: Failed to connect to Logstash at localhost:5044
# 아하! Logstash 연결 실패!

# Step 3: Logstash 상태 확인
$ docker ps | grep logstash
(아무것도 없음)
# Logstash가 안 떠있음!

# Step 4: Logstash 시작
$ docker-compose up -d logstash

# Step 5: Logstash 준비될 때까지 대기 (30초 정도)
$ docker logs -f lk-logstash
[INFO] Successfully started Logstash API endpoint

# Step 6: Filebeat 재시작
$ docker-compose restart filebeat

# Step 7: Filebeat 로그 다시 확인
$ docker logs lk-filebeat
[INFO] Connection to Logstash established
# ✅ 연결 성공!

# Step 8: Kibana에서 확인
# http://localhost:5601
# Management > Index Patterns > Create index pattern
# lk-trade-* 입력 → Create
# Discover 탭으로 이동
# 로그가 보임! 🎉
```

**배운 점**:
- ELK Stack 시작 순서 중요:
  1. Elasticsearch 먼저
  2. Logstash (Elasticsearch 준비 후)
  3. Kibana
  4. Filebeat (Logstash 준비 후)
- `docker logs`로 각 컨테이너 상태 확인
- 연결 실패 시 순서대로 하나씩 확인

---

### 시나리오 4: Correlation ID로 분산 추적하기

**상황**:
```
주니어 D: "user-service에서 trade-service 호출했는데, trade-service 로그를 어떻게 찾죠?"
시니어: "Correlation ID 구현했어요?"
주니어 D: "그게 뭔가요?"
시니어: "요청마다 고유 ID를 부여해서 여러 서비스 로그를 추적하는 거예요."
```

**구현 과정**:
```kotlin
// Step 1: Interceptor 생성
@Component
class CorrelationIdInterceptor : HandlerInterceptor {
    companion object {
        const val CORRELATION_ID_HEADER = "X-Correlation-ID"
        const val CORRELATION_ID_MDC_KEY = "correlationId"
    }

    override fun preHandle(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any
    ): Boolean {
        // 헤더에서 Correlation ID 가져오기 or 생성
        val correlationId = request.getHeader(CORRELATION_ID_HEADER)
            ?: UUID.randomUUID().toString()

        // MDC에 저장 (모든 로그에 자동 포함)
        MDC.put(CORRELATION_ID_MDC_KEY, correlationId)

        // 응답 헤더에도 추가
        response.setHeader(CORRELATION_ID_HEADER, correlationId)

        return true
    }

    override fun afterCompletion(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any,
        ex: Exception?
    ) {
        MDC.clear()
    }
}

// Step 2: Feign Client에서 Correlation ID 전달
@Component
class CorrelationIdFeignInterceptor : RequestInterceptor {
    override fun apply(template: RequestTemplate) {
        val correlationId = MDC.get("correlationId")
        if (correlationId != null) {
            template.header("X-Correlation-ID", correlationId)
        }
    }
}

// Step 3: Logback 설정 (correlationId 포함)
<!-- logback-spring.xml -->
<appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
    <encoder class="net.logstash.logback.encoder.LogstashEncoder">
        <includeMdcKeyName>correlationId</includeMdcKeyName>
    </encoder>
</appender>
```

**사용 예시**:
```bash
# Kibana에서 검색:
correlationId: "abc-123-def-456"

# 결과 (여러 서비스 로그가 한 번에 조회됨):
┌──────────────────────────────────────────────────────────────┐
│ 10:15:32.123 | user-service     | Authenticating user       │
│ 10:15:32.234 | user-service     | User authenticated        │
│ 10:15:32.345 | trade-service    | Creating order            │
│ 10:15:32.456 | trade-service    | Order created: #12345     │
│ 10:15:32.567 | account-service  | Deducting balance         │
│ 10:15:32.678 | account-service  | Balance updated           │
│ 10:15:32.789 | notification     | Sending email             │
└──────────────────────────────────────────────────────────────┘

# 전체 요청 흐름이 한눈에! 🎉
```

**배운 점**:
- Correlation ID = 분산 시스템에서 필수
- MDC (Mapped Diagnostic Context) 활용
- 모든 서비스 간 호출에 전달
- Kibana에서 손쉬운 추적 가능

---

## ❓ FAQ

<details>
<summary><strong>Q1: docker logs 명령어로 로그를 볼 수 없는데 어떻게 하나요?</strong></summary>

**A**: 애플리케이션이 stdout/stderr로 로그를 출력하지 않기 때문입니다.

**상세 설명**:

**문제**:
```bash
$ docker logs myapp
(아무것도 출력 안 됨)

# 하지만 컨테이너 내부에는 로그 파일이 있음:
$ docker exec myapp ls /var/log/app
app.log  # 파일로만 로그 저장됨
```

**원인**:
애플리케이션이 파일에만 로그를 쓰고, stdout/stderr로는 출력하지 않음.

**해결 방법**:

**방법 1: 심볼릭 링크로 stdout 연결 (권장)**
```dockerfile
# Dockerfile
FROM openjdk:17-jre-alpine

# 로그를 stdout으로 리다이렉트
RUN ln -sf /dev/stdout /var/log/app.log

CMD ["java", "-jar", "app.jar"]
```

**방법 2: 애플리케이션 설정 변경 (Logback 예시)**
```xml
<!-- logback-spring.xml -->
<configuration>
    <!-- 파일 대신 콘솔로 출력 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level [%thread] %logger : %msg%n</pattern>
        </encoder>
    </appender>

    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
    </root>
</configuration>
```

**방법 3: 파일 로그를 직접 확인**
```bash
# 컨테이너 내부에서 tail
$ docker exec myapp tail -f /var/log/app.log

# 또는 호스트로 복사
$ docker cp myapp:/var/log/app.log ./app.log
$ tail -f ./app.log
```

**Best Practice**:
> **"컨테이너 로그는 항상 stdout/stderr로 출력하세요!"**
>
> 이유:
> - Docker 로깅 드라이버 활용 가능
> - Kubernetes 등 오케스트레이션 툴과 호환
> - 12-Factor App 원칙 준수

</details>

<details>
<summary><strong>Q2: ELK Stack이 메모리를 너무 많이 사용하는데 어떻게 줄이나요?</strong></summary>

**A**: JVM 힙 메모리 설정과 인덱스 관리로 메모리 사용량을 최적화할 수 있습니다.

**상세 설명**:

**문제**:
```bash
$ docker stats
CONTAINER        MEM USAGE / LIMIT
elasticsearch    7.5GiB / 8GiB   (94%)
logstash         3.2GiB / 4GiB   (80%)
kibana           1.8GiB / 2GiB   (90%)
# 총 12.5GB 사용 중! 😱
```

**해결 방법**:

**1. Elasticsearch 메모리 최적화**
```yaml
# docker-compose.yml
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      # JVM 힙 메모리 설정 (물리 메모리의 50% 이하)
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"  # 8GB → 2GB로 감소
      - discovery.type=single-node
      - xpack.security.enabled=false
    deploy:
      resources:
        limits:
          memory: 4g  # 컨테이너 전체 메모리 제한
```

**2. Logstash 메모리 최적화**
```yaml
services:
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    environment:
      - "LS_JAVA_OPTS=-Xms512m -Xmx1g"  # 4GB → 1GB로 감소
    deploy:
      resources:
        limits:
          memory: 2g
```

**3. 오래된 인덱스 자동 삭제 (ILM)**
```bash
# Index Lifecycle Management 정책 설정
curl -X PUT "http://localhost:9200/_ilm/policy/lk-trade-policy" \
  -H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_size": "50gb",
            "max_age": "7d"
          }
        }
      },
      "delete": {
        "min_age": "30d",  # 30일 후 자동 삭제
        "actions": {
          "delete": {}
        }
      }
    }
  }
}'
```

**4. 작은 환경용 설정 (개발/테스트)**
```yaml
# docker-compose.dev.yml
services:
  elasticsearch:
    environment:
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"  # 최소 설정
    deploy:
      resources:
        limits:
          memory: 1g

  logstash:
    environment:
      - "LS_JAVA_OPTS=-Xms256m -Xmx512m"
    deploy:
      resources:
        limits:
          memory: 1g

  kibana:
    environment:
      - NODE_OPTIONS="--max-old-space-size=512"
    deploy:
      resources:
        limits:
          memory: 1g

# 총 3GB로 축소!
```

**메모리 최적화 가이드라인**:

| 환경 | Elasticsearch | Logstash | Kibana | 총합 |
|-----|--------------|----------|--------|------|
| **개발** | 512MB | 512MB | 512MB | 1.5GB |
| **소규모** | 2GB | 1GB | 1GB | 4GB |
| **중규모** | 4GB | 2GB | 2GB | 8GB |
| **대규모** | 8GB+ | 4GB+ | 2GB | 14GB+ |

</details>

<details>
<summary><strong>Q3: Kibana에서 로그를 검색했는데 너무 느린데 어떻게 하나요?</strong></summary>

**A**: 시간 범위 축소, 인덱스 최적화, 필드 필터링으로 검색 속도를 개선할 수 있습니다.

**상세 설명**:

**문제**:
```
Kibana 검색 시 30초 이상 소요... 😴
```

**원인 진단**:
```bash
# 1. 인덱스 크기 확인
$ curl -X GET "http://localhost:9200/_cat/indices?v&h=index,docs.count,store.size"
index                    docs.count  store.size
lk-trade-2025.09.01     10,000,000      15gb
lk-trade-2025.09.02     12,000,000      18gb
lk-trade-2025.09.30      8,000,000      12gb
# 총 3000만 건, 45GB! 😱
```

**해결책**:

**1. 시간 범위 축소 (가장 효과적!)**
```
Kibana UI:
- "Last 15 minutes" 선택 (기본: Last 15 minutes)
- 필요시에만 "Last 24 hours" 또는 "Last 7 days" 사용

효과:
- Last 7 days: 30초
- Last 24 hours: 5초
- Last 1 hour: 0.5초
```

**2. 필드 필터링 (정확한 검색)**
```
❌ 느린 검색:
message: *error*
# 모든 message 필드를 와일드카드 검색 → 느림

✅ 빠른 검색:
log_level: "ERROR"
# 정확한 필드 매칭 → 빠름

✅ 더 빠른 검색:
log_level: "ERROR" AND service_name: "user-service" AND @timestamp: [now-1h TO now]
# 복합 조건으로 범위 좁히기
```

**3. 인덱스 최적화**
```bash
# 인덱스 병합 (merge)
curl -X POST "http://localhost:9200/lk-trade-*/_forcemerge?max_num_segments=1"

# 효과: 검색 속도 30~50% 향상
```

**4. 샤드 수 조정**
```bash
# 인덱스 템플릿 설정
curl -X PUT "http://localhost:9200/_index_template/lk-trade-template" \
  -H 'Content-Type: application/json' -d'
{
  "index_patterns": ["lk-trade-*"],
  "template": {
    "settings": {
      "number_of_shards": 1,      # 단일 노드: 1개 (기본: 5개)
      "number_of_replicas": 0     # 개발 환경: 0개 (프로덕션: 1~2개)
    }
  }
}'

# 효과: 불필요한 샤드 제거로 검색 속도 향상
```

**5. 자주 검색하는 쿼리 저장**
```
Kibana > Discover > Save Search
이름: "최근 1시간 에러 로그"
필터: log_level: "ERROR" AND @timestamp: [now-1h TO now]

→ 다음부터 클릭 한 번으로 즉시 검색!
```

**성능 비교**:

| 방법 | Before | After | 개선율 |
|-----|--------|-------|--------|
| 시간 범위 축소 (7일→1시간) | 30초 | 0.5초 | 98% ↓ |
| 필드 필터링 (와일드카드→정확한 매칭) | 10초 | 2초 | 80% ↓ |
| 인덱스 병합 | 5초 | 2.5초 | 50% ↓ |
| 샤드 수 최적화 | 3초 | 1.5초 | 50% ↓ |

</details>

<details>
<summary><strong>Q4: 로그에 민감 정보(비밀번호, 카드번호)가 노출되는데 어떻게 막나요?</strong></summary>

**A**: 로그 출력 전 마스킹 처리와 Logback 필터를 사용합니다.

**상세 설명**:

**문제**:
```kotlin
// ❌ 위험한 로그
logger.info("User login: email=${user.email}, password=${user.password}")
// 출력: User login: email=user@example.com, password=mySecretPassword123

logger.info("Payment: cardNumber=${payment.cardNumber}")
// 출력: Payment: cardNumber=1234-5678-9012-3456
```

**해결 방법**:

**1. 마스킹 확장 함수 (Kotlin)**
```kotlin
// MaskingExtensions.kt
fun String.maskEmail(): String {
    val parts = this.split("@")
    if (parts.size != 2) return "***@***.***"
    val local = parts[0]
    val domain = parts[1]
    val masked = local.take(2) + "*".repeat(maxOf(0, local.length - 2))
    return "$masked@$domain"
}

fun String.maskPhone(): String {
    return this.replaceRange(4, this.length - 4, "*".repeat(this.length - 8))
}

fun String.maskCardNumber(): String {
    return this.replaceRange(4, 15, " **** **** ****")
}

fun String.maskPassword(): String {
    return "***"  // 절대 출력하지 않음
}

// 사용 예시
logger.info("User login: email=${user.email.maskEmail()}")
// 출력: User login: email=us**@example.com

logger.info("Payment: cardNumber=${payment.cardNumber.maskCardNumber()}")
// 출력: Payment: cardNumber=1234 **** **** ****
```

**2. 데이터 클래스에 마스킹 toString() 구현**
```kotlin
data class User(
    val id: Long,
    val email: String,
    val password: String,  // 원본
    val phone: String
) {
    // 로그용 안전한 toString
    fun toLogString(): String {
        return "User(id=$id, email=${email.maskEmail()}, phone=${phone.maskPhone()})"
        // password는 아예 출력 안 함!
    }
}

// 사용
logger.info("Created user: ${user.toLogString()}")
// 출력: Created user: User(id=123, email=us**@example.com, phone=010-****-5678)
```

**3. Logback 필터 (자동 마스킹)**
```xml
<!-- logback-spring.xml -->
<configuration>
    <!-- 민감 정보 마스킹 필터 -->
    <conversionRule conversionWord="mask"
                    converterClass="com.lk.trade.logging.MaskingConverter" />

    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level [%thread] %logger : %mask%msg%n</pattern>
        </encoder>
    </appender>
</configuration>
```

```kotlin
// MaskingConverter.kt
class MaskingConverter : MessageConverter() {
    private val patterns = mapOf(
        Regex(""""password"\s*:\s*"([^"]+)"""") to """"password":"***"""",
        Regex(Regex("\\b\\d{4}-\\d{4}-\\d{4}-\\d{4}\\b")) to "****-****-****-****",
        Regex(Regex("\\b\\d{3}-\\d{4}-\\d{4}\\b")) to "***-****-****"
    )

    override fun convert(event: ILoggingEvent): String {
        var message = event.formattedMessage
        patterns.forEach { (regex, replacement) ->
            message = regex.replace(message, replacement)
        }
        return message
    }
}
```

**4. 구조화된 로깅에서 필드 제외**
```kotlin
logger.info("User created",
    kv("userId", user.id),
    kv("email", user.email.maskEmail()),
    // password는 아예 로그에 포함하지 않음!
)

// JSON 출력:
{
  "message": "User created",
  "userId": 123,
  "email": "us**@example.com"
  // password 필드 없음!
}
```

**Best Practice**:
- ✅ 비밀번호, 토큰: 절대 로그에 출력하지 않음
- ✅ 이메일, 전화번호: 부분 마스킹
- ✅ 카드번호: 앞 4자리만 표시
- ✅ 개인 식별 정보 (주민번호 등): 완전 마스킹

</details>

<details>
<summary><strong>Q5: docker-compose logs와 docker logs의 차이가 뭔가요?</strong></summary>

**A**: `docker logs`는 개별 컨테이너 로그를, `docker-compose logs`는 여러 서비스 로그를 통합해서 볼 수 있습니다.

**상세 설명**:

**docker logs (개별 컨테이너)**:
```bash
# 특정 컨테이너 하나의 로그만
$ docker logs lk-user-service
2025-09-30 10:15:32.123 INFO  Application started
2025-09-30 10:16:45.456 ERROR Connection failed
...

# 장점: 빠름, 단순함
# 단점: 여러 컨테이너 로그를 한 번에 못 봄
```

**docker-compose logs (여러 서비스 통합)**:
```bash
# 모든 서비스 로그를 시간순으로 통합
$ docker-compose logs -f
user-service     | 2025-09-30 10:15:32.123 INFO  User login
trade-service    | 2025-09-30 10:15:33.456 INFO  Order created
account-service  | 2025-09-30 10:15:34.789 INFO  Balance updated
user-service     | 2025-09-30 10:15:35.012 INFO  User logout
# 여러 서비스가 섞여서 나옴 (시간순 정렬)

# 특정 서비스만 보기
$ docker-compose logs -f user-service trade-service
user-service     | 2025-09-30 10:15:32.123 INFO  User login
trade-service    | 2025-09-30 10:15:33.456 INFO  Order created
# user-service와 trade-service만 출력

# 장점: 여러 서비스 로그를 한 화면에서 볼 수 있음
# 단점: 로그가 많으면 읽기 어려움
```

**비교표**:

| 명령어 | 대상 | 사용 시나리오 |
|--------|------|------------|
| `docker logs <container>` | 개별 컨테이너 | 특정 컨테이너만 집중 분석 |
| `docker-compose logs` | 모든 서비스 | 전체 시스템 흐름 파악 |
| `docker-compose logs <service1> <service2>` | 특정 서비스들 | 관련 서비스들만 함께 분석 |

**실전 사용 팁**:

```bash
# 1. 전체 흐름 파악 (처음)
$ docker-compose logs --tail 100

# 2. 문제 있는 서비스 발견
user-service     | ERROR: Something went wrong

# 3. 해당 서비스만 집중 분석
$ docker logs -f lk-user-service --tail 500

# 4. 관련 서비스들도 함께 확인
$ docker-compose logs -f user-service account-service

# 5. 에러만 필터링
$ docker-compose logs --tail 1000 | grep ERROR
```

**추천 워크플로우**:
1. `docker-compose logs --tail 100`: 전체 개요 파악
2. `docker logs <특정_컨테이너>`: 문제 컨테이너 집중 분석
3. `docker-compose logs <서비스1> <서비스2>`: 연관 서비스 함께 분석

</details>

---

## 📝 면접 질문

### 주니어 레벨

**Q1: Docker 컨테이너의 로그는 기본적으로 어디에 저장되나요?**

**A**: `/var/lib/docker/containers/<container-id>/<container-id>-json.log` 파일에 JSON 형식으로 저장됩니다.

**상세 답변**:
```bash
# 로그 파일 위치 확인
$ docker inspect user-service | grep LogPath
"LogPath": "/var/lib/docker/containers/abc123.../abc123...-json.log"

# 로그 파일 직접 확인 (Linux/Mac)
$ sudo tail -f /var/lib/docker/containers/abc123.../abc123...-json.log

# 로그 파일 형식 (JSON)
{"log":"2025-09-30 10:15:32.123 INFO  Application started\n","stream":"stdout","time":"2025-09-30T01:15:32.123456789Z"}
{"log":"2025-09-30 10:15:33.456 ERROR Connection failed\n","stream":"stderr","time":"2025-09-30T01:15:33.456789012Z"}
```

**기본 로그 드라이버**:
- 드라이버: `json-file` (기본값)
- 위치: `/var/lib/docker/containers/`
- 형식: JSON Lines (각 줄이 하나의 JSON 객체)

**핵심 포인트**:
- stdout/stderr 출력이 자동으로 수집됨
- Docker Daemon이 자동으로 저장
- 로그 로테이션 설정 안 하면 무한정 증가 (주의!)

---

**Q2: docker logs 명령어의 주요 옵션 3가지를 설명하세요.**

**A**: `--tail`, `-f`, `-t` 옵션이 가장 자주 사용됩니다.

**상세 답변**:

**1. `--tail N` (최근 N줄만 출력)**
```bash
# 최근 50줄만 보기
$ docker logs --tail 50 user-service

# 사용 시나리오:
# - 전체 로그가 너무 많을 때
# - 최신 상태만 빠르게 확인할 때
# - 기본 docker logs는 모든 로그 출력 (느림)
```

**2. `-f, --follow` (실시간 스트리밍)**
```bash
# 실시간으로 로그 따라가기
$ docker logs -f user-service

# Linux의 tail -f와 동일
# Ctrl+C로 중단할 때까지 계속 출력
# 사용 시나리오:
# - 애플리케이션 시작 시 로그 모니터링
# - 에러 발생 여부 실시간 확인
# - 개발 중 디버깅
```

**3. `-t, --timestamps` (타임스탬프 포함)**
```bash
# 타임스탬프와 함께 출력
$ docker logs -t user-service
2025-09-30T01:15:32.123456789Z 2025-09-30 10:15:32.123 INFO  Application started
2025-09-30T01:15:33.456789012Z 2025-09-30 10:15:33.456 ERROR Connection failed

# 사용 시나리오:
# - 정확한 시간 파악 필요할 때
# - 여러 컨테이너 로그 비교 시
# - 장애 시간 분석
```

**조합 사용 (실전)**:
```bash
# 최근 100줄을 타임스탬프와 함께 실시간으로
$ docker logs --tail 100 -ft user-service

# 특정 시간 이후 로그만
$ docker logs --since 2025-09-30T10:00:00 user-service

# 최근 1시간 로그
$ docker logs --since 1h user-service
```

---

### 중급 레벨

**Q3: ELK Stack의 각 구성 요소 역할을 설명하고, Docker 환경에서 로그가 어떻게 흐르는지 설명하세요.**

**A**: **E**lasticsearch, **L**ogstash, **K**ibana는 각각 저장, 가공, 시각화 역할을 담당합니다.

**상세 답변**:

**전체 로그 흐름**:
```
Docker Containers
    ↓ (stdout/stderr)
Docker Daemon
    ↓ (json-file)
JSON 로그 파일
    ↓
Filebeat (수집)
    ↓ (Beats Protocol)
Logstash (가공)
    ↓ (HTTP/JSON)
Elasticsearch (저장)
    ↓ (REST API)
Kibana (시각화)
```

**각 구성 요소 상세**:

**1. Filebeat (로그 수집기)**
```yaml
역할: Docker 컨테이너 로그 파일을 읽어서 Logstash로 전송

filebeat.inputs:
  - type: container
    paths:
      - '/var/lib/docker/containers/*/*.log'

output.logstash:
  hosts: ["logstash:5044"]

장점:
- 가볍고 빠름 (Go언어)
- 자동으로 Docker 메타데이터 추가
- 네트워크 단절 시 재전송 보장
```

**2. Logstash (로그 가공)**
```ruby
역할: 로그를 파싱하고 필터링하여 구조화

input {
  beats {
    port => 5044  # Filebeat로부터 수신
  }
}

filter {
  # Spring Boot 로그 파싱
  grok {
    match => {
      "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} ..."
    }
  }

  # 날짜 파싱
  date {
    match => ["timestamp", "ISO8601"]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "lk-trade-%{+YYYY.MM.dd}"
  }
}

기능:
- Grok 패턴으로 비구조화 로그 → 구조화
- 필드 추가/제거/변환
- 여러 소스 통합
```

**3. Elasticsearch (로그 저장 및 검색)**
```
역할: 로그를 색인하고 빠르게 검색

특징:
- 분산 검색 엔진
- 역색인(Inverted Index)으로 빠른 전문 검색
- JSON 기반 REST API
- 수평 확장 가능 (샤딩)

데이터 저장:
- 인덱스: 날짜별 분리 (lk-trade-2025.09.30)
- 도큐먼트: 각 로그 라인이 하나의 JSON 문서
- 필드: log_level, service_name, message, timestamp 등
```

**4. Kibana (로그 시각화)**
```
역할: Elasticsearch 데이터를 웹 UI로 시각화

기능:
- Discover: 로그 검색 및 필터링
- Visualize: 차트, 그래프 생성
- Dashboard: 여러 시각화를 하나의 대시보드로

검색 예시:
- log_level: "ERROR"
- service_name: "user-service" AND response_time_ms: >1000
- @timestamp: [now-1h TO now]
```

**실전 예시**:
```bash
# 1. 애플리케이션 로그 출력
[user-service] 2025-09-30 10:15:32.123 ERROR Connection failed

# 2. Docker가 JSON으로 저장
{"log":"2025-09-30 10:15:32.123 ERROR Connection failed\n","stream":"stderr","time":"..."}

# 3. Filebeat가 수집하고 Docker 메타데이터 추가
{
  "log": "2025-09-30 10:15:32.123 ERROR Connection failed",
  "container": {"name": "user-service"},
  ...
}

# 4. Logstash가 파싱
{
  "timestamp": "2025-09-30T10:15:32.123",
  "log_level": "ERROR",
  "message": "Connection failed",
  "service_name": "user-service"
}

# 5. Elasticsearch에 저장
PUT /lk-trade-2025.09.30/_doc/abc123
{
  "@timestamp": "2025-09-30T10:15:32.123Z",
  "log_level": "ERROR",
  "message": "Connection failed",
  "service_name": "user-service"
}

# 6. Kibana에서 검색
log_level: "ERROR" AND service_name: "user-service"
→ 즉시 결과 표시!
```

**핵심 포인트**:
- Filebeat: 가벼운 수집기
- Logstash: 강력한 파싱 엔진
- Elasticsearch: 빠른 검색 엔진
- Kibana: 직관적인 UI

---

**Q4: 로그 로테이션이 왜 필요하고, Docker에서 어떻게 설정하나요?**

**A**: 디스크 공간 고갈을 방지하기 위해 필수이며, `max-size`와 `max-file` 옵션으로 설정합니다.

**상세 답변**:

**문제 상황**:
```bash
# 로그 로테이션 설정 안 했을 때:
$ du -sh /var/lib/docker/containers/*/
18G  /var/lib/docker/containers/abc123.../  # user-service
12G  /var/lib/docker/containers/def456.../  # trade-service
...

# 디스크 거의 꽉 참!
$ df -h
/dev/sda1  100G  95G  5G  95% /

# 결과: 서비스 중단 위험!
```

**로그 로테이션 설정**:
```yaml
# docker-compose.yml
services:
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # 파일 하나당 최대 10MB
        max-file: "3"     # 최대 3개 파일 유지
        # → 총 최대 30MB로 제한
```

**동작 방식**:
```
1. user-service-json.log (0MB → 10MB까지 증가)
   └→ 10MB 도달

2. user-service-json.log → user-service-json.log.1 (이름 변경)
   user-service-json.log (새로 생성, 0MB부터 시작)

3. user-service-json.log (10MB)
   user-service-json.log.1 (10MB)

4. user-service-json.log → user-service-json.log.1
   user-service-json.log.1 → user-service-json.log.2
   user-service-json.log (새로 생성)

5. user-service-json.log (10MB)
   user-service-json.log.1 (10MB)
   user-service-json.log.2 (10MB)
   → 총 30MB

6. max-file=3 도달, 가장 오래된 파일 삭제:
   user-service-json.log.2 삭제
   user-service-json.log → user-service-json.log.1
   user-service-json.log.1 → user-service-json.log.2
   user-service-json.log (새로 생성)

→ 항상 30MB 이하 유지!
```

**권장 설정값**:

| 환경 | max-size | max-file | 총 용량 | 보존 기간 |
|-----|----------|----------|---------|----------|
| **개발** | 10m | 3 | 30MB | ~1일 |
| **테스트** | 50m | 5 | 250MB | ~1주 |
| **프로덕션** | 100m | 10 | 1GB | ~1개월 |
| **대용량** | 500m | 20 | 10GB | ~3개월 |

**설정 검증**:
```bash
# 현재 로그 설정 확인
$ docker inspect user-service | jq '.[0].HostConfig.LogConfig'
{
  "Type": "json-file",
  "Config": {
    "max-size": "10m",
    "max-file": "3"
  }
}

# 로그 파일 크기 확인
$ sudo ls -lh /var/lib/docker/containers/abc123.../
-rw-r----- 1 root root 10M Oct 1 10:00 abc123...-json.log
-rw-r----- 1 root root 10M Oct 1 09:00 abc123...-json.log.1
-rw-r----- 1 root root 10M Oct 1 08:00 abc123...-json.log.2
# 총 30MB ✅
```

**주의사항**:
- 설정 변경 후 컨테이너 재시작 필요
- 기존 로그 파일은 자동으로 정리 안 됨 (수동 삭제 필요)
- `max-file=1`은 너무 적음 (최소 3개 권장)

---

**Q5: Correlation ID를 사용한 분산 추적의 원리를 설명하고, 실제 구현 방법을 코드로 보여주세요.**

**A**: 요청마다 고유 ID를 부여하고 모든 서비스 호출에 전달하여, 여러 서비스를 거치는 요청 흐름을 추적합니다.

**상세 답변**:

**문제 상황**:
```
마이크로서비스 환경:

사용자 요청
  ↓
API Gateway → user-service → account-service → trade-service
                     ↓              ↓                ↓
                  로그 A         로그 B           로그 C

문제: 로그 A, B, C가 같은 요청인지 알 수 없음!

user-service 로그:
10:15:32.123 INFO User authenticated
10:15:35.456 INFO User authenticated  # 다른 요청인지 같은 요청인지?

account-service 로그:
10:15:33.789 INFO Balance checked
10:15:34.012 INFO Balance checked  # 어떤 user-service 요청에서 온 건지?
```

**Correlation ID 원리**:
```
사용자 요청 (correlationId: abc-123-def)
  ↓
API Gateway (abc-123-def 생성, 헤더에 추가)
  ↓
user-service (abc-123-def 수신, 로그에 기록)
  ↓ 다음 서비스 호출 시 전달
account-service (abc-123-def 수신, 로그에 기록)
  ↓ 다음 서비스 호출 시 전달
trade-service (abc-123-def 수신, 로그에 기록)

모든 로그에 abc-123-def가 포함됨!
```

**구현 코드 (Spring Boot + Kotlin)**:

**1. Interceptor로 Correlation ID 관리**
```kotlin
// CorrelationIdInterceptor.kt
@Component
class CorrelationIdInterceptor : HandlerInterceptor {
    companion object {
        const val CORRELATION_ID_HEADER = "X-Correlation-ID"
        const val CORRELATION_ID_MDC_KEY = "correlationId"
    }

    override fun preHandle(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any
    ): Boolean {
        // 1. 헤더에서 Correlation ID 가져오기
        val correlationId = request.getHeader(CORRELATION_ID_HEADER)
            ?: UUID.randomUUID().toString()  // 없으면 생성

        // 2. MDC에 저장 (모든 로그에 자동 포함됨)
        MDC.put(CORRELATION_ID_MDC_KEY, correlationId)

        // 3. 응답 헤더에도 추가 (클라이언트가 확인 가능)
        response.setHeader(CORRELATION_ID_HEADER, correlationId)

        return true
    }

    override fun afterCompletion(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any,
        ex: Exception?
    ) {
        // 요청 완료 후 MDC 정리 (메모리 누수 방지)
        MDC.clear()
    }
}

// WebMvcConfig.kt (등록)
@Configuration
class WebMvcConfig(
    private val correlationIdInterceptor: CorrelationIdInterceptor
) : WebMvcConfigurer {
    override fun addInterceptors(registry: InterceptorRegistry) {
        registry.addInterceptor(correlationIdInterceptor)
    }
}
```

**2. Feign Client에서 Correlation ID 전달**
```kotlin
// CorrelationIdFeignInterceptor.kt
@Component
class CorrelationIdFeignInterceptor : RequestInterceptor {
    override fun apply(template: RequestTemplate) {
        // MDC에서 Correlation ID 가져와서 헤더에 추가
        val correlationId = MDC.get(CorrelationIdInterceptor.CORRELATION_ID_MDC_KEY)
        if (correlationId != null) {
            template.header(
                CorrelationIdInterceptor.CORRELATION_ID_HEADER,
                correlationId
            )
        }
    }
}

// Feign Client 설정
@FeignClient(
    name = "account-service",
    configuration = [CorrelationIdFeignInterceptor::class]
)
interface AccountServiceClient {
    @GetMapping("/api/accounts/{userId}/balance")
    fun getBalance(@PathVariable userId: Long): BalanceResponse
}
```

**3. Logback 설정 (Correlation ID 포함)**
```xml
<!-- logback-spring.xml -->
<configuration>
    <appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <!-- MDC의 correlationId를 자동으로 포함 -->
            <includeMdcKeyName>correlationId</includeMdcKeyName>
            <fieldNames>
                <timestamp>timestamp</timestamp>
                <message>message</message>
                <logger>logger</logger>
                <level>level</level>
            </fieldNames>
        </encoder>
    </appender>

    <root level="INFO">
        <appender-ref ref="JSON"/>
    </root>
</configuration>
```

**4. 로그 출력 예시**
```kotlin
// UserService.kt
class UserService(
    private val accountServiceClient: AccountServiceClient
) {
    private val logger = LoggerFactory.getLogger(UserService::class.java)

    fun getUserBalance(userId: Long): Balance {
        logger.info("Fetching balance for user {}", userId)
        // correlationId는 MDC에서 자동으로 로그에 포함됨!

        val balance = accountServiceClient.getBalance(userId)
        // Feign Client가 자동으로 Correlation ID를 헤더에 추가

        logger.info("Balance fetched: {}", balance.amount)
        return balance
    }
}
```

**실제 로그 출력**:
```json
// user-service 로그:
{
  "timestamp": "2025-09-30T10:15:32.123Z",
  "level": "INFO",
  "logger": "com.lk.trade.user.UserService",
  "message": "Fetching balance for user 123",
  "correlationId": "abc-123-def-456",  // ← 여기!
  "service": "user-service"
}

// account-service 로그:
{
  "timestamp": "2025-09-30T10:15:32.345Z",
  "level": "INFO",
  "logger": "com.lk.trade.account.AccountService",
  "message": "Getting balance for user 123",
  "correlationId": "abc-123-def-456",  // ← 같은 ID!
  "service": "account-service"
}
```

**Kibana에서 추적**:
```
검색: correlationId: "abc-123-def-456"

결과 (시간순):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
10:15:32.123 | user-service     | Fetching balance for user 123
10:15:32.345 | account-service  | Getting balance for user 123
10:15:32.456 | account-service  | Balance: $1,000
10:15:32.567 | user-service     | Balance fetched: $1,000
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

→ 전체 요청 흐름이 한눈에!
```

**핵심 포인트**:
- **MDC (Mapped Diagnostic Context)**: ThreadLocal 기반, 현재 스레드의 로그에 자동 포함
- **HTTP 헤더 전달**: X-Correlation-ID 헤더로 서비스 간 전달
- **자동화**: Interceptor와 Feign Interceptor로 개발자가 신경 안 써도 됨

---

## 다음 단계

축하합니다! 🎉 이제 Docker 로그 관리의 모든 것을 배웠습니다.

### 이번 섹션에서 배운 것

✅ Docker 로그 드라이버 종류와 설정
✅ ELK Stack (Elasticsearch + Logstash + Kibana) 구축
✅ Filebeat로 Docker 컨테이너 로그 자동 수집
✅ Logstash로 로그 파싱 및 가공
✅ Kibana에서 로그 검색 및 시각화
✅ 구조화된 로깅 및 Correlation ID 추적
✅ 로그 관리 모범 사례
✅ LK-Trade 프로젝트에 로그 관리 통합

### 다음에 배울 것

**섹션 27: 보안 (Security)**에서는:
- Docker 보안 모범 사례
- 컨테이너 격리 및 권한 관리
- 이미지 취약점 스캔
- Secrets 관리
- 네트워크 보안
- 보안 정책 적용

### 추가 학습 자료

**공식 문서:**
- [Docker Logging](https://docs.docker.com/config/containers/logging/)
- [Elastic Stack](https://www.elastic.co/guide/index.html)
- [Filebeat Reference](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)
- [Logstash Reference](https://www.elastic.co/guide/en/logstash/current/index.html)

**심화 학습:**
- [ELK Stack Tutorial](https://www.elastic.co/webinars/getting-started-elasticsearch)
- [Structured Logging Best Practices](https://betterstack.com/community/guides/logging/structured-logging/)
- [Distributed Tracing with OpenTelemetry](https://opentelemetry.io/)

**실전 연습:**
1. LK-Trade 프로젝트에 ELK Stack 적용
2. Kibana 대시보드 커스터마이징
3. 알림 규칙 설정 (Elasticsearch Watcher)
4. 로그 기반 성능 분석 및 최적화

---

**다음 섹션에서 만나요!** 🚀