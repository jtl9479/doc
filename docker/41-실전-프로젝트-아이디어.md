# 섹션 41: 실전 프로젝트 아이디어

## 🚀 실전이 최고의 학습입니다

> "I hear and I forget. I see and I remember. I do and I understand." - 공자

Docker를 배웠다면, 이제 직접 만들어보세요! 이 섹션에서는 난이도별, 목적별 실전 프로젝트 아이디어를 제공합니다.

---

## 📊 프로젝트 난이도 가이드

```
입문 (⭐)
- 2-3일 소요
- 기본 개념 적용
- 단일 서비스

초급 (⭐⭐)
- 1주일 소요
- Docker Compose 사용
- 2-3개 서비스

중급 (⭐⭐⭐)
- 2-3주 소요
- CI/CD 파이프라인
- 5개 이상 서비스

고급 (⭐⭐⭐⭐)
- 1-2개월 소요
- 오케스트레이션
- 프로덕션 배포

전문가 (⭐⭐⭐⭐⭐)
- 3개월 이상
- 대규모 시스템
- 고가용성 설계
```

---

## 🎯 프로젝트 1: 개인 블로그 플랫폼 (⭐⭐)

### 프로젝트 개요

```
목표: 개인 블로그 플랫폼을 Docker로 구축

학습 목표:
✅ 멀티 컨테이너 애플리케이션
✅ 데이터 영속성 관리
✅ 리버스 프록시 설정
✅ 기본 CI/CD
```

### 기술 스택

```yaml
Frontend:
  - React (Vite)
  - Tailwind CSS

Backend:
  - Node.js + Express
  - Prisma ORM

Database:
  - PostgreSQL 16

Cache:
  - Redis

Search:
  - Elasticsearch (선택)

Reverse Proxy:
  - Nginx

Monitoring:
  - Grafana + Prometheus
```

### 프로젝트 구조

```
personal-blog/
├── docker-compose.yml
├── .env.example
├── frontend/
│   ├── Dockerfile
│   ├── nginx.conf
│   └── src/
├── backend/
│   ├── Dockerfile
│   ├── package.json
│   └── src/
├── nginx/
│   └── nginx.conf
└── scripts/
    ├── backup.sh
    └── deploy.sh
```

### docker-compose.yml

```yaml
version: '3.8'

services:
  # Frontend (React)
  frontend:
    build:
      context: ./frontend
      target: production
    container_name: blog-frontend
    depends_on:
      - backend
    networks:
      - frontend-network

  # Backend (Node.js)
  backend:
    build:
      context: ./backend
    container_name: blog-backend
    environment:
      - DATABASE_URL=postgresql://blog:password@postgres:5432/blogdb
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=${JWT_SECRET}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - frontend-network
      - backend-network
    volumes:
      - ./uploads:/app/uploads

  # PostgreSQL
  postgres:
    image: postgres:16-alpine
    container_name: blog-postgres
    environment:
      POSTGRES_DB: blogdb
      POSTGRES_USER: blog
      POSTGRES_PASSWORD: password
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - backend-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U blog"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache
  redis:
    image: redis:alpine
    container_name: blog-redis
    networks:
      - backend-network
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: blog-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - frontend
      - backend
    networks:
      - frontend-network

  # Elasticsearch (Optional)
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: blog-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - backend-network
    profiles:
      - with-search

volumes:
  postgres-data:
  redis-data:
  elasticsearch-data:

networks:
  frontend-network:
  backend-network:
```

### 구현 단계

```
Phase 1: 기본 구성 (1-2일)
  ✅ Docker Compose 설정
  ✅ 각 서비스 Dockerfile 작성
  ✅ 로컬에서 실행 확인

Phase 2: 기능 구현 (3-4일)
  ✅ 사용자 인증 (JWT)
  ✅ 포스트 CRUD
  ✅ 댓글 기능
  ✅ 이미지 업로드

Phase 3: 최적화 (1-2일)
  ✅ Redis 캐싱 적용
  ✅ Nginx 설정 최적화
  ✅ 이미지 최적화
  ✅ 성능 테스트

Phase 4: 배포 (1일)
  ✅ GitHub Actions CI/CD
  ✅ Docker Hub 푸시
  ✅ 클라우드 배포 (AWS/GCP)
```

### 도전 과제

```
⭐ 기본:
  - 마크다운 에디터 추가
  - 태그 및 카테고리 기능

⭐⭐ 중급:
  - Elasticsearch로 전체 검색
  - 댓글 실시간 알림 (WebSocket)
  - 소셜 로그인 (OAuth)

⭐⭐⭐ 고급:
  - CDN 통합
  - 이미지 자동 최적화
  - 다국어 지원
```

---

## 🎯 프로젝트 2: E-Commerce 마이크로서비스 (⭐⭐⭐⭐)

### 프로젝트 개요

```
목표: 확장 가능한 이커머스 플랫폼

학습 목표:
✅ 마이크로서비스 아키텍처
✅ 서비스 간 통신 (REST, gRPC)
✅ 이벤트 드리븐 아키텍처
✅ API Gateway 패턴
✅ 분산 트레이싱
```

### 마이크로서비스 구성

```
┌─────────────────────────────────────────┐
│           API Gateway (Kong)            │
└──────────────┬──────────────────────────┘
               │
    ┌──────────┼──────────┬──────────┐
    │          │          │          │
┌───▼───┐  ┌──▼───┐  ┌──▼───┐  ┌──▼─────┐
│ User  │  │Product│ │Order │  │Payment │
│Service│  │Service│ │Service│ │Service │
└───┬───┘  └──┬───┘  └──┬───┘  └──┬─────┘
    │         │         │         │
┌───▼────┐┌──▼────┐┌──▼────┐┌──▼──────┐
│User DB ││Prod DB││Order DB││Payment  │
│(Postgre││(Mongo)││(Postgre││Service  │
│  SQL)  ││       ││  SQL)  ││(Stripe) │
└────────┘└───────┘└────────┘└─────────┘
```

### 서비스 상세

#### 1. User Service (사용자 관리)

```kotlin
// UserService.kt
@RestController
@RequestMapping("/api/users")
class UserController(
    private val userService: UserService,
    private val kafkaTemplate: KafkaTemplate<String, UserEvent>
) {

    @PostMapping("/register")
    fun register(@RequestBody request: RegisterRequest): User {
        val user = userService.createUser(request)

        // Event 발행
        kafkaTemplate.send("user.created", UserEvent(
            userId = user.id,
            email = user.email,
            timestamp = Instant.now()
        ))

        return user
    }

    @GetMapping("/{id}")
    fun getUser(@PathVariable id: Long): User {
        return userService.findById(id)
    }
}
```

```dockerfile
# Dockerfile
FROM gradle:8.5-jdk17 AS builder
WORKDIR /app
COPY . .
RUN gradle build --no-daemon

FROM eclipse-temurin:17-jre-alpine
WORKDIR /app
COPY --from=builder /app/build/libs/*.jar app.jar
EXPOSE 8080
ENTRYPOINT ["java", "-jar", "app.jar"]
```

#### 2. Product Service (상품 관리)

```javascript
// productService.js
const express = require('express');
const mongoose = require('mongoose');
const redis = require('redis');

const router = express.Router();
const redisClient = redis.createClient({ url: process.env.REDIS_URL });

// 상품 조회 (캐시 적용)
router.get('/:id', async (req, res) => {
    const { id } = req.params;
    const cacheKey = `product:${id}`;

    try {
        // 1. 캐시 확인
        const cached = await redisClient.get(cacheKey);
        if (cached) {
            return res.json(JSON.parse(cached));
        }

        // 2. DB 조회
        const product = await Product.findById(id);

        // 3. 캐시 저장
        await redisClient.setEx(cacheKey, 3600, JSON.stringify(product));

        res.json(product);
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

// 상품 생성
router.post('/', async (req, res) => {
    const product = new Product(req.body);
    await product.save();

    // Elasticsearch 인덱싱
    await indexProduct(product);

    res.status(201).json(product);
});

module.exports = router;
```

#### 3. Order Service (주문 관리)

```python
# order_service.py
from flask import Flask, request, jsonify
from sqlalchemy import create_engine
from kafka import KafkaProducer
import requests
import json

app = Flask(__name__)
producer = KafkaProducer(
    bootstrap_servers='kafka:9092',
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

@app.route('/api/orders', methods=['POST'])
def create_order():
    data = request.get_json()

    # 1. 재고 확인 (Product Service)
    product_response = requests.get(
        f"http://product-service:8080/api/products/{data['productId']}"
    )

    if product_response.status_code != 200:
        return jsonify({"error": "Product not found"}), 404

    product = product_response.json()

    if product['stock'] < data['quantity']:
        return jsonify({"error": "Insufficient stock"}), 400

    # 2. 주문 생성
    order = Order(
        user_id=data['userId'],
        product_id=data['productId'],
        quantity=data['quantity'],
        total_price=product['price'] * data['quantity'],
        status='pending'
    )
    db.session.add(order)
    db.session.commit()

    # 3. 이벤트 발행
    producer.send('order.created', {
        'orderId': order.id,
        'userId': order.user_id,
        'totalPrice': order.total_price,
        'timestamp': order.created_at.isoformat()
    })

    return jsonify({
        'orderId': order.id,
        'status': order.status
    }), 201

@app.route('/api/orders/<int:order_id>', methods=['GET'])
def get_order(order_id):
    order = Order.query.get_or_404(order_id)
    return jsonify(order.to_dict())

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

#### 4. Payment Service (결제)

```go
// payment_service.go
package main

import (
    "github.com/gin-gonic/gin"
    "github.com/stripe/stripe-go/v76"
    "github.com/stripe/stripe-go/v76/paymentintent"
)

type PaymentRequest struct {
    OrderID int64  `json:"orderId"`
    Amount  int64  `json:"amount"`
    Currency string `json:"currency"`
}

func main() {
    stripe.Key = os.Getenv("STRIPE_SECRET_KEY")

    r := gin.Default()

    r.POST("/api/payments", func(c *gin.Context) {
        var req PaymentRequest
        if err := c.ShouldBindJSON(&req); err != nil {
            c.JSON(400, gin.H{"error": err.Error()})
            return
        }

        // Stripe Payment Intent 생성
        params := &stripe.PaymentIntentParams{
            Amount:   stripe.Int64(req.Amount),
            Currency: stripe.String(req.Currency),
            Metadata: map[string]string{
                "order_id": fmt.Sprintf("%d", req.OrderID),
            },
        }

        pi, err := paymentintent.New(params)
        if err != nil {
            c.JSON(500, gin.H{"error": err.Error()})
            return
        }

        // Kafka 이벤트 발행
        publishPaymentEvent("payment.completed", pi)

        c.JSON(200, gin.H{
            "paymentIntentId": pi.ID,
            "status": pi.Status,
        })
    })

    r.Run(":8080")
}
```

### docker-compose.yml (마이크로서비스)

```yaml
version: '3.8'

services:
  # API Gateway
  kong:
    image: kong:3.5-alpine
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-db
      KONG_PG_USER: kong
      KONG_PG_PASSWORD: kong
    ports:
      - "8000:8000"  # Proxy
      - "8001:8001"  # Admin API
    depends_on:
      - kong-db
    networks:
      - microservices

  kong-db:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: kong
      POSTGRES_DB: kong
      POSTGRES_PASSWORD: kong
    volumes:
      - kong-db-data:/var/lib/postgresql/data
    networks:
      - microservices

  # User Service
  user-service:
    build: ./services/user-service
    environment:
      DATABASE_URL: postgresql://postgres:password@user-db:5432/userdb
      KAFKA_BROKERS: kafka:9092
    depends_on:
      - user-db
      - kafka
    networks:
      - microservices

  user-db:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: userdb
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - user-db-data:/var/lib/postgresql/data
    networks:
      - microservices

  # Product Service
  product-service:
    build: ./services/product-service
    environment:
      MONGODB_URI: mongodb://product-db:27017/productdb
      REDIS_URL: redis://redis:6379
      KAFKA_BROKERS: kafka:9092
    depends_on:
      - product-db
      - redis
      - kafka
    networks:
      - microservices

  product-db:
    image: mongo:7
    volumes:
      - product-db-data:/data/db
    networks:
      - microservices

  # Order Service
  order-service:
    build: ./services/order-service
    environment:
      DATABASE_URL: postgresql://postgres:password@order-db:5432/orderdb
      KAFKA_BROKERS: kafka:9092
    depends_on:
      - order-db
      - kafka
    networks:
      - microservices

  order-db:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: orderdb
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - order-db-data:/var/lib/postgresql/data
    networks:
      - microservices

  # Payment Service
  payment-service:
    build: ./services/payment-service
    environment:
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY}
      KAFKA_BROKERS: kafka:9092
    depends_on:
      - kafka
    networks:
      - microservices

  # Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - microservices

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - microservices

  # Redis (Shared Cache)
  redis:
    image: redis:alpine
    networks:
      - microservices

  # Jaeger (Distributed Tracing)
  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"  # UI
      - "14268:14268"  # Collector
    networks:
      - microservices

volumes:
  kong-db-data:
  user-db-data:
  product-db-data:
  order-db-data:

networks:
  microservices:
    driver: bridge
```

### 구현 단계

```
Phase 1: 기본 서비스 (1주)
  ✅ User Service (인증/인가)
  ✅ Product Service (상품 CRUD)
  ✅ 각 서비스 독립 실행 확인

Phase 2: 통신 구현 (1주)
  ✅ API Gateway 설정 (Kong)
  ✅ 서비스 간 REST 통신
  ✅ 에러 처리 및 재시도

Phase 3: 이벤트 드리븐 (1주)
  ✅ Kafka 설정
  ✅ 이벤트 발행/구독
  ✅ Order Service 구현

Phase 4: 결제 통합 (3-4일)
  ✅ Payment Service (Stripe)
  ✅ 결제 플로우 구현
  ✅ 테스트 환경 설정

Phase 5: 관측성 (3-4일)
  ✅ 분산 트레이싱 (Jaeger)
  ✅ 메트릭 수집 (Prometheus)
  ✅ 로그 집계 (ELK)

Phase 6: 배포 (1주)
  ✅ Docker Swarm / Kubernetes
  ✅ CI/CD 파이프라인
  ✅ 모니터링 대시보드
```

### 도전 과제

```
⭐⭐ 중급:
  - gRPC로 서비스 간 통신
  - Circuit Breaker 구현
  - API Rate Limiting

⭐⭐⭐ 고급:
  - Saga 패턴으로 분산 트랜잭션
  - CQRS 패턴 적용
  - Event Sourcing

⭐⭐⭐⭐ 전문가:
  - Service Mesh (Istio)
  - Multi-tenant 아키텍처
  - Chaos Engineering
```

---

## 🎯 프로젝트 3: DevOps 자동화 플랫폼 (⭐⭐⭐⭐⭐)

### 프로젝트 개요

```
목표: 완전한 DevOps 플랫폼 구축

학습 목표:
✅ GitOps 워크플로우
✅ 자동화된 CI/CD
✅ Infrastructure as Code
✅ Full Observability
✅ Self-Service 플랫폼
```

### 플랫폼 구성

```
┌─────────────────────────────────────────┐
│         GitLab (소스 관리)               │
└──────────────┬──────────────────────────┘
               │ Push Event
               ▼
┌─────────────────────────────────────────┐
│        Jenkins (CI/CD 오케스트레이션)    │
│  - Build                                │
│  - Test                                 │
│  - Security Scan                        │
│  - Deploy                               │
└──────────────┬──────────────────────────┘
               │
        ┌──────┴──────┐
        ▼             ▼
┌───────────────┐ ┌──────────────┐
│Harbor Registry│ │ArgoCD (GitOps)│
│(이미지 저장)   │ │(배포 자동화)   │
└───────────────┘ └──────┬───────┘
                         │
                         ▼
                  ┌─────────────┐
                  │  Kubernetes │
                  │   Cluster   │
                  └──────┬──────┘
                         │
         ┌───────────────┼───────────────┐
         ▼               ▼               ▼
  ┌───────────┐   ┌───────────┐  ┌────────────┐
  │Prometheus │   │ELK Stack  │  │  Grafana   │
  │(메트릭)    │   │(로그)      │  │(시각화)     │
  └───────────┘   └───────────┘  └────────────┘
```

### docker-compose.yml (DevOps Stack)

```yaml
version: '3.8'

services:
  # GitLab
  gitlab:
    image: gitlab/gitlab-ce:latest
    container_name: gitlab
    hostname: gitlab.local
    ports:
      - "80:80"
      - "443:443"
      - "22:22"
    volumes:
      - gitlab-config:/etc/gitlab
      - gitlab-logs:/var/log/gitlab
      - gitlab-data:/var/opt/gitlab
    environment:
      GITLAB_OMNIBUS_CONFIG: |
        external_url 'http://gitlab.local'
        gitlab_rails['gitlab_shell_ssh_port'] = 22
    networks:
      - devops

  # Jenkins
  jenkins:
    image: jenkins/jenkins:lts
    container_name: jenkins
    ports:
      - "8080:8080"
      - "50000:50000"
    volumes:
      - jenkins-data:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - JAVA_OPTS=-Djenkins.install.runSetupWizard=false
    networks:
      - devops

  # Harbor (Private Registry)
  harbor-core:
    image: goharbor/harbor-core:v2.9.0
    container_name: harbor-core
    depends_on:
      - harbor-db
      - redis
    environment:
      CORE_SECRET: ${HARBOR_CORE_SECRET}
      JOBSERVICE_SECRET: ${HARBOR_JOBSERVICE_SECRET}
    networks:
      - devops

  harbor-db:
    image: goharbor/harbor-db:v2.9.0
    container_name: harbor-db
    volumes:
      - harbor-db-data:/var/lib/postgresql/data
    environment:
      POSTGRES_PASSWORD: ${HARBOR_DB_PASSWORD}
    networks:
      - devops

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - devops

  # Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - devops

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - devops

  # Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    depends_on:
      - elasticsearch
    networks:
      - devops

  # Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - devops

  # Redis
  redis:
    image: redis:alpine
    container_name: redis
    networks:
      - devops

volumes:
  gitlab-config:
  gitlab-logs:
  gitlab-data:
  jenkins-data:
  harbor-db-data:
  prometheus-data:
  grafana-data:
  elasticsearch-data:

networks:
  devops:
    driver: bridge
```

### Jenkinsfile 예제

```groovy
pipeline {
    agent any

    environment {
        DOCKER_REGISTRY = 'harbor.local'
        APP_NAME = 'myapp'
        SLACK_CHANNEL = '#deployments'
    }

    stages {
        stage('Checkout') {
            steps {
                git branch: 'main',
                    url: 'http://gitlab.local/myapp.git'
            }
        }

        stage('Build') {
            steps {
                sh './gradlew build --no-daemon'
            }
        }

        stage('Unit Tests') {
            steps {
                sh './gradlew test'
                junit '**/build/test-results/test/*.xml'
            }
        }

        stage('Code Quality') {
            steps {
                sh './gradlew sonarqube'
            }
        }

        stage('Security Scan') {
            steps {
                sh 'trivy fs --exit-code 1 --severity HIGH,CRITICAL .'
            }
        }

        stage('Build Docker Image') {
            steps {
                script {
                    def image = docker.build("${DOCKER_REGISTRY}/${APP_NAME}:${BUILD_NUMBER}")
                    docker.withRegistry("https://${DOCKER_REGISTRY}", 'harbor-credentials') {
                        image.push()
                        image.push('latest')
                    }
                }
            }
        }

        stage('Image Scan') {
            steps {
                sh "trivy image ${DOCKER_REGISTRY}/${APP_NAME}:${BUILD_NUMBER}"
            }
        }

        stage('Update GitOps Repo') {
            steps {
                script {
                    sh """
                        git clone http://gitlab.local/myapp-gitops.git
                        cd myapp-gitops
                        sed -i 's|image:.*|image: ${DOCKER_REGISTRY}/${APP_NAME}:${BUILD_NUMBER}|' k8s/deployment.yaml
                        git add .
                        git commit -m "Update image to ${BUILD_NUMBER}"
                        git push origin main
                    """
                }
            }
        }

        stage('Deploy to Staging') {
            when {
                branch 'develop'
            }
            steps {
                sh 'kubectl apply -f k8s/staging/ --namespace=staging'
            }
        }

        stage('Integration Tests') {
            when {
                branch 'develop'
            }
            steps {
                sh './gradlew integrationTest -Denv=staging'
            }
        }

        stage('Deploy to Production') {
            when {
                branch 'main'
            }
            steps {
                input message: 'Deploy to Production?', ok: 'Deploy'
                sh 'kubectl apply -f k8s/production/ --namespace=production'
            }
        }

        stage('Smoke Tests') {
            when {
                branch 'main'
            }
            steps {
                sh './scripts/smoke-tests.sh'
            }
        }
    }

    post {
        success {
            slackSend channel: "${SLACK_CHANNEL}",
                      color: 'good',
                      message: "✅ Build #${BUILD_NUMBER} succeeded"
        }
        failure {
            slackSend channel: "${SLACK_CHANNEL}",
                      color: 'danger',
                      message: "❌ Build #${BUILD_NUMBER} failed"
        }
        always {
            cleanWs()
        }
    }
}
```

### 구현 단계

```
Phase 1: 인프라 구축 (1주)
  ✅ GitLab 설치 및 설정
  ✅ Jenkins 설치 및 플러그인
  ✅ Harbor 설치
  ✅ 네트워크 구성

Phase 2: CI/CD 파이프라인 (1주)
  ✅ Jenkinsfile 작성
  ✅ 자동 빌드 설정
  ✅ 테스트 자동화
  ✅ 보안 스캔 통합

Phase 3: GitOps (1주)
  ✅ ArgoCD 설치
  ✅ GitOps 워크플로우
  ✅ 자동 동기화
  ✅ Rollback 전략

Phase 4: 모니터링 (1주)
  ✅ Prometheus 설정
  ✅ Grafana 대시보드
  ✅ 알림 규칙
  ✅ SLI/SLO 정의

Phase 5: 로깅 (1주)
  ✅ ELK Stack 설정
  ✅ 로그 수집 파이프라인
  ✅ 로그 분석 쿼리
  ✅ 알림 설정

Phase 6: 자동화 (1-2주)
  ✅ Self-Service 포털
  ✅ Infrastructure as Code (Terraform)
  ✅ 자동 스케일링
  ✅ Backup 자동화
```

---

## 🎯 추가 프로젝트 아이디어

### 프로젝트 4: 실시간 채팅 애플리케이션 (⭐⭐)

```
기술 스택:
  - Frontend: React + Socket.io
  - Backend: Node.js + Socket.io
  - Database: MongoDB
  - Cache: Redis (Pub/Sub)
  - Message Queue: RabbitMQ

특징:
  ✅ 실시간 메시징
  ✅ 그룹 채팅
  ✅ 파일 공유
  ✅ 수평 확장 가능
```

### 프로젝트 5: IoT 데이터 수집 플랫폼 (⭐⭐⭐)

```
기술 스택:
  - Data Ingestion: MQTT Broker (Mosquitto)
  - Stream Processing: Apache Kafka
  - Time-Series DB: InfluxDB
  - Visualization: Grafana
  - API: FastAPI (Python)

특징:
  ✅ 대용량 데이터 처리
  ✅ 실시간 대시보드
  ✅ 알림 시스템
  ✅ 데이터 분석
```

### 프로젝트 6: AI/ML 서빙 플랫폼 (⭐⭐⭐⭐)

```
기술 스택:
  - Model Serving: TensorFlow Serving
  - API Gateway: FastAPI
  - Model Registry: MLflow
  - Feature Store: Feast
  - Monitoring: Prometheus + Grafana

특징:
  ✅ 모델 버전 관리
  ✅ A/B 테스트
  ✅ 모델 성능 모니터링
  ✅ 자동 재학습
```

---

## 💡 프로젝트 시작 팁

### 1. MVP부터 시작

```
❌ 나쁜 접근:
  - 모든 기능을 한 번에 구현
  - 완벽한 아키텍처 설계에 집착

✅ 좋은 접근:
  - 핵심 기능만 먼저 구현
  - 빠르게 실행 가능한 버전 만들기
  - 점진적 개선
```

### 2. 문서화 습관

```markdown
# README.md 필수 항목

## 프로젝트 개요
- 목적
- 주요 기능

## 시작하기
\`\`\`bash
docker-compose up -d
\`\`\`

## 아키텍처
- 시스템 다이어그램
- 기술 스택

## API 문서
- 엔드포인트 목록
- 예제 요청/응답

## 트러블슈팅
- 자주 발생하는 문제
- 해결 방법
```

### 3. Git 커밋 전략

```
feat: 새로운 기능 추가
fix: 버그 수정
docs: 문서 수정
refactor: 코드 리팩토링
test: 테스트 코드
chore: 빌드, 설정 변경

예:
feat: Add user authentication
fix: Fix memory leak in cache layer
docs: Update API documentation
```

---

**다음 섹션에서는 실력 향상을 위한 구체적인 로드맵을 다룹니다!**

**다음: [섹션 42: 실력 향상 로드맵](./42-실력-향상-로드맵.md)**