# 29. 프로덕션 배포 전략

> **학습 목표**: 다양한 배포 전략(Recreate, Rolling Update, Blue-Green, Canary)을 이해하고, 상황에 맞는 최적의 배포 방식을 선택하여 무중단 배포를 구현할 수 있습니다.

**⏱️ 예상 학습 시간**: 3-4시간
**난이도**: ⭐⭐⭐⭐⭐ (5개/5개)

---

## 목차
1. [왜 배포 전략이 중요한가](#왜-배포-전략이-중요한가)
2. [실생활 비유로 이해하기](#실생활-비유로-이해하기)
3. [배포 전략의 종류](#배포-전략의-종류)
4. [Recreate 배포](#1-recreate-배포)
5. [Rolling Update](#2-rolling-update-순차-배포)
6. [Blue-Green 배포](#3-blue-green-배포)
7. [Canary 배포](#4-canary-배포)
8. [A/B Testing](#5-ab-testing)
9. [LK-Trade 배포 전략](#6-lk-trade-프로젝트-배포-전략)
10. [주니어 개발자 시나리오](#주니어-개발자-시나리오)
11. [FAQ](#faq)
12. [면접 질문](#면접-질문)

---

## 💡 왜 배포 전략이 중요한가?

### 실무 배경

**"프로덕션 배포 중 장애가 발생했습니다. 어떻게 대응하시겠습니까?"**

#### ❌ 배포 전략이 없으면 발생하는 문제

```
문제 1: 전체 서비스 다운타임 발생
- 증상: 모든 서버를 한 번에 업데이트
- 대응: 새 버전에 버그가 있으면 전체 서비스 중단
- 영향: 평균 5-10분 다운타임, 모든 사용자 영향
- 비용: 1분당 $694 손실, 10분 = $6,940 손실

문제 2: 느린 롤백으로 피해 확대
- 증상: "어? 배포 후 에러율이 급증했어요!"
- 대응: 수동 롤백 시도 (15분 소요)
- 영향: 긴 복구 시간 동안 고객 이탈
- 비용: 15분 × $694 = $10,410 + 고객 신뢰도 하락

문제 3: 테스트가 불충분한 배포
- 증상: "로컬에서는 됐는데 프로덕션에서 안돼요"
- 대응: 급하게 핫픽스 배포 반복
- 영향: 불안정한 서비스, 개발자 야근
- 비용: 개발자 3명 × 5시간 × $50 = $750
```

#### ✅ 체계적 배포 전략을 적용하면

```
해결책 1: 무중단 배포로 안정성 확보
- 방법: Rolling Update 또는 Blue-Green 배포
- 효과: 다운타임 0분, 사용자 경험 유지
- 절감: 다운타임 비용 100% 절감

해결책 2: 빠른 롤백으로 피해 최소화
- 방법: Blue-Green 배포 (1-2초 내 롤백)
- 효과: 문제 발견 시 즉시 이전 버전으로 복귀
- 절감: 복구 시간 15분 → 10초 (99% 단축)

해결책 3: 점진적 배포로 위험 분산
- 방법: Canary 배포 (5% → 25% → 50% → 100%)
- 효과: 소수 사용자에게 먼저 테스트, 문제 조기 발견
- 절감: 전체 장애 위험 95% 감소
```

### 수치로 보는 효과

| 지표 | Before (무계획 배포) | After (전략적 배포) | 개선율 |
|------|---------------------|-------------------|--------|
| 평균 다운타임 | 10분 | 0분 | **100%↓** |
| 배포 실패율 | 20% | 2% | **90%↓** |
| 평균 복구 시간 (MTTR) | 15분 | 30초 | **97%↓** |
| 배포 빈도 | 주 1회 | 일 5회 | **3500%↑** |
| 사용자 영향 범위 | 100% | 5% (Canary) | **95%↓** |
| 월간 다운타임 비용 | $27,760 | $0 | **100%↓** |

---

## 🔍 실생활 비유로 이해하기

### 비유 1: 항공사의 비행기 교체 전략

```
항공사가 신형 비행기를 도입하는 방법:

┌─────────────────────────────────────────────────────────┐
│ ❌ 위험한 방법: 모든 비행기를 한 번에 교체             │
│                                                         │
│ 1. 오전 6시: 모든 기존 비행기 운항 중단                │
│ 2. 오전 6시~오후 2시: 신형 비행기로 교체 (8시간)      │
│ 3. 오후 2시: 신형 비행기 운항 시작                     │
│                                                         │
│ 문제:                                                   │
│ - 8시간 동안 항공편 전면 중단                          │
│ - 신형 비행기에 문제 발생 시 모든 항공편 마비         │
│ - 승객 불만 폭증, 항공사 신뢰도 추락                  │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│ ✅ 안전한 방법: 점진적 교체 (Rolling Update)           │
│                                                         │
│ 1. 첫째 날: 비행기 1대만 신형으로 교체                 │
│    → 문제 없으면 계속 운항                             │
│ 2. 둘째 날: 2대 추가 교체                              │
│ 3. 한 달간 점진적으로 전체 교체                        │
│                                                         │
│ 장점:                                                   │
│ - 무중단 운항 (승객 불편 없음)                         │
│ - 신형 비행기 문제 발견 시 즉시 중단 가능             │
│ - 기존 비행기로 백업 가능                              │
└─────────────────────────────────────────────────────────┘

Docker 배포도 동일:
기존 컨테이너 = 기존 비행기
새 컨테이너 = 신형 비행기
사용자 트래픽 = 승객
```

### 비유 2: 교량 교체 공사 (Blue-Green 배포)

```
오래된 다리를 새 다리로 교체하는 방법:

┌─────────────────────────────────────────────────────────┐
│ 교량 교체 전략                                          │
│                                                         │
│ 1단계: 기존 다리 (Blue) 운영 중                         │
│    ═══════════════  ← 모든 차량 통행                   │
│    [기존 다리]                                          │
│                                                         │
│ 2단계: 새 다리 (Green) 건설 (운행 중단 없음)           │
│    ═══════════════  ← 차량 통행 계속                   │
│    [기존 다리]                                          │
│    ═══════════════  ← 건설 중                          │
│    [새 다리]                                            │
│                                                         │
│ 3단계: 새 다리 완성 후 테스트                           │
│    ═══════════════  ← 차량 통행 계속                   │
│    [기존 다리]                                          │
│    ═══════════════  ← 테스트 차량만 통과               │
│    [새 다리] ✅                                         │
│                                                         │
│ 4단계: 트래픽 전환 (1-2초)                              │
│    ═══════════════  ← 통행 중단                        │
│    [기존 다리]                                          │
│    ═══════════════  ← 모든 차량 통행 시작              │
│    [새 다리] ✅                                         │
│                                                         │
│ 5단계: 문제 없으면 기존 다리 철거                       │
│    ═══════════════  ← 모든 차량 통행                   │
│    [새 다리] ✅                                         │
└─────────────────────────────────────────────────────────┘

Docker Blue-Green:
- Blue = 현재 운영 중인 컨테이너
- Green = 새 버전 컨테이너
- 로드 밸런서가 트래픽을 Blue → Green으로 즉시 전환
- 문제 발생 시 즉시 Blue로 다시 전환
```

### 비유 3: 신메뉴 출시 (Canary 배포)

```
레스토랑에서 새 메뉴를 출시하는 전략:

┌─────────────────────────────────────────────────────────┐
│ ❌ 위험한 방법: 전체 메뉴를 한 번에 변경               │
│                                                         │
│ 월요일: 모든 메뉴판을 새 메뉴로 교체                   │
│ 결과: 손님들이 새 메뉴를 싫어함 → 매출 급감            │
│       다시 이전 메뉴로 복구하기 어려움                 │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│ ✅ 안전한 방법: 소수 고객부터 테스트 (Canary)          │
│                                                         │
│ 1주차: 5% 고객에게만 새 메뉴 제공                      │
│   → 피드백 수집: "맛있어요!" ✅                        │
│                                                         │
│ 2주차: 25% 고객으로 확대                                │
│   → 피드백: "재료가 부족해요" ⚠️                      │
│   → 재료 공급량 조정                                    │
│                                                         │
│ 3주차: 50% 고객으로 확대                                │
│   → 피드백: "조리 시간이 너무 길어요" ⚠️              │
│   → 조리 프로세스 개선                                  │
│                                                         │
│ 4주차: 100% 전면 출시                                   │
│   → 모든 문제 해결 완료 ✅                             │
│   → 성공적인 신메뉴 출시                                │
└─────────────────────────────────────────────────────────┘

Docker Canary:
- 5% → 25% → 50% → 100%로 점진적 트래픽 증가
- 각 단계에서 에러율, 응답 시간 모니터링
- 문제 발견 시 즉시 중단하고 이전 버전으로 롤백
```

---

## 배포 전략의 종류

### 1. 배포 실패 시나리오 비교

```
❌ 무계획 배포 (All at Once)
===========================

15:00 - 새 버전 배포 시작
15:01 - 모든 서버를 동시에 새 버전으로 교체
15:02 - 치명적인 버그 발견!
15:03 - 모든 사용자가 서비스 이용 불가
15:04 - 긴급 롤백 시도
15:10 - 롤백 완료, 6분간 전체 서비스 중단
결과: 매출 손실, 고객 이탈, 브랜드 이미지 손상 💀


✅ Canary 배포 (점진적)
=======================

15:00 - 새 버전 배포 시작
15:01 - 5%의 트래픽만 새 버전으로 전환
15:02 - 5% 사용자 모니터링 → 버그 발견!
15:03 - 즉시 새 버전 중단
15:04 - 95%의 사용자는 영향 없음
결과: 5%만 잠깐 영향, 빠른 대응, 피해 최소화 ✨
```

### 2. 다운타임의 비용

```
다운타임 비용 계산
=================

가정:
- 일 평균 거래액: $1,000,000
- 1시간 다운타임 비용: $1,000,000 / 24 = $41,667
- 1분 다운타임 비용: $694

시나리오별 비용:
┌─────────────────────┬──────────────┬─────────────┐
│ 배포 전략           │ 다운타임     │ 비용        │
├─────────────────────┼──────────────┼─────────────┤
│ All at Once         │ 5분          │ $3,470      │
│ Rolling Update      │ 0분 (무중단) │ $0          │
│ Blue-Green          │ 30초 (전환)  │ $347        │
│ Canary (버그 발견)  │ 0분 (5%만)   │ ~$0         │
└─────────────────────┴──────────────┴─────────────┘

+ 고객 신뢰도 하락
+ 브랜드 이미지 손상
+ 경쟁사로 이탈
```

---

## 배포 전략의 종류

### 1. 전체 비교

```
┌──────────────────┬──────────────┬───────────┬───────────┬──────────────┐
│ 전략             │ 다운타임     │ 롤백 속도 │ 리소스    │ 복잡도       │
├──────────────────┼──────────────┼───────────┼───────────┼──────────────┤
│ Recreate         │ 있음 (5분+)  │ 느림      │ 1배       │ 낮음         │
│ Rolling Update   │ 없음         │ 느림      │ 1배       │ 중간         │
│ Blue-Green       │ 거의 없음    │ 매우 빠름 │ 2배       │ 중간         │
│ Canary           │ 없음         │ 빠름      │ 1.1배     │ 높음         │
│ A/B Testing      │ 없음         │ 빠름      │ 1.2배     │ 높음         │
└──────────────────┴──────────────┴───────────┴───────────┴──────────────┘
```

---

## 1. Recreate 배포

가장 간단하지만 다운타임이 발생합니다.

### 동작 방식

```
시간 흐름
=========

기존 버전 (v1.0)
┌─────┐ ┌─────┐ ┌─────┐
│ v1  │ │ v1  │ │ v1  │  ← 3개의 컨테이너 실행 중
└─────┘ └─────┘ └─────┘
   |       |       |
   ↓       ↓       ↓
  Stop    Stop    Stop    ← 모두 중지 (다운타임 시작!)
   X       X       X

   ⏳ 다운타임 (5-10분)

   ↓       ↓       ↓
┌─────┐ ┌─────┐ ┌─────┐
│ v2  │ │ v2  │ │ v2  │  ← 새 버전 시작 (다운타임 종료)
└─────┘ └─────┘ └─────┘
```

### docker-compose 예시

```yaml
# docker-compose.yml
version: '3.8'

services:
  user-service:
    image: lk-trade/user-service:${VERSION}
    deploy:
      replicas: 3
      # 기본 전략 (Recreate)
```

```bash
# 배포 명령
export VERSION=2.0.0
docker-compose down
docker-compose pull
docker-compose up -d

# 다운타임: docker-compose down부터 up -d 완료까지
```

### 장단점

```
✅ 장점:
- 구현이 매우 간단
- 버전 충돌 없음 (한 번에 하나의 버전만 실행)
- 리소스 효율적 (추가 서버 불필요)

❌ 단점:
- 다운타임 발생 (5-10분)
- 사용자 경험 저하
- 프로덕션 환경에는 부적합
```

**사용 시나리오:**
- 개발/테스트 환경
- 사용자가 없는 시간대 (새벽)
- 유지보수 창구 (maintenance window) 활용

---

## 2. Rolling Update (순차 배포)

무중단으로 점진적으로 업데이트합니다.

### 동작 방식

```
시간 흐름
=========

초기 상태 (v1.0)
┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐
│ v1  │ │ v1  │ │ v1  │ │ v1  │  (4개 인스턴스)
└─────┘ └─────┘ └─────┘ └─────┘
   ↓
1단계: 하나씩 교체
┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐
│ v2  │ │ v1  │ │ v1  │ │ v1  │  ← 1개 업데이트
└─────┘ └─────┘ └─────┘ └─────┘
   ↓
2단계
┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐
│ v2  │ │ v2  │ │ v1  │ │ v1  │  ← 2개 업데이트
└─────┘ └─────┘ └─────┘ └─────┘
   ↓
3단계
┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐
│ v2  │ │ v2  │ │ v2  │ │ v1  │  ← 3개 업데이트
└─────┘ └─────┘ └─────┘ └─────┘
   ↓
완료
┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐
│ v2  │ │ v2  │ │ v2  │ │ v2  │  ← 모두 업데이트
└─────┘ └─────┘ └─────┘ └─────┘

✅ 전체 과정에서 다운타임 없음!
```

### Docker Swarm으로 Rolling Update

```bash
# Swarm 초기화
docker swarm init

# Stack 배포
docker stack deploy -c docker-stack.yml lk-trade
```

```yaml
# docker-stack.yml
version: '3.8'

services:
  user-service:
    image: lk-trade/user-service:${VERSION:-latest}
    deploy:
      replicas: 4
      update_config:
        parallelism: 1        # 한 번에 1개씩 업데이트
        delay: 10s            # 각 업데이트 사이 대기 시간
        failure_action: rollback  # 실패 시 자동 롤백
        monitor: 60s          # 모니터링 시간
        max_failure_ratio: 0.25   # 25% 실패 시 롤백
        order: stop-first     # 기존 컨테이너 중지 후 새 컨테이너 시작
      rollback_config:
        parallelism: 1
        delay: 10s
        failure_action: pause
        monitor: 60s
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 40s
    networks:
      - lk-trade-network

networks:
  lk-trade-network:
    driver: overlay
```

### 배포 및 모니터링

```bash
# 새 버전 배포
export VERSION=2.0.0
docker stack deploy -c docker-stack.yml lk-trade

# 배포 진행 상황 모니터링
watch -n 1 'docker service ps lk-trade_user-service'

# 출력:
ID            NAME                         IMAGE                    NODE    DESIRED STATE  CURRENT STATE
abc123...     lk-trade_user-service.1      lk-trade/user-service:2.0.0  node1   Running        Running 30 seconds ago
def456...     lk-trade_user-service.2      lk-trade/user-service:2.0.0  node1   Running        Running 20 seconds ago
ghi789...     lk-trade_user-service.3      lk-trade/user-service:2.0.0  node1   Running        Running 10 seconds ago
jkl012...     lk-trade_user-service.4      lk-trade/user-service:1.0.0  node1   Shutdown       Shutdown 5 seconds ago

# 서비스 상태 확인
docker service ls
docker service logs -f lk-trade_user-service

# 롤백 (문제 발생 시)
docker service rollback lk-trade_user-service

# 또는 이전 버전으로 재배포
export VERSION=1.0.0
docker stack deploy -c docker-stack.yml lk-trade
```

### 장단점

```
✅ 장점:
- 무중단 배포 (Zero Downtime)
- 점진적 업데이트로 위험 분산
- 자동 헬스체크 및 롤백
- 추가 리소스 불필요

❌ 단점:
- 배포 시간이 김 (전체 업데이트까지)
- v1과 v2가 동시에 실행됨 (호환성 필요)
- 롤백이 느림 (다시 rolling)
```

**사용 시나리오:**
- 일반적인 프로덕션 배포
- 리소스가 제한적인 환경
- 버전 간 호환성이 보장되는 경우

---

## 3. Blue-Green 배포

두 개의 동일한 환경을 운영하고 즉시 전환합니다.

### 동작 방식

```
Blue (기존 환경, v1.0)          Green (새 환경, v2.0)
=========================        =========================

┌───────────────────────┐        ┌───────────────────────┐
│ Load Balancer         │        │                       │
│   ↓                   │        │                       │
│ Blue Environment      │        │ Green Environment     │
│ ┌─────┐ ┌─────┐      │        │ ┌─────┐ ┌─────┐      │
│ │ v1  │ │ v1  │      │        │ │ v2  │ │ v2  │      │
│ └─────┘ └─────┘      │        │ └─────┘ └─────┘      │
│   ↑                   │        │                       │
│ 100% 트래픽           │        │ 0% 트래픽             │
└───────────────────────┘        └───────────────────────┘

            ↓ 테스트 완료, 전환 준비

┌───────────────────────┐        ┌───────────────────────┐
│ Load Balancer         │        │                       │
│       ↓               │        │                       │
│ Blue Environment      │        │ Green Environment     │
│ ┌─────┐ ┌─────┐      │        │ ┌─────┐ ┌─────┐      │
│ │ v1  │ │ v1  │      │        │ │ v2  │ │ v2  │      │
│ └─────┘ └─────┘      │        │ └─────┘ └─────┘      │
│                       │        │   ↑                   │
│ 0% 트래픽             │        │ 100% 트래픽           │
└───────────────────────┘        └───────────────────────┘

            ↓ 문제 없으면 Blue 환경 종료

┌───────────────────────┐
│ Green Environment     │
│ ┌─────┐ ┌─────┐      │
│ │ v2  │ │ v2  │      │
│ └─────┘ └─────┘      │
│   ↑                   │
│ 100% 트래픽           │
└───────────────────────┘

            ↓ Green이 이제 Blue가 됨
```

### Nginx를 이용한 Blue-Green 배포

```yaml
# docker-compose.blue-green.yml
version: '3.8'

services:
  # Nginx 로드 밸런서
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/upstream.conf:/etc/nginx/conf.d/upstream.conf:ro
    networks:
      - lk-trade-network
    depends_on:
      - user-service-blue
      - user-service-green

  # Blue 환경 (현재 운영)
  user-service-blue:
    image: lk-trade/user-service:1.0.0
    container_name: user-service-blue
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - DEPLOYMENT_COLOR=blue
    networks:
      - lk-trade-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "http://localhost:8080/actuator/health"]
      interval: 10s
      timeout: 3s
      retries: 3

  # Green 환경 (새 버전)
  user-service-green:
    image: lk-trade/user-service:2.0.0
    container_name: user-service-green
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - DEPLOYMENT_COLOR=green
    networks:
      - lk-trade-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "http://localhost:8080/actuator/health"]
      interval: 10s
      timeout: 3s
      retries: 3

networks:
  lk-trade-network:
    driver: bridge
```

```nginx
# nginx/upstream.conf (초기 상태: Blue)
upstream user_service {
    server user-service-blue:8080 max_fails=3 fail_timeout=30s;
    # server user-service-green:8080 max_fails=3 fail_timeout=30s;
}

server {
    listen 80;

    location / {
        proxy_pass http://user_service;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # 헬스 체크 응답 시간 초과 설정
        proxy_connect_timeout 2s;
        proxy_send_timeout 2s;
        proxy_read_timeout 2s;
    }

    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
}
```

### Blue-Green 전환 스크립트

```bash
#!/bin/bash
# scripts/blue-green-deploy.sh

set -e

CURRENT_ENV=${1:-blue}
NEW_ENV=${2:-green}

if [ "$CURRENT_ENV" != "blue" ] && [ "$CURRENT_ENV" != "green" ]; then
    echo "❌ Invalid environment. Use 'blue' or 'green'"
    exit 1
fi

if [ "$CURRENT_ENV" == "blue" ]; then
    NEW_ENV="green"
else
    NEW_ENV="blue"
fi

echo "
╔═══════════════════════════════════════════════════╗
║   Blue-Green Deployment                           ║
╚═══════════════════════════════════════════════════╝

Current Environment: $CURRENT_ENV
New Environment:     $NEW_ENV
"

# 1. 새 환경 헬스 체크
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo "1️⃣  Health Check: $NEW_ENV environment"
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

MAX_RETRIES=30
RETRY=0

while [ $RETRY -lt $MAX_RETRIES ]; do
    if docker exec user-service-$NEW_ENV wget -q --spider http://localhost:8080/actuator/health; then
        echo "✅ $NEW_ENV environment is healthy"
        break
    fi
    RETRY=$((RETRY+1))
    echo "⏳ Waiting for $NEW_ENV to be ready... ($RETRY/$MAX_RETRIES)"
    sleep 2
done

if [ $RETRY -eq $MAX_RETRIES ]; then
    echo "❌ $NEW_ENV environment health check failed"
    exit 1
fi

# 2. 스모크 테스트
echo ""
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo "2️⃣  Smoke Tests"
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

# 기본 API 테스트
if ! docker exec user-service-$NEW_ENV wget -q -O- http://localhost:8080/actuator/info > /dev/null; then
    echo "❌ Smoke test failed"
    exit 1
fi

echo "✅ Smoke tests passed"

# 3. 트래픽 전환
echo ""
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo "3️⃣  Traffic Switch"
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

read -p "Switch traffic to $NEW_ENV? (yes/no): " CONFIRM
if [ "$CONFIRM" != "yes" ]; then
    echo "Deployment cancelled"
    exit 0
fi

# Nginx 설정 변경
cat > nginx/upstream.conf <<EOF
upstream user_service {
    server user-service-$NEW_ENV:8080 max_fails=3 fail_timeout=30s;
    # server user-service-$CURRENT_ENV:8080 max_fails=3 fail_timeout=30s;
}

server {
    listen 80;

    location / {
        proxy_pass http://user_service;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;

        proxy_connect_timeout 2s;
        proxy_send_timeout 2s;
        proxy_read_timeout 2s;
    }
}
EOF

# Nginx 재시작
docker exec nginx nginx -s reload
echo "✅ Traffic switched to $NEW_ENV"

# 4. 모니터링
echo ""
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo "4️⃣  Monitoring (60 seconds)"
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo "Press Ctrl+C to stop monitoring and rollback"
echo ""

for i in {1..60}; do
    if ! docker exec user-service-$NEW_ENV wget -q --spider http://localhost:8080/actuator/health; then
        echo ""
        echo "❌ Health check failed during monitoring!"
        echo "🔄 Rolling back to $CURRENT_ENV..."

        # 롤백
        cat > nginx/upstream.conf <<EOF
upstream user_service {
    server user-service-$CURRENT_ENV:8080 max_fails=3 fail_timeout=30s;
}

server {
    listen 80;
    location / {
        proxy_pass http://user_service;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
    }
}
EOF
        docker exec nginx nginx -s reload
        echo "✅ Rolled back to $CURRENT_ENV"
        exit 1
    fi
    echo -n "."
    sleep 1
done

echo ""
echo ""
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo "5️⃣  Cleanup"
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

read -p "Stop $CURRENT_ENV environment? (yes/no): " CLEANUP
if [ "$CLEANUP" == "yes" ]; then
    docker-compose stop user-service-$CURRENT_ENV
    echo "✅ $CURRENT_ENV environment stopped"
else
    echo "⚠️  $CURRENT_ENV environment is still running"
    echo "   You can manually stop it later with:"
    echo "   docker-compose stop user-service-$CURRENT_ENV"
fi

echo ""
echo "✅ Blue-Green deployment completed successfully!"
echo ""
echo "Current active environment: $NEW_ENV"
```

### 사용 방법

```bash
# 1. 초기 상태: Blue 운영 중
docker-compose -f docker-compose.blue-green.yml up -d user-service-blue nginx

# 2. Green 환경에 새 버전 배포
docker-compose -f docker-compose.blue-green.yml up -d user-service-green

# 3. Blue → Green 전환
bash scripts/blue-green-deploy.sh blue

# 4. 문제 발생 시 즉시 롤백 (Green → Blue)
bash scripts/blue-green-rollback.sh green
```

### 장단점

```
✅ 장점:
- 거의 즉시 전환 (1-2초)
- 매우 빠른 롤백 (1-2초)
- 프로덕션과 동일한 환경에서 테스트 가능
- v1과 v2가 격리됨

❌ 단점:
- 리소스 2배 필요
- 데이터베이스 마이그레이션 복잡
- 인프라 비용 증가
```

**사용 시나리오:**
- 중요한 프로덕션 배포
- 빠른 롤백이 필수인 경우
- 리소스가 충분한 환경

---

## 4. Canary 배포

소수의 사용자에게 먼저 배포하여 테스트합니다.

### 동작 방식

```
시간 흐름
=========

초기: 5% Canary
┌───────────────────────────────────────────────┐
│ Load Balancer                                 │
│                                               │
│  5% ──→ ┌─────┐  Canary (v2.0)              │
│         │ v2  │                               │
│         └─────┘                               │
│                                               │
│ 95% ──→ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐     │
│         │ v1  │ │ v1  │ │ v1  │ │ v1  │     │
│         └─────┘ └─────┘ └─────┘ └─────┘     │
└───────────────────────────────────────────────┘

    ↓ 모니터링 (15분) → 문제 없음

25% Canary
┌───────────────────────────────────────────────┐
│ 25% ──→ ┌─────┐ ┌─────┐  Canary (v2.0)       │
│         │ v2  │ │ v2  │                       │
│         └─────┘ └─────┘                       │
│                                               │
│ 75% ──→ ┌─────┐ ┌─────┐ ┌─────┐              │
│         │ v1  │ │ v1  │ │ v1  │              │
│         └─────┘ └─────┘ └─────┘              │
└───────────────────────────────────────────────┘

    ↓ 모니터링 (15분) → 문제 없음

50% Canary
┌───────────────────────────────────────────────┐
│ 50% ──→ ┌─────┐ ┌─────┐ ┌─────┐              │
│         │ v2  │ │ v2  │ │ v2  │              │
│         └─────┘ └─────┘ └─────┘              │
│                                               │
│ 50% ──→ ┌─────┐ ┌─────┐                      │
│         │ v1  │ │ v1  │                      │
│         └─────┘ └─────┘                      │
└───────────────────────────────────────────────┘

    ↓ 모니터링 (15분) → 문제 없음

100% 전환
┌───────────────────────────────────────────────┐
│100% ──→ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐      │
│         │ v2  │ │ v2  │ │ v2  │ │ v2  │      │
│         └─────┘ └─────┘ └─────┘ └─────┘      │
└───────────────────────────────────────────────┘
```

### Traefik을 이용한 Canary 배포

```yaml
# docker-compose.canary.yml
version: '3.8'

services:
  # Traefik (로드 밸런서)
  traefik:
    image: traefik:v2.10
    command:
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
    ports:
      - "80:80"
      - "8080:8080"  # Traefik 대시보드
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - lk-trade-network

  # Stable 버전 (v1.0)
  user-service-stable:
    image: lk-trade/user-service:1.0.0
    deploy:
      replicas: 4
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.user-stable.rule=Host(`api.lk-trade.com`)"
        - "traefik.http.services.user-stable.loadbalancer.server.port=8080"
        - "traefik.http.services.user-stable.loadbalancer.sticky.cookie=true"
        # 가중치: 95%
        - "traefik.http.services.user-stable.loadbalancer.weight=95"
    networks:
      - lk-trade-network

  # Canary 버전 (v2.0)
  user-service-canary:
    image: lk-trade/user-service:2.0.0
    deploy:
      replicas: 1
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.user-canary.rule=Host(`api.lk-trade.com`)"
        - "traefik.http.services.user-canary.loadbalancer.server.port=8080"
        - "traefik.http.services.user-canary.loadbalancer.sticky.cookie=true"
        # 가중치: 5%
        - "traefik.http.services.user-canary.loadbalancer.weight=5"
    networks:
      - lk-trade-network

networks:
  lk-trade-network:
    driver: overlay
```

### Canary 배포 자동화 스크립트

```bash
#!/bin/bash
# scripts/canary-deploy.sh

set -e

NEW_VERSION=$1
CANARY_PERCENTAGES=(5 25 50 100)
MONITORING_DURATION=900  # 15분 (초)

if [ -z "$NEW_VERSION" ]; then
    echo "Usage: $0 <new-version>"
    echo "Example: $0 2.0.0"
    exit 1
fi

echo "
╔═══════════════════════════════════════════════════╗
║   Canary Deployment                               ║
╚═══════════════════════════════════════════════════╝

New Version: $NEW_VERSION
Canary Stages: ${CANARY_PERCENTAGES[@]}%
Monitoring Duration: $MONITORING_DURATION seconds per stage
"

# Prometheus 메트릭 체크 함수
check_metrics() {
    local version=$1

    # 에러율 체크
    ERROR_RATE=$(curl -s "http://localhost:9090/api/v1/query?query=rate(http_requests_total{status=~\"5..\",version=\"$version\"}[5m])" | jq -r '.data.result[0].value[1] // 0')

    # 응답 시간 체크
    AVG_RESPONSE_TIME=$(curl -s "http://localhost:9090/api/v1/query?query=histogram_quantile(0.95,http_request_duration_seconds{version=\"$version\"})" | jq -r '.data.result[0].value[1] // 0')

    echo "  Error Rate: $ERROR_RATE"
    echo "  P95 Response Time: ${AVG_RESPONSE_TIME}s"

    # 임계값 체크
    if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
        echo "  ❌ Error rate too high (>1%)"
        return 1
    fi

    if (( $(echo "$AVG_RESPONSE_TIME > 1.0" | bc -l) )); then
        echo "  ❌ Response time too slow (>1s)"
        return 1
    fi

    return 0
}

# Canary 단계별 배포
for PERCENTAGE in "${CANARY_PERCENTAGES[@]}"; do
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo "🚀 Deploying Canary: $PERCENTAGE%"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

    # 가중치 계산
    STABLE_WEIGHT=$((100 - PERCENTAGE))
    CANARY_WEIGHT=$PERCENTAGE

    # Docker Compose 파일 업데이트
    cat > docker-compose.canary-weights.yml <<EOF
version: '3.8'

services:
  user-service-stable:
    image: lk-trade/user-service:1.0.0
    deploy:
      labels:
        - "traefik.http.services.user-stable.loadbalancer.weight=$STABLE_WEIGHT"

  user-service-canary:
    image: lk-trade/user-service:$NEW_VERSION
    deploy:
      labels:
        - "traefik.http.services.user-canary.loadbalancer.weight=$CANARY_WEIGHT"
EOF

    # 배포
    docker stack deploy -c docker-compose.canary.yml -c docker-compose.canary-weights.yml lk-trade

    echo "⏳ Monitoring for $MONITORING_DURATION seconds..."

    # 모니터링
    ELAPSED=0
    while [ $ELAPSED -lt $MONITORING_DURATION ]; do
        sleep 30
        ELAPSED=$((ELAPSED + 30))

        echo ""
        echo "[$ELAPSED/${MONITORING_DURATION}s] Checking metrics..."

        if ! check_metrics "$NEW_VERSION"; then
            echo ""
            echo "❌ Canary deployment failed at $PERCENTAGE%"
            echo "🔄 Rolling back..."

            # 롤백
            docker stack deploy -c docker-compose.stable-only.yml lk-trade

            echo "✅ Rolled back to stable version"
            exit 1
        fi

        echo "  ✅ Metrics OK"
    done

    echo ""
    echo "✅ Canary $PERCENTAGE% successful"
    echo ""

    if [ $PERCENTAGE -ne 100 ]; then
        read -p "Continue to next stage? (yes/no): " CONTINUE
        if [ "$CONTINUE" != "yes" ]; then
            echo "Deployment paused at $PERCENTAGE%"
            exit 0
        fi
    fi
done

echo "
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
✅ Canary deployment completed successfully!
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Version $NEW_VERSION is now serving 100% of traffic.
"
```

### 장단점

```
✅ 장점:
- 위험 최소화 (소수 사용자만 영향)
- 실제 사용자 환경에서 테스트
- 점진적 트래픽 증가
- 빠른 문제 감지 및 롤백

❌ 단점:
- 구현 복잡도 높음
- 모니터링 필수
- 배포 시간 김 (단계별 모니터링)
- 인프라 복잡성 증가
```

**사용 시나리오:**
- 중대한 변경 사항
- 새로운 기능 출시
- 대규모 사용자 대상 서비스

---

## 5. A/B Testing

비즈니스 메트릭 기반으로 두 버전을 비교합니다.

### Canary vs A/B Testing

```
┌─────────────────┬───────────────────┬──────────────────┐
│                 │ Canary            │ A/B Testing      │
├─────────────────┼───────────────────┼──────────────────┤
│ 목적            │ 안정성 검증       │ 비즈니스 검증    │
│ 사용자 선택     │ 랜덤              │ 의도적 그룹 분리 │
│ 모니터링 지표   │ 에러율, 응답시간  │ 전환율, 매출     │
│ 기간            │ 짧음 (분~시간)    │ 길음 (일~주)     │
│ 최종 결정       │ 자동 (메트릭)     │ 수동 (비즈니스)  │
└─────────────────┴───────────────────┴──────────────────┘
```

### 구현 예시

```yaml
# docker-compose.ab-testing.yml
version: '3.8'

services:
  traefik:
    image: traefik:v2.10
    command:
      - "--providers.docker=true"
      - "--entrypoints.web.address=:80"
    ports:
      - "80:80"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - lk-trade-network

  # 버전 A (기존 UI)
  frontend-a:
    image: lk-trade/frontend:1.0.0-old-ui
    deploy:
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.frontend-a.rule=Host(`lk-trade.com`) && Header(`X-AB-Test`, `A`)"
        - "traefik.http.services.frontend-a.loadbalancer.server.port=80"
        - "traefik.http.middlewares.ab-test-a.headers.customrequestheaders.X-AB-Group=A"
    environment:
      - AB_TEST_GROUP=A
      - FEATURE_NEW_CHECKOUT=false
    networks:
      - lk-trade-network

  # 버전 B (새 UI)
  frontend-b:
    image: lk-trade/frontend:2.0.0-new-ui
    deploy:
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.frontend-b.rule=Host(`lk-trade.com`) && Header(`X-AB-Test`, `B`)"
        - "traefik.http.services.frontend-b.loadbalancer.server.port=80"
        - "traefik.http.middlewares.ab-test-b.headers.customrequestheaders.X-AB-Group=B"
    environment:
      - AB_TEST_GROUP=B
      - FEATURE_NEW_CHECKOUT=true
    networks:
      - lk-trade-network

networks:
  lk-trade-network:
    driver: overlay
```

사용자를 그룹별로 분리:

```javascript
// frontend/ab-test.js
function getABTestGroup() {
    // 쿠키에서 그룹 확인
    let group = getCookie('ab_test_group');

    if (!group) {
        // 50/50 랜덤 배정
        group = Math.random() < 0.5 ? 'A' : 'B';
        setCookie('ab_test_group', group, 30);  // 30일
    }

    return group;
}

// API 요청 시 헤더 추가
fetch('/api/orders', {
    headers: {
        'X-AB-Test': getABTestGroup()
    }
});

// 이벤트 트래킹
function trackEvent(eventName, data) {
    analytics.track(eventName, {
        ...data,
        ab_test_group: getABTestGroup(),
        timestamp: new Date().toISOString()
    });
}

// 예: 체크아웃 완료 트래킹
trackEvent('checkout_completed', {
    order_id: orderId,
    amount: orderAmount
});
```

---

## 6. LK-Trade 프로젝트 배포 전략

### 권장 전략

```
서비스별 배포 전략
=================

┌────────────────────┬──────────────────┬─────────────┐
│ 서비스             │ 배포 전략        │ 이유        │
├────────────────────┼──────────────────┼─────────────┤
│ user-service       │ Blue-Green       │ 중요도 높음 │
│ trade-service      │ Canary           │ 위험도 높음 │
│ account-service    │ Rolling Update   │ 일반적      │
│ strategy-service   │ Rolling Update   │ 일반적      │
│ notification       │ Recreate         │ 중요도 낮음 │
│ admin              │ Recreate         │ 사용자 적음 │
└────────────────────┴──────────────────┴─────────────┘
```

### Makefile 통합

```makefile
# Makefile
.PHONY: deploy-blue-green deploy-canary deploy-rolling

# Blue-Green 배포
deploy-blue-green:
	@echo "🔵🟢 Blue-Green Deployment"
	@read -p "Enter service name: " service; \
	read -p "Enter new version: " version; \
	bash scripts/blue-green-deploy.sh $$service $$version

# Canary 배포
deploy-canary:
	@echo "🐤 Canary Deployment"
	@read -p "Enter service name: " service; \
	read -p "Enter new version: " version; \
	bash scripts/canary-deploy.sh $$service $$version

# Rolling Update
deploy-rolling:
	@echo "🔄 Rolling Update"
	@read -p "Enter service name: " service; \
	read -p "Enter new version: " version; \
	export VERSION=$$version && docker stack deploy -c docker-stack.yml lk-trade

# 롤백
rollback:
	@echo "⏪ Rollback"
	@read -p "Enter service name: " service; \
	docker service rollback lk-trade_$$service

# 배포 상태 확인
deploy-status:
	@docker service ls
	@echo ""
	@docker service ps lk-trade_user-service --format "table {{.Name}}\t{{.Image}}\t{{.CurrentState}}"
```

---

## 👨‍💻 주니어 개발자 시나리오

### 시나리오 1: 첫 프로덕션 배포 - 전체 서비스 다운

**상황**:
```
주니어 A의 첫 프로덕션 배포
팀장: "user-service 2.0 버전 프로덕션 배포 부탁해요"
주니어 A: "네! (두근두근)"

15:00 - docker-compose down
15:01 - docker-compose pull
15:02 - docker-compose up -d
15:03 - 슬랙에 알림 폭주: "서비스 안돼요!"
15:04 - 팀장: "왜 전체 서비스가 다운됐죠?"
주니어 A: (식은땀) "...docker-compose down 하면 안됐나요?"
```

**문제점**:
- `docker-compose down`: 모든 컨테이너 중지 → 전체 다운타임
- 새 버전에 버그 있을 경우 모든 사용자 영향
- 롤백에도 시간 소요

**올바른 해결**:
```bash
# ❌ 잘못된 방법
docker-compose down  # 전체 서비스 중단!
docker-compose up -d

# ✅ 올바른 방법 1: Rolling Update (Docker Swarm)
docker stack deploy -c docker-stack.yml lk-trade
# → 자동으로 하나씩 업데이트, 무중단 배포

# ✅ 올바른 방법 2: Blue-Green 배포
bash scripts/blue-green-deploy.sh
# → 새 버전 준비 후 즉시 전환, 롤백 용이

# ✅ 올바른 방법 3: 서비스별 개별 업데이트
docker-compose up -d --no-deps user-service
# → user-service만 업데이트, 다른 서비스는 계속 운영
```

**배운 점**:
- 프로덕션 배포는 절대 `docker-compose down` 사용 금지
- Rolling Update나 Blue-Green 배포 사용
- 배포 전 반드시 팀장/시니어에게 리뷰 받기

---

### 시나리오 2: 배포 후 버그 발견 - 빠른 롤백

**상황**:
```
주니어 B: Blue-Green 배포 시도

15:00 - Green 환경에 v2.0 배포 완료
15:05 - Blue → Green 트래픽 전환
15:06 - 모니터링: "에러율 급증!"
        에러율: 0.1% → 5% (50배 증가)
15:07 - 주니어 B (당황): "어떻게 하죠?!"
시니어: "침착하게 롤백하세요"
```

**단계별 해결**:
```bash
# Step 1: 즉시 Green → Blue 롤백 (10초 소요)
# nginx/upstream.conf 수정
upstream user_service {
    server user-service-blue:8080;  # Green → Blue로 복귀
}

# Nginx 재시작
docker exec nginx nginx -s reload

# Step 2: 확인
curl http://localhost/health
# {"status":"UP","version":"1.0"}  ← v1.0으로 복귀

# Step 3: Green 환경에서 로그 확인
docker logs user-service-green | grep ERROR

# 출력:
# NullPointerException at AccountController.getBalance()
# 아하! v2.0의 버그 발견

# Step 4: 버그 수정 후 재배포
# 코드 수정 → v2.1로 다시 Green 배포 → 테스트 → 전환
```

**배운 점**:
- Blue-Green 배포는 롤백이 매우 빠름 (10초 이내)
- 배포 후 최소 30-60분 모니터링 필수
- 에러율, 응답 시간, CPU/메모리 사용률 확인

---

### 시나리오 3: Canary 배포로 위험 최소화

**상황**:
```
주니어 C: 대규모 리팩토링 후 배포 (두려움 가득)

"이번 업데이트는 핵심 로직을 많이 바꿨어요.
 한 번에 전체 배포하기엔 너무 위험해요..."

시니어: "Canary 배포를 해보세요. 5%부터 시작하면 돼요."
```

**단계별 실행**:
```bash
# Step 1: 5% Canary 배포
cat > docker-compose.canary.yml <<EOF
services:
  user-service-stable:
    image: user-service:1.0
    deploy:
      replicas: 19  # 95%

  user-service-canary:
    image: user-service:2.0
    deploy:
      replicas: 1   # 5%
EOF

docker stack deploy -c docker-compose.canary.yml lk-trade

# Step 2: 15분간 모니터링
echo "Monitoring Canary 5%..."
for i in {1..15}; do
    ERROR_RATE=$(docker stats user-service-canary --no-stream | grep user-service-canary)
    echo "$i분: $ERROR_RATE"
    sleep 60
done

# Step 3: 문제 없으면 25%로 확대
docker service scale lk-trade_user-service-canary=5
docker service scale lk-trade_user-service-stable=15

# Step 4: 계속 모니터링 후 50%, 100%로 확대
```

**배운 점**:
- 대규모 변경은 Canary 배포 필수
- 각 단계마다 충분한 모니터링 시간 확보
- 문제 발견 시 Canary만 중단하면 95%는 안전

---

### 시나리오 4: 배포 전략 선택 실수

**상황**:
```
주니어 D: 개발 환경에서 사용하던 방식을 프로덕션에 그대로 적용

# 개발 환경 (문제 없음)
docker-compose down
docker-compose up -d

# 프로덕션 환경 (큰 문제!)
docker-compose -f docker-compose.prod.yml down  # ← 전체 서비스 중단!
docker-compose -f docker-compose.prod.yml up -d

결과: 5분간 전체 서비스 다운타임
팀장: "왜 프로덕션에서 down을 사용했나요?"
```

**환경별 올바른 배포 방식**:
```
┌─────────────┬──────────────────┬─────────────────┐
│ 환경        │ 배포 방식        │ 다운타임        │
├─────────────┼──────────────────┼─────────────────┤
│ 로컬 개발   │ docker-compose   │ OK (혼자 사용)  │
│             │ down & up        │                 │
├─────────────┼──────────────────┼─────────────────┤
│ 개발 서버   │ docker-compose   │ OK (개발팀만)   │
│             │ up -d --build    │                 │
├─────────────┼──────────────────┼─────────────────┤
│ 스테이징    │ Rolling Update   │ 권장 (무중단)   │
│             │ 또는 Blue-Green  │                 │
├─────────────┼──────────────────┼─────────────────┤
│ 프로덕션    │ Blue-Green       │ 필수 (무중단)   │
│             │ 또는 Canary      │                 │
└─────────────┴──────────────────┴─────────────────┘
```

**배운 점**:
- 개발 환경과 프로덕션 환경은 배포 방식이 다름
- 프로덕션에서는 무중단 배포 필수
- 배포 전 항상 환경 확인 (`echo $ENV`)

---

## ❓ FAQ

<details>
<summary><strong>Q1: Rolling Update와 Blue-Green 중 어떤 것을 선택해야 하나요?</strong></summary>

**A**: **리소스와 롤백 속도 요구사항**에 따라 선택하세요.

**상세 설명**:

**Rolling Update 선택 기준**:
```
✅ 선택하는 경우:
- 리소스가 제한적인 경우 (서버 비용 절감)
- 배포 빈도가 높은 경우 (일 10회+)
- 버전 간 호환성이 보장되는 경우
- 롤백이 3-5분 이내면 OK

예: 일반적인 마이크로서비스, 작은 업데이트
```

**Blue-Green 선택 기준**:
```
✅ 선택하는 경우:
- 즉시 롤백이 필요한 경우 (금융, 결제 서비스)
- 리소스가 충분한 경우 (서버 2배)
- 대규모 변경 사항
- 프로덕션과 동일한 환경에서 사전 테스트 필요

예: 결제 서비스, 중요 API, 대규모 DB 마이그레이션 포함 배포
```

**실전 비교**:
```bash
# 시나리오: user-service 배포 (4개 인스턴스)

Rolling Update:
- 리소스: 4개 인스턴스 (기존과 동일)
- 배포 시간: 5분 (하나씩 업데이트)
- 롤백 시간: 5분 (다시 하나씩 되돌림)
- 비용: $0 (추가 리소스 없음)

Blue-Green:
- 리소스: 8개 인스턴스 (Blue 4개 + Green 4개)
- 배포 시간: 2분 (Green 준비 + 전환)
- 롤백 시간: 10초 (트래픽만 전환)
- 비용: $100/월 (서버 2배 사용 기간 동안)
```

**Best Practice**:
- **일반적인 배포**: Rolling Update
- **중요한 배포**: Blue-Green
- **매우 중요한 배포**: Canary → Blue-Green 조합

</details>

<details>
<summary><strong>Q2: Canary 배포 시 몇 퍼센트부터 시작해야 하나요?</strong></summary>

**A**: **5%에서 시작하여 25% → 50% → 100%로 진행**하는 것이 일반적입니다.

**상세 설명**:

**Canary 비율 결정 기준**:
```
사용자 규모에 따른 Canary 시작 비율:

┌────────────────┬──────────────┬─────────────┐
│ 일일 사용자 수 │ 시작 비율    │ 영향 사용자 │
├────────────────┼──────────────┼─────────────┤
│ 1,000명        │ 10%          │ 100명       │
│ 10,000명       │ 5%           │ 500명       │
│ 100,000명      │ 1%           │ 1,000명     │
│ 1,000,000명+   │ 0.1-1%       │ 1,000-10k명 │
└────────────────┴──────────────┴─────────────┘

원칙: 최소 100-1,000명의 사용자에게 테스트
```

**일반적인 Canary 단계**:
```
┌───────┬──────────┬──────────────┬─────────────┐
│ 단계  │ 비율     │ 모니터링 시간│ 목적        │
├───────┼──────────┼──────────────┼─────────────┤
│ 1단계 │ 5%       │ 15-30분      │ 기본 검증   │
│ 2단계 │ 25%      │ 15-30분      │ 부하 검증   │
│ 3단계 │ 50%      │ 15-30분      │ 대규모 검증 │
│ 4단계 │ 100%     │ 1-2시간      │ 전체 배포   │
└───────┴──────────┴──────────────┴─────────────┘

총 소요 시간: 2-3시간
```

**변경 규모에 따른 조정**:
```
작은 변경 (버그 수정, 마이너 업데이트):
5% → 50% → 100%
모니터링: 각 10분
총 시간: 30분

중간 변경 (새 기능 추가):
5% → 25% → 50% → 100%
모니터링: 각 15분
총 시간: 1시간

큰 변경 (대규모 리팩토링):
1% → 5% → 10% → 25% → 50% → 100%
모니터링: 각 30분
총 시간: 3시간
```

**자동화 예시**:
```bash
#!/bin/bash
# scripts/canary-deploy.sh

PERCENTAGES=(5 25 50 100)
MONITOR_TIME=900  # 15분

for percent in "${PERCENTAGES[@]}"; do
    echo "Deploying Canary: $percent%"

    # 트래픽 비율 조정
    adjust_traffic_weight $percent

    # 모니터링
    for ((i=0; i<$MONITOR_TIME; i+=30)); do
        ERROR_RATE=$(get_error_rate)
        if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
            echo "Error rate too high! Rolling back..."
            rollback_canary
            exit 1
        fi
        sleep 30
    done

    echo "Canary $percent% successful"
done
```

**핵심**:
- 시작 비율: 5% (사용자 10만명 이하)
- 각 단계: 15-30분 모니터링
- 자동 롤백 기준 설정 (에러율 > 1%)

</details>

<details>
<summary><strong>Q3: Blue-Green 배포 시 데이터베이스 마이그레이션은 어떻게 처리하나요?</strong></summary>

**A**: **하위 호환성을 유지하면서 단계적으로 마이그레이션**해야 합니다.

**상세 설명**:

**문제 상황**:
```
Blue (v1.0): users 테이블에 `name` 컬럼 사용
Green (v2.0): `name` 컬럼을 `first_name`, `last_name`으로 분리

문제:
1. Green 배포 전 DB 마이그레이션하면 Blue가 동작 안 함
2. Green 배포 후 DB 마이그레이션하면 Green이 동작 안 함
```

**해결 방법: 3단계 마이그레이션**:

```
┌─────────────────────────────────────────────────────┐
│ 1단계: 컬럼 추가 (하위 호환성 유지)                │
│                                                     │
│ Migration v1:                                       │
│   ALTER TABLE users ADD COLUMN first_name VARCHAR; │
│   ALTER TABLE users ADD COLUMN last_name VARCHAR;  │
│   -- 기존 name 컬럼 유지!                          │
│                                                     │
│ 상태:                                               │
│   Blue (v1.0): name 사용 (여전히 동작)             │
│   DB: name, first_name, last_name 모두 존재        │
└─────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────┐
│ 2단계: Green (v2.0) 배포                            │
│                                                     │
│ Green 코드:                                         │
│   - first_name, last_name 사용                     │
│   - name 컬럼 읽기 지원 (fallback)                 │
│                                                     │
│ Blue → Green 트래픽 전환                            │
│   - 문제 없으면 Green으로 완전 전환                │
│   - 문제 있으면 Blue로 즉시 롤백 가능              │
└─────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────┐
│ 3단계: 기존 컬럼 제거 (충분한 시간 후)             │
│                                                     │
│ Green 배포 후 1-2주 뒤:                             │
│   Migration v2:                                     │
│   ALTER TABLE users DROP COLUMN name;              │
│                                                     │
│ 이제 Green (v2.0)만 사용하므로 안전               │
└─────────────────────────────────────────────────────┘
```

**코드 예시**:

**v1.5 (중간 버전): 두 방식 모두 지원**
```kotlin
// User.kt (v1.5)
@Entity
data class User(
    @Column(name = "first_name")
    val firstName: String?,

    @Column(name = "last_name")
    val lastName: String?,

    @Column(name = "name")
    @Deprecated("Use firstName and lastName")
    val name: String?
) {
    // 하위 호환성 보장
    fun getFullName(): String {
        return if (firstName != null && lastName != null) {
            "$firstName $lastName"
        } else {
            name ?: ""
        }
    }
}
```

**v2.0 (최종 버전): 새 방식만 사용**
```kotlin
// User.kt (v2.0)
@Entity
data class User(
    @Column(name = "first_name")
    val firstName: String,

    @Column(name = "last_name")
    val lastName: String
) {
    fun getFullName(): String = "$firstName $lastName"
}
```

**Best Practice**:
1. **확장 단계**: 새 컬럼 추가 (기존 컬럼 유지)
2. **마이그레이션 단계**: 새 버전 배포 (양쪽 지원)
3. **정리 단계**: 기존 컬럼 제거 (충분한 시간 후)

</details>

<details>
<summary><strong>Q4: 배포 중 롤백 기준은 무엇인가요?</strong></summary>

**A**: **에러율, 응답 시간, 리소스 사용량을 기준으로 자동/수동 롤백**합니다.

**상세 설명**:

**자동 롤백 기준**:
```yaml
# 롤백 임계값 (자동)
rollback_criteria:
  error_rate:
    threshold: 1.0%        # 에러율 1% 초과 시
    baseline: 0.1%         # 평소 에러율
    multiplier: 10x        # 10배 증가 시 롤백

  response_time:
    p95_threshold: 2000ms  # P95 응답시간 2초 초과
    p99_threshold: 5000ms  # P99 응답시간 5초 초과
    baseline_p95: 200ms    # 평소 P95

  resource_usage:
    cpu_threshold: 90%     # CPU 90% 초과
    memory_threshold: 90%  # 메모리 90% 초과

  health_check:
    consecutive_failures: 3  # 연속 3회 실패 시
```

**실전 롤백 스크립트**:
```bash
#!/bin/bash
# scripts/auto-rollback-monitor.sh

DEPLOY_VERSION=$1
BASELINE_ERROR_RATE=0.001  # 0.1%
THRESHOLD_ERROR_RATE=0.01   # 1%

monitor_deployment() {
    for i in {1..30}; do  # 30분 모니터링
        # 에러율 확인
        CURRENT_ERROR_RATE=$(get_error_rate $DEPLOY_VERSION)

        if (( $(echo "$CURRENT_ERROR_RATE > $THRESHOLD_ERROR_RATE" | bc -l) )); then
            echo "🚨 Error rate too high: $CURRENT_ERROR_RATE"
            echo "Threshold: $THRESHOLD_ERROR_RATE"
            echo "Initiating automatic rollback..."
            rollback_deployment
            send_slack_alert "Automatic rollback triggered"
            return 1
        fi

        # P95 응답 시간 확인
        P95_RESPONSE=$(get_p95_response_time $DEPLOY_VERSION)
        if (( $(echo "$P95_RESPONSE > 2000" | bc -l) )); then
            echo "🚨 P95 response time too high: ${P95_RESPONSE}ms"
            rollback_deployment
            return 1
        fi

        # CPU 사용률 확인
        CPU_USAGE=$(get_cpu_usage $DEPLOY_VERSION)
        if (( $(echo "$CPU_USAGE > 90" | bc -l) )); then
            echo "🚨 CPU usage too high: ${CPU_USAGE}%"
            rollback_deployment
            return 1
        fi

        echo "✅ Minute $i: All metrics OK"
        sleep 60
    done

    echo "✅ Deployment successful after 30 minutes monitoring"
    return 0
}
```

**수동 롤백 판단 기준**:
```
비즈니스 지표:
□ 거래 성공률 감소 (결제, 주문)
□ 사용자 이탈률 증가
□ 고객 불만 접수 증가
□ 핵심 기능 사용 감소

기술 지표:
□ 데이터 정합성 문제
□ 외부 API 연동 실패
□ 알 수 없는 오류 패턴
□ 로그에 예상치 못한 에러

경험적 판단:
□ "뭔가 이상한데?" 느낌
□ 팀원들의 우려
□ 과거 유사 사례

원칙: "의심스러우면 롤백하라"
```

**롤백 의사결정 프로세스**:
```
배포 후 모니터링
    ↓
지표 확인 (1분마다)
    ↓
┌───────────────────┐
│ 임계값 초과?      │
└─────┬─────────┬───┘
      Yes       No
      ↓         ↓
  [자동 롤백]  [계속 모니터링]
      ↓
  슬랙 알림 발송
      ↓
  원인 분석
      ↓
  수정 후 재배포
```

**핵심**:
- 자동 롤백: 명확한 수치 기준
- 수동 롤백: 비즈니스 판단 + 직감
- "의심스러우면 롤백" 원칙

</details>

<details>
<summary><strong>Q5: Rolling Update 시 v1과 v2가 동시에 실행되는데 문제 없나요?</strong></summary>

**A**: **버전 간 호환성(backward compatibility)을 유지**하면 문제 없습니다.

**상세 설명**:

**문제 상황**:
```
Rolling Update 중:
┌─────────────────────────────────────┐
│ v1.0 (기존)  │ v2.0 (새 버전)       │
│ ───────────  │ ───────────          │
│ 컨테이너 1   │ 컨테이너 3 (업데이트)│
│ 컨테이너 2   │ 컨테이너 4 (업데이트)│
└─────────────────────────────────────┘

사용자 요청이 v1과 v2에 섞여서 전달됨
→ 버전 간 호환성 필수!
```

**호환성 체크리스트**:

**1. API 호환성**:
```
✅ OK: 새 필드 추가 (optional)
{
  "userId": 123,
  "name": "John",
  "email": "john@example.com"  // v2.0에서 추가
}

❌ NOT OK: 필수 필드 제거
{
  "userId": 123
  // "name" 제거 → v1.0이 처리 못함!
}

✅ OK: 기존 필드 유지 + 새 필드 추가
{
  "userId": 123,
  "name": "John",          // v1.0 호환
  "email": "john@com"  // v2.0 신규
}
```

**2. 데이터베이스 스키마**:
```sql
-- ✅ OK: 새 컬럼 추가 (NULL 허용)
ALTER TABLE users
ADD COLUMN email VARCHAR(255) NULL;

-- ❌ NOT OK: 기존 컬럼 제거
ALTER TABLE users
DROP COLUMN name;  -- v1.0이 사용 중!

-- ✅ OK: 컬럼 이름 변경 (3단계)
-- 1단계: new_column 추가
-- 2단계: v2.0 배포 (둘 다 지원)
-- 3단계: old_column 제거
```

**3. 메시지 큐/이벤트**:
```kotlin
// ✅ OK: 하위 호환성 유지
data class UserCreatedEvent(
    val userId: Long,
    val name: String,
    val email: String? = null  // v2.0에서 추가 (optional)
) {
    // v1.0도 처리 가능 (email 무시)
    // v2.0은 email 사용
}

// ❌ NOT OK: 필수 필드 추가
data class UserCreatedEvent(
    val userId: Long,
    val name: String,
    val email: String  // 필수! v1.0 처리 못함
)
```

**4. 캐시 키 호환성**:
```kotlin
// ✅ OK: 캐시 키에 버전 포함
val cacheKey = "user:${userId}:v2"

// ❌ NOT OK: 같은 키, 다른 구조
// v1.0: "user:123" → "John"
// v2.0: "user:123" → {"name":"John","email":"john@com"}
// → v1.0이 v2.0 데이터 파싱 실패!
```

**버전 호환성 테스트**:
```bash
#!/bin/bash
# scripts/compatibility-test.sh

# 1. v1.0 컨테이너 시작
docker run -d --name v1 user-service:1.0

# 2. v2.0 컨테이너 시작
docker run -d --name v2 user-service:2.0

# 3. v1 → v2 API 호출 테스트
curl v1/api/users/123 | jq > user_v1.json
curl v2/api/users/123 | jq > user_v2.json

# 4. v2 응답을 v1이 처리 가능한지 확인
docker exec v1 curl -X POST \
    -H "Content-Type: application/json" \
    -d @user_v2.json \
    http://localhost:8080/api/users

# 5. 성공하면 호환성 OK
```

**Best Practice**:
- API: 새 필드는 optional로 추가
- DB: 3단계 마이그레이션
- 이벤트: 하위 호환성 유지
- 테스트: 버전 간 호환성 자동 테스트

</details>

---

## 📝 면접 질문

### 주니어 레벨

**Q1: Rolling Update와 Blue-Green 배포의 차이점을 설명해주세요.**

**A**: **Rolling Update는 점진적 교체, Blue-Green은 즉시 전환**입니다.

**상세 답변**:

**Rolling Update**:
```
동작 방식:
1. 기존 컨테이너를 하나씩 새 버전으로 교체
2. 각 컨테이너 업데이트 사이에 대기 시간
3. 모든 컨테이너가 업데이트될 때까지 반복

┌───────────────────────────────────┐
│ v1 v1 v1 v1  (초기 상태)        │
│  ↓                                │
│ v2 v1 v1 v1  (1개 업데이트)      │
│  ↓                                │
│ v2 v2 v1 v1  (2개 업데이트)      │
│  ↓                                │
│ v2 v2 v2 v1  (3개 업데이트)      │
│  ↓                                │
│ v2 v2 v2 v2  (완료)              │
└───────────────────────────────────┘

장점:
✅ 리소스 효율적 (추가 서버 불필요)
✅ 무중단 배포
✅ 점진적 위험 분산

단점:
❌ 배포 시간 김 (5-10분)
❌ 롤백 느림 (다시 rolling)
❌ v1과 v2 동시 실행 (호환성 필요)
```

**Blue-Green**:
```
동작 방식:
1. Blue(기존) 환경 운영 중
2. Green(새) 환경을 똑같이 구축
3. Green 테스트 완료 후
4. 로드 밸런서만 Blue → Green 전환 (1-2초)

┌─────────────────────────────────────┐
│ Blue (v1)     Green (v2)            │
│ ────────────  ────────────           │
│ v1 v1 v1 v1   v2 v2 v2 v2           │
│     ↑             ↑                  │
│ [트래픽]    [대기 중]                │
│                                      │
│         트래픽 전환 (1초)            │
│                                      │
│ v1 v1 v1 v1   v2 v2 v2 v2           │
│               ↑                      │
│             [트래픽]                 │
└─────────────────────────────────────┘

장점:
✅ 즉시 전환 (1-2초)
✅ 즉시 롤백 (1-2초)
✅ 프로덕션 환경에서 사전 테스트 가능
✅ v1과 v2 격리

단점:
❌ 리소스 2배 필요
❌ 인프라 비용 증가
❌ DB 마이그레이션 복잡
```

**선택 기준**:
```
Rolling Update 추천:
- 일반적인 마이크로서비스
- 리소스 제약이 있는 환경
- 자주 배포하는 서비스

Blue-Green 추천:
- 금융/결제 서비스
- 즉시 롤백이 중요한 서비스
- 대규모 변경 사항
```

---

**Q2: Canary 배포는 무엇이고 언제 사용하나요?**

**A**: **소수 사용자에게 먼저 배포하여 위험을 최소화하는 전략**입니다.

**상세 답변**:

**Canary 배포 개념**:
```
"탄광의 카나리아"에서 유래
- 옛날 광부들이 유독 가스 감지를 위해 카나리아를 데려감
- 카나리아가 죽으면 광부들이 즉시 대피

Docker Canary:
- 소수 사용자 = 카나리아
- 문제 발견 시 전체 사용자 영향 전에 중단
```

**동작 방식**:
```
1단계: 5% 트래픽을 새 버전으로
┌──────────────────────────────┐
│ 95% → v1 (Stable)           │
│  5% → v2 (Canary) ← 모니터링│
└──────────────────────────────┘
15-30분 모니터링
  ✅ OK → 다음 단계
  ❌ 문제 → 즉시 중단

2단계: 25% 트래픽
┌──────────────────────────────┐
│ 75% → v1                     │
│ 25% → v2 ← 모니터링          │
└──────────────────────────────┘
15-30분 모니터링

3단계: 50% 트래픽
┌──────────────────────────────┐
│ 50% → v1                     │
│ 50% → v2 ← 모니터링          │
└──────────────────────────────┘

4단계: 100% 전환
┌──────────────────────────────┐
│ 100% → v2 (성공!)            │
└──────────────────────────────┘
```

**사용 시나리오**:
```
✅ Canary 배포 필수 상황:
1. 대규모 리팩토링
   예: 핵심 API 로직 전면 변경

2. 새로운 알고리즘 도입
   예: 추천 알고리즘 ML 모델 변경

3. 외부 의존성 변경
   예: 결제 PG사 변경

4. 성능 최적화
   예: DB 쿼리 최적화 (성능 회귀 검증)

5. 신규 기능 출시
   예: 새로운 거래 방식 추가

❌ Canary 불필요 상황:
- 오타 수정
- 로그 메시지 변경
- UI 텍스트 수정
- 문서 업데이트
```

**구현 예시**:
```yaml
# Traefik로 Canary 구현
services:
  stable:
    image: user-service:1.0
    deploy:
      labels:
        - "traefik.http.services.stable.loadbalancer.weight=95"

  canary:
    image: user-service:2.0
    deploy:
      labels:
        - "traefik.http.services.canary.loadbalancer.weight=5"
```

**핵심**:
- 5% → 25% → 50% → 100% 점진적 증가
- 각 단계에서 충분한 모니터링
- 에러율, 응답시간, 리소스 확인
- 문제 발견 시 즉시 중단

---

### 중급 레벨

**Q3: Blue-Green 배포 시 데이터베이스 마이그레이션은 어떻게 처리해야 하나요?**

**A**: **3단계 마이그레이션으로 하위 호환성을 유지**합니다.

**상세 답변**:

(이 부분은 FAQ Q3와 동일하므로 생략하고 추가 면접 팁 제공)

**면접에서 추가로 답변하면 좋은 내용**:
```
1. 실무 경험 강조:
"실제 프로젝트에서 users 테이블의 name 컬럼을
 first_name, last_name으로 분리할 때 이 방식을 사용했습니다.
 1주일간 두 방식을 모두 지원한 후 기존 컬럼을 제거했습니다."

2. 트레이드오프 설명:
"3단계 마이그레이션은 시간이 더 걸리지만,
 롤백이 쉽고 안전합니다. 긴급한 경우가 아니라면
 이 방식을 추천합니다."

3. 대안 제시:
"데이터베이스 뷰(View)를 사용하면
 애플리케이션 코드 변경 없이 스키마 변경이 가능합니다."
```

---

**Q4: 배포 중 롤백을 해야 하는 상황과 판단 기준은 무엇인가요?**

**A**: **자동 롤백 기준과 수동 판단 기준을 조합**합니다.

**상세 답변**:

**자동 롤백 기준 (메트릭 기반)**:
```
1. 에러율 급증
   평소: 0.1%
   현재: 5%
   → 50배 증가 → 즉시 롤백

2. 응답 시간 증가
   평소 P95: 200ms
   현재 P95: 2000ms
   → 10배 증가 → 즉시 롤백

3. 헬스체크 실패
   연속 3회 실패 → 즉시 롤백

4. 리소스 초과
   CPU/메모리 90% 초과 → 롤백
```

**수동 롤백 판단 (비즈니스 기준)**:
```
1. 결제/거래 실패 증가
   "결제가 안돼요" 문의 급증
   → 즉시 조사 후 롤백 결정

2. 데이터 정합성 문제
   "잔고가 이상해요"
   → 즉시 롤백 + 데이터 복구

3. 알 수 없는 동작
   로그에 예상치 못한 에러
   → 원인 파악 어려우면 롤백

4. 고객 불만 급증
   슬랙/CS 채널에 문의 폭주
   → 즉시 상황 파악 후 판단
```

**롤백 의사결정 프로세스**:
```python
def should_rollback(metrics, business_metrics):
    # 자동 롤백 기준 (명확한 임계값)
    if metrics.error_rate > 0.01:  # 1% 초과
        return True, "Error rate exceeded"

    if metrics.p95_response_time > 2000:  # 2초 초과
        return True, "Response time too high"

    if metrics.consecutive_health_check_failures >= 3:
        return True, "Health check failed"

    # 수동 판단 기준 (팀 합의)
    if business_metrics.payment_failure_rate > baseline * 2:
        return True, "Payment failures increased"

    if business_metrics.customer_complaints > threshold:
        return True, "Too many customer complaints"

    # 의심스러운 경우도 롤백
    if metrics.looks_suspicious():
        return True, "Suspicious behavior detected"

    return False, "All OK"

# 원칙: "의심스러우면 롤백하라"
# 재배포는 쉽지만, 고객 신뢰 회복은 어렵다
```

**실전 롤백 시나리오**:
```
Case 1: 명확한 에러 → 즉시 롤백
15:05 - 배포 완료
15:10 - 에러율 0.1% → 3% (30배)
15:11 - 자동 롤백 실행
15:12 - 에러율 정상화
15:13 - 슬랙 알림: "Automatic rollback completed"

Case 2: 애매한 상황 → 팀 논의
15:05 - 배포 완료
15:20 - 에러율 정상, 응답시간 정상
15:25 - 고객 문의 3건: "화면이 이상해요"
15:30 - 팀 논의: "롤백할까요?"
15:35 - 결정: 롤백 (의심스러우면 롤백)
15:40 - 원인 파악 후 재배포 준비
```

**핵심**:
- 자동: 명확한 메트릭 임계값
- 수동: 비즈니스 판단 + 직감
- 원칙: "의심스러우면 롤백"

---

**Q5: 대규모 트래픽 서비스에서 안전하게 배포하려면 어떤 전략을 조합해야 하나요?**

**A**: **Canary + Blue-Green + Feature Flag를 조합**합니다.

**상세 답변**:

**단계별 안전 배포 전략**:

```
1단계: Feature Flag (기능 토글)
┌─────────────────────────────────────┐
│ 코드는 배포하되, 기능은 비활성화     │
│                                     │
│ if (featureFlag.isEnabled("new_ui")) {│
│     renderNewUI()                   │
│ } else {                            │
│     renderOldUI()  // 기본값        │
│ }                                    │
│                                     │
│ 장점: 배포와 출시 분리               │
│       롤백 불필요 (토글만 OFF)       │
└─────────────────────────────────────┘

2단계: Canary 배포 (소수 검증)
┌─────────────────────────────────────┐
│ 5% 사용자에게 Feature Flag ON       │
│                                     │
│ featureFlag.setPercentage(          │
│     "new_ui",                       │
│     percentage=5,                   │
│     userGroup="internal"  // 직원만 │
│ )                                    │
│                                     │
│ 1일 모니터링 → 문제 없으면 확대     │
└─────────────────────────────────────┘

3단계: Blue-Green 배포 (전환 준비)
┌─────────────────────────────────────┐
│ Green 환경에 새 버전 완전 배포       │
│                                     │
│ Blue (v1.0) - 100% 트래픽           │
│ Green (v2.0) - Feature Flag 25% ON │
│                                     │
│ 3일 모니터링 → 문제 없으면 전환     │
└─────────────────────────────────────┘

4단계: 전체 전환
┌─────────────────────────────────────┐
│ Blue → Green 트래픽 전환 (1-2초)    │
│ Feature Flag 100% ON                │
│                                     │
│ 1주일 모니터링 → 안정화 확인        │
└─────────────────────────────────────┘

5단계: 정리
┌─────────────────────────────────────┐
│ Blue 환경 제거                       │
│ Feature Flag 코드 정리               │
│ Old UI 코드 제거                     │
└─────────────────────────────────────┘
```

**구현 예시**:

**Feature Flag 시스템**:
```kotlin
// FeatureFlagService.kt
interface FeatureFlagService {
    fun isEnabled(
        flagName: String,
        userId: Long
    ): Boolean
}

class LaunchDarklyFeatureFlagService : FeatureFlagService {
    override fun isEnabled(
        flagName: String,
        userId: Long
    ): Boolean {
        val user = LDUser.Builder(userId.toString()).build()
        return ldClient.boolVariation(flagName, user, false)
    }
}

// Controller.kt
@GetMapping("/dashboard")
fun getDashboard(@AuthUser user: User): String {
    return if (featureFlagService.isEnabled("new_dashboard", user.id)) {
        renderNewDashboard()
    } else {
        renderOldDashboard()
    }
}
```

**Canary + Feature Flag 조합**:
```python
# 배포 자동화 스크립트
def safe_deployment(version):
    # 1. Green 환경에 배포
    deploy_to_green(version)

    # 2. Feature Flag: 5% 직원만
    feature_flag.set(
        "new_feature",
        percentage=5,
        whitelist=["employee_group"]
    )
    sleep(hours=24)  # 1일 모니터링

    # 3. Feature Flag: 25% 일반 사용자
    if metrics_ok():
        feature_flag.set(
            "new_feature",
            percentage=25,
            whitelist=None
        )
        sleep(hours=72)  # 3일 모니터링
    else:
        rollback_feature_flag()
        return False

    # 4. Blue → Green 전환
    if metrics_ok():
        switch_traffic_to_green()
        feature_flag.set("new_feature", percentage=100)
    else:
        switch_traffic_to_blue()
        return False

    # 5. 1주일 후 정리
    sleep(days=7)
    if metrics_ok():
        cleanup_blue()
        remove_feature_flag_code()

    return True
```

**모니터링 대시보드**:
```
┌─────────────────────────────────────────────────┐
│ Feature Flag: new_checkout                      │
│                                                 │
│ Enabled: 25%                                    │
│ Rollout: Canary (5% → 25% → 50% → 100%)       │
│                                                 │
│ Metrics:                                        │
│ ├─ Error Rate:     0.08% (✅ OK)               │
│ ├─ P95 Response:   180ms (✅ OK)               │
│ ├─ Conversion:     4.2% (✅ +0.3% vs old)      │
│ └─ Revenue/User:   $42 (✅ +$2 vs old)         │
│                                                 │
│ User Feedback:                                  │
│ ├─ Positive: 127 (85%)                         │
│ ├─ Negative: 23 (15%)                          │
│ └─ "Faster checkout!" ⭐⭐⭐⭐⭐              │
│                                                 │
│ [🔴 Emergency Rollback]  [🟢 Increase to 50%] │
└─────────────────────────────────────────────────┘
```

**핵심**:
- Feature Flag: 배포와 출시 분리
- Canary: 점진적 위험 분산
- Blue-Green: 빠른 전환/롤백
- 3가지 조합 = 최고 안전성

---

## 다음 단계

축하합니다! 프로덕션 배포 전략을 완벽하게 마스터했습니다.

### 이번 섹션에서 배운 것

✅ 배포 전략의 중요성
✅ Recreate 배포
✅ Rolling Update (순차 배포)
✅ Blue-Green 배포
✅ Canary 배포
✅ A/B Testing
✅ 서비스별 배포 전략 선택

### 다음에 배울 것

**섹션 30: CI/CD 파이프라인 구축**에서는:
- GitHub Actions를 이용한 CI/CD
- Jenkins를 이용한 CI/CD
- GitLab CI/CD
- 자동화된 테스트 및 배포

### 추가 학습 자료

**공식 문서:**
- [Docker Swarm Deploy](https://docs.docker.com/engine/swarm/stack-deploy/)
- [Rolling Updates](https://docs.docker.com/engine/swarm/swarm-tutorial/rolling-update/)

**도구:**
- [Traefik](https://traefik.io/) - 현대적인 로드 밸런서
- [Flagger](https://flagger.app/) - Canary 배포 자동화

---

**다음 섹션에서 만나요!** 🚀