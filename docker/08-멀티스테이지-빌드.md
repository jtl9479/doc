# 섹션 8: 멀티스테이지 빌드

> **학습 목표**: 멀티스테이지 빌드를 사용하여 이미지 크기를 94% 감소시키고, 보안을 강화하며, 프로덕션 환경에 최적화된 Docker 이미지를 만들 수 있습니다.

**⏱️ 예상 학습 시간**: 2-3시간
**난이도**: ⭐⭐⭐☆☆ (3개/5개)

---

## 📚 목차
- [멀티스테이지 빌드란?](#81-멀티스테이지-빌드란)
- [왜 필요한가?](#812-왜-필요한가)
- [기본 패턴](#82-기본-패턴)
- [고급 패턴](#83-고급-패턴)
- [최적화 기법](#84-최적화-기법)
- [실전 예시](#85-실전-예시)
- [문제 해결](#86-문제-해결)
- [실생활 비유](#실생활-비유-5가지-이상)
- [수치로 보는 효과](#-수치로-보는-효과)
- [주니어 시나리오](#-주니어-시나리오)
- [FAQ](#-faq)
- [면접 질문 리스트](#-면접-질문-리스트)
- [베스트 프랙티스](#87-베스트-프랙티스)
- [축하합니다](#-축하합니다)
- [다음 단계](#88-다음-단계)

---

## 8.1 멀티스테이지 빌드란?

### 8.1.1 개념 이해

**멀티스테이지 빌드**는 하나의 Dockerfile에서 **여러 개의 FROM 문**을 사용하여 빌드 과정을 단계별로 분리하는 기법입니다.

---

## 🌟 실생활 비유 (5가지 이상)

### 비유 1: 요리 과정 - 주방과 식탁의 분리

```
[전통적인 방식] - 조리 도구까지 식탁에
┌─────────────────────────────────────┐
│ 식탁 위:                             │
│ - 완성된 요리 🍝                     │
│ - 냄비, 프라이팬, 칼, 도마 🔪        │
│ - 재료 쓰레기, 설거지 대야 🗑️        │
│ 총 무게: 20kg                        │
└─────────────────────────────────────┘

[멀티스테이지 방식] - 요리만 식탁에
┌─────────────────────────────────────┐
│ [주방] 조리 단계 (Stage 1)           │
│ - 냄비로 파스타 삶기                 │
│ - 소스 만들기                        │
│ - 설거지 및 정리                     │
└─────────────────────────────────────┘
               ↓ 완성된 요리만 이동
┌─────────────────────────────────────┐
│ [식탁] 서빙 단계 (Stage 2)           │
│ - 완성된 요리만 🍝                   │
│ 총 무게: 500g                        │
└─────────────────────────────────────┘
```

**핵심**: 요리 과정(빌드)은 주방에서, 최종 결과물(실행)만 식탁으로!

### 비유 2: 건축 현장 - 공사 장비와 완공된 건물

```
[싱글 스테이지] - 공사 장비를 건물 안에 남겨둠
┌─────────────────────────────────────┐
│ 아파트 내부:                         │
│ - 거주 공간 (100평)                  │
│ - 크레인 (50평)                      │
│ - 시멘트 믹서 (30평)                 │
│ - 공사 자재 (20평)                   │
│ 총 면적: 200평 (불필요한 공간 50%)   │
└─────────────────────────────────────┘

[멀티스테이지] - 공사 완료 후 장비 철거
┌─────────────────────────────────────┐
│ [현장] 공사 단계 (Stage 1)           │
│ - 크레인, 믹서 등으로 건물 시공      │
│ - 마감 작업 완료                     │
└─────────────────────────────────────┘
               ↓ 공사 장비 철거
┌─────────────────────────────────────┐
│ [입주] 완공 단계 (Stage 2)           │
│ - 거주 공간만 (100평)                │
│ 총 면적: 100평 (50% 절약!)           │
└─────────────────────────────────────┘
```

**핵심**: 건축 도구는 완공 후 철거, 실제 거주 공간만 남김!

### 비유 3: 카페 매장 - 로스팅 공장과 판매점의 분리

```
[통합 매장] - 로스팅 기계까지 매장에
┌─────────────────────────────────────┐
│ 카페 매장 (100㎡):                   │
│ - 고객 좌석 (30㎡)                   │
│ - 로스팅 기계 (40㎡)                 │
│ - 원두 보관창고 (20㎡)               │
│ - 포장 설비 (10㎡)                   │
│ 월 임대료: 1,000만원                 │
└─────────────────────────────────────┘

[분리 매장] - 로스팅은 공장에서
┌─────────────────────────────────────┐
│ [공장] 로스팅 단계 (외곽 지역)       │
│ - 대형 로스팅 기계로 생산            │
│ - 완제품 원두만 매장으로 배송        │
└─────────────────────────────────────┘
               ↓ 완제품 원두만 이동
┌─────────────────────────────────────┐
│ [매장] 판매 단계 (30㎡)              │
│ - 고객 좌석 + 완제품 원두만          │
│ 월 임대료: 300만원 (70% 절감!)       │
└─────────────────────────────────────┘
```

**핵심**: 제조(빌드)와 판매(런타임)를 분리하면 비용 절감!

### 비유 4: 영화 제작 - 촬영장과 영화관의 분리

```
[전체를 상영관에] - 촬영 장비까지 상영
┌─────────────────────────────────────┐
│ 영화관에 함께 보관:                  │
│ - 완성 영화 (10GB)                   │
│ - 4K 촬영 카메라 (원본 파일 1TB)     │
│ - 편집 소프트웨어 (200GB)            │
│ - NG 장면 모음 (500GB)               │
│ 총 용량: 1.7TB                       │
└─────────────────────────────────────┘

[제작과 상영 분리] - 완성 영화만 상영
┌─────────────────────────────────────┐
│ [스튜디오] 제작 단계                 │
│ - 촬영, 편집, CG 작업                │
│ - 최종 마스터링                      │
└─────────────────────────────────────┘
               ↓ 완성 영화만 배포
┌─────────────────────────────────────┐
│ [영화관] 상영 단계                   │
│ - 완성 영화만 (10GB)                 │
│ 총 용량: 10GB (99% 절감!)            │
└─────────────────────────────────────┘
```

**핵심**: 제작 과정은 숨기고, 완성품만 고객에게 제공!

### 비유 5: 가구 배송 - IKEA 조립 vs 완제품 배송

```
[자재 전체 배송] - 공장 설비까지 배송
┌─────────────────────────────────────┐
│ 고객 집으로 배송:                    │
│ - 완성 책상 (50kg)                   │
│ - 목재 절단기 (100kg)                │
│ - 전동 드릴 (20kg)                   │
│ - 사포, 페인트 (30kg)                │
│ - 원목 자재 (200kg)                  │
│ 총 무게: 400kg                       │
│ 배송비: 50,000원                     │
└─────────────────────────────────────┘

[완제품만 배송] - 조립 완료된 가구만
┌─────────────────────────────────────┐
│ [공장] 제작 단계                     │
│ - 절단, 조립, 마감 처리              │
│ - 품질 검사 완료                     │
└─────────────────────────────────────┘
               ↓ 완제품만 배송
┌─────────────────────────────────────┐
│ [고객] 완성 책상 (50kg)              │
│ 배송비: 5,000원 (90% 절감!)          │
└─────────────────────────────────────┘
```

**핵심**: 제작 도구는 공장에 두고, 완성품만 고객에게!

### 🎯 비유 종합 비교표

| 비유 | 싱글 스테이지 | 멀티스테이지 | 절감 효과 |
|------|---------------|--------------|-----------|
| 요리 | 조리 도구까지 식탁에 (20kg) | 완성 요리만 (500g) | 97.5% ↓ |
| 건축 | 공사 장비 포함 (200평) | 거주 공간만 (100평) | 50% ↓ |
| 카페 | 로스팅 기계 포함 (1,000만원) | 판매 공간만 (300만원) | 70% ↓ |
| 영화 | 제작 파일 전체 (1.7TB) | 완성 영화만 (10GB) | 99% ↓ |
| 가구 | 제작 도구 포함 (400kg) | 완제품만 (50kg) | 87.5% ↓ |

**Docker 멀티스테이지**: 평균 **80-99% 이미지 크기 감소!**

---

## 📊 수치로 보는 효과

### 실제 이미지 크기 비교

| 언어/프레임워크 | 싱글 스테이지 | 멀티스테이지 | 절감률 | 절감량 |
|-----------------|---------------|--------------|--------|--------|
| **Go** | 1.2GB | 20MB | **98.3%↓** | 1.18GB |
| **Node.js** | 450MB | 120MB | **73.3%↓** | 330MB |
| **Python** | 1.2GB | 280MB | **76.7%↓** | 920MB |
| **Java Spring Boot** | 600MB | 180MB | **70%↓** | 420MB |
| **Rust** | 2.1GB | 15MB | **99.3%↓** | 2.085GB |
| **.NET Core** | 800MB | 105MB | **86.9%↓** | 695MB |

### 비용 절감 효과

**시나리오**: 마이크로서비스 10개, 컨테이너 100개 운영

| 항목 | 싱글 스테이지 | 멀티스테이지 | 절감 |
|------|---------------|--------------|------|
| **이미지 크기** | 600MB/개 | 150MB/개 | 75%↓ |
| **레지스트리 저장소** | 60GB | 15GB | 45GB ↓ |
| **월 저장 비용** | $120 | $30 | **$90 ↓** |
| **배포 시간** | 10분 | 2분 | **80% 빠름** |
| **네트워크 전송** | 60GB | 15GB | **45GB ↓** |
| **월 트래픽 비용** | $60 | $15 | **$45 ↓** |
| **총 월 비용** | $180 | $45 | **$135 ↓** |
| **연간 비용** | $2,160 | $540 | **$1,620 ↓** |

### 성능 개선 효과

| 지표 | Before | After | 개선율 |
|------|--------|-------|--------|
| 빌드 시간 (의존성 캐시) | 5분 | 30초 | **90%↓** |
| 이미지 Pull 시간 | 3분 | 30초 | **83%↓** |
| CI/CD 파이프라인 | 15분 | 5분 | **67%↓** |
| 디스크 I/O | 600MB/s | 150MB/s | **75%↓** |
| 컨테이너 시작 시간 | 15초 | 3초 | **80%↓** |

### 보안 개선 효과

| 보안 지표 | 싱글 스테이지 | 멀티스테이지 | 개선 |
|-----------|---------------|--------------|------|
| **CVE 취약점 수** | 147개 | 23개 | **84%↓** |
| **패키지 개수** | 850개 | 45개 | **95%↓** |
| **공격 표면** | gcc, make, apt 등 포함 | 런타임 라이브러리만 | **대폭 감소** |
| **악성코드 위험** | 높음 (빌드 도구 악용 가능) | 낮음 (실행 파일만) | **위험도 80%↓** |

---

### 8.1.2 왜 필요한가?

#### ❌ 싱글 스테이지의 문제점

```dockerfile
FROM golang:1.21
WORKDIR /app
COPY . .
RUN go build -o myapp .
CMD ["./myapp"]
```

```bash
docker build -t myapp-single .
docker images myapp-single
# REPOSITORY      TAG       SIZE
# myapp-single    latest    1.2GB  😱
```

**문제점:**
- ❌ Go 컴파일러 (800MB) 포함
- ❌ 빌드 도구 (200MB) 포함
- ❌ 소스 코드 (10MB) 포함
- ❌ 실제 실행 파일 (15MB)만 필요한데!

#### ✅ 멀티스테이지의 해결

```dockerfile
# Stage 1: 빌드
FROM golang:1.21 AS builder
WORKDIR /app
COPY . .
RUN go build -o myapp .

# Stage 2: 런타임
FROM alpine:3.18
WORKDIR /app
COPY --from=builder /app/myapp .
CMD ["./myapp"]
```

```bash
docker build -t myapp-multi .
docker images myapp-multi
# REPOSITORY      TAG       SIZE
# myapp-multi     latest    20MB  🎉
```

**장점:**
- ✅ 이미지 크기: 1.2GB → 20MB (94% 감소!)
- ✅ 빌드 도구 제거 (보안 향상)
- ✅ 공격 표면 최소화
- ✅ 다운로드/배포 속도 향상

---

## 8.2 기본 패턴

### 8.2.1 가장 간단한 예시: Go 애플리케이션

**프로젝트 구조:**

```
myapp/
├── Dockerfile
├── go.mod
├── go.sum
└── main.go
```

**main.go:**

```go
package main

import (
    "fmt"
    "net/http"
)

func main() {
    http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
        fmt.Fprintf(w, "Hello from Multi-stage Build!")
    })
    fmt.Println("Server starting on :8080")
    http.ListenAndServe(":8080", nil)
}
```

**Dockerfile (멀티스테이지):**

```dockerfile
# ==================================
# Stage 1: 빌드 환경
# ==================================
FROM golang:1.21-alpine AS builder

# 빌드 도구 설치
RUN apk add --no-cache git

WORKDIR /build

# 의존성 다운로드 (캐시 활용)
COPY go.mod go.sum ./
RUN go mod download

# 소스 복사 및 빌드
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o myapp .

# ==================================
# Stage 2: 런타임 환경
# ==================================
FROM alpine:3.18

# 필수 CA 인증서 설치 (HTTPS 통신용)
RUN apk --no-cache add ca-certificates

WORKDIR /app

# 빌드된 실행 파일만 복사
COPY --from=builder /build/myapp .

# 포트 노출
EXPOSE 8080

# 실행
CMD ["./myapp"]
```

**빌드 및 실행:**

```bash
# 빌드
docker build -t myapp:multi .

# 크기 확인
docker images | grep myapp
# myapp  multi  15MB

# 실행
docker run -d -p 8080:8080 --name myapp myapp:multi

# 테스트
curl http://localhost:8080
# 출력: Hello from Multi-stage Build!
```

**단계별 분석:**

```
[빌드 과정]
┌─────────────────────────────────────┐
│ Stage 1: builder (golang:1.21)      │
├─────────────────────────────────────┤
│ 1. Go 컴파일러 다운로드 (800MB)     │
│ 2. 의존성 다운로드 (50MB)           │
│ 3. 소스 코드 빌드                    │
│ 4. 실행 파일 생성: myapp (15MB)     │
│                                      │
│ [임시 컨테이너 - 빌드 후 삭제됨]    │
└─────────────────────────────────────┘
               ↓ myapp 파일만 복사
┌─────────────────────────────────────┐
│ Stage 2: final (alpine:3.18)        │
├─────────────────────────────────────┤
│ 1. Alpine Linux (5MB)               │
│ 2. CA 인증서 (1MB)                  │
│ 3. myapp 실행 파일 (15MB)           │
│                                      │
│ [최종 이미지 크기: 21MB]             │
└─────────────────────────────────────┘
```

---

### 8.2.2 Node.js 애플리케이션

**프로젝트 구조:**

```
webapp/
├── Dockerfile
├── package.json
├── package-lock.json
├── src/
│   └── index.js
└── public/
    └── index.html
```

**package.json:**

```json
{
  "name": "webapp",
  "version": "1.0.0",
  "scripts": {
    "build": "webpack --mode production",
    "start": "node dist/server.js"
  },
  "dependencies": {
    "express": "^4.18.0"
  },
  "devDependencies": {
    "webpack": "^5.88.0",
    "webpack-cli": "^5.1.0"
  }
}
```

**Dockerfile (멀티스테이지):**

```dockerfile
# ==================================
# Stage 1: 의존성 설치 및 빌드
# ==================================
FROM node:18-alpine AS builder

WORKDIR /build

# 의존성 파일 복사
COPY package*.json ./

# 모든 의존성 설치 (devDependencies 포함)
RUN npm ci

# 소스 복사
COPY . .

# 프로덕션 빌드
RUN npm run build

# ==================================
# Stage 2: 프로덕션 의존성만 설치
# ==================================
FROM node:18-alpine AS dependencies

WORKDIR /deps

COPY package*.json ./

# 프로덕션 의존성만 설치
RUN npm ci --only=production

# ==================================
# Stage 3: 최종 런타임
# ==================================
FROM node:18-alpine

ENV NODE_ENV=production

# 보안: 일반 사용자로 실행
USER node

WORKDIR /app

# 빌드 결과물 복사
COPY --from=builder --chown=node:node /build/dist ./dist

# 프로덕션 의존성 복사
COPY --from=dependencies --chown=node:node /deps/node_modules ./node_modules

# 패키지 메타데이터 복사
COPY --chown=node:node package*.json ./

EXPOSE 3000

CMD ["node", "dist/server.js"]
```

**크기 비교:**

```bash
# 싱글 스테이지
FROM node:18-alpine
COPY . .
RUN npm install && npm run build
CMD ["node", "dist/server.js"]
# 이미지 크기: 450MB (devDependencies 포함)

# 멀티스테이지
# 이미지 크기: 120MB (프로덕션만)
# 절감: 73%
```

---

### 8.2.3 Python 애플리케이션

```dockerfile
# ==================================
# Stage 1: 컴파일 및 빌드
# ==================================
FROM python:3.11-slim AS builder

# 빌드 도구 설치
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    g++ \
    libpq-dev \
    python3-dev \
 && rm -rf /var/lib/apt/lists/*

# 가상 환경 생성
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# 의존성 설치
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ==================================
# Stage 2: 런타임
# ==================================
FROM python:3.11-slim

# 런타임 라이브러리만 설치
RUN apt-get update && apt-get install -y --no-install-recommends \
    libpq5 \
 && rm -rf /var/lib/apt/lists/*

# 가상 환경 복사
COPY --from=builder /opt/venv /opt/venv

# 환경 변수
ENV PATH="/opt/venv/bin:$PATH" \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1

# 애플리케이션 코드
WORKDIR /app
COPY . .

# 보안
RUN groupadd -r appuser --gid=1001 && \
    useradd -r -g appuser --uid=1001 --create-home appuser && \
    chown -R appuser:appuser /app

USER appuser

EXPOSE 8000

CMD ["gunicorn", "--bind", "0.0.0.0:8000", "app:app"]
```

**크기 비교:**

| 방식 | 이미지 크기 | 빌드 도구 포함 |
|------|-------------|----------------|
| 싱글 스테이지 | 1.2GB | gcc, g++, python3-dev |
| 멀티스테이지 | 280MB | 제거됨 |
| 절감률 | 77% | - |

---

## 8.3 고급 패턴

### 8.3.1 3단계 빌드: 의존성 분리

```dockerfile
# ==================================
# Stage 1: 의존성 캐싱
# ==================================
FROM node:18-alpine AS dependencies

WORKDIR /deps

COPY package*.json ./

# 개발 의존성
RUN npm ci

# 프로덕션 의존성
RUN npm ci --only=production --prefix ./production

# ==================================
# Stage 2: 빌드
# ==================================
FROM node:18-alpine AS builder

WORKDIR /build

# 개발 의존성 복사 (빌드 도구 필요)
COPY --from=dependencies /deps/node_modules ./node_modules
COPY package*.json ./
COPY . .

# 빌드 실행
RUN npm run build && \
    npm run test

# ==================================
# Stage 3: 런타임
# ==================================
FROM node:18-alpine

ENV NODE_ENV=production

USER node
WORKDIR /app

# 프로덕션 의존성 복사
COPY --from=dependencies --chown=node:node /deps/production/node_modules ./node_modules

# 빌드 결과물 복사
COPY --from=builder --chown=node:node /build/dist ./dist
COPY --chown=node:node package*.json ./

EXPOSE 3000
CMD ["node", "dist/server.js"]
```

**장점:**

1. **의존성 캐싱 최적화**
   ```
   package.json 변경 없음:
   Stage 1 (dependencies) → 캐시 사용 ✅
   Stage 2 (builder) → 캐시 사용 ✅
   Stage 3 (final) → 캐시 사용 ✅

   빌드 시간: 2초
   ```

2. **소스 변경 시**
   ```
   소스 코드만 변경:
   Stage 1 (dependencies) → 캐시 사용 ✅
   Stage 2 (builder) → 재빌드 ⚙️
   Stage 3 (final) → 재빌드 ⚙️

   빌드 시간: 30초 (의존성 설치 생략)
   ```

---

### 8.3.2 조건부 스테이지: 개발/프로덕션 분리

```dockerfile
# ==================================
# Stage 1: 베이스 (공통)
# ==================================
FROM node:18-alpine AS base

WORKDIR /app
COPY package*.json ./

# ==================================
# Stage 2: 개발 환경
# ==================================
FROM base AS development

# 모든 의존성 설치
RUN npm install

# 개발 도구 설치
RUN apk add --no-cache \
    vim \
    curl \
    git

# 소스 코드 복사
COPY . .

# 핫 리로드 활성화
ENV NODE_ENV=development
EXPOSE 3000 9229
CMD ["npm", "run", "dev"]

# ==================================
# Stage 3: 프로덕션 빌드
# ==================================
FROM base AS builder

RUN npm ci --only=production
COPY . .
RUN npm run build

# ==================================
# Stage 4: 프로덕션 환경
# ==================================
FROM node:18-alpine AS production

ENV NODE_ENV=production
USER node
WORKDIR /app

COPY --from=builder --chown=node:node /app/dist ./dist
COPY --from=builder --chown=node:node /app/node_modules ./node_modules
COPY --chown=node:node package*.json ./

EXPOSE 3000
CMD ["node", "dist/server.js"]
```

**사용법:**

```bash
# 개발 환경 빌드
docker build --target development -t myapp:dev .

# 개발 환경 실행 (볼륨 마운트로 핫 리로드)
docker run -d \
  -p 3000:3000 \
  -p 9229:9229 \
  -v $(pwd)/src:/app/src \
  --name myapp-dev \
  myapp:dev

# 프로덕션 환경 빌드
docker build --target production -t myapp:prod .

# 프로덕션 환경 실행
docker run -d \
  -p 3000:3000 \
  --name myapp-prod \
  myapp:prod
```

**크기 비교:**

```bash
docker images | grep myapp
# REPOSITORY  TAG   SIZE
# myapp       dev   450MB  (개발 도구 포함)
# myapp       prod  120MB  (최소 런타임)
```

---

### 8.3.3 병렬 빌드: 프론트엔드 + 백엔드

```dockerfile
# ==================================
# Stage 1: 프론트엔드 빌드
# ==================================
FROM node:18-alpine AS frontend-builder

WORKDIR /frontend

COPY frontend/package*.json ./
RUN npm ci

COPY frontend/ ./
RUN npm run build
# 결과: /frontend/dist/

# ==================================
# Stage 2: 백엔드 빌드
# ==================================
FROM golang:1.21-alpine AS backend-builder

WORKDIR /backend

COPY backend/go.mod backend/go.sum ./
RUN go mod download

COPY backend/ ./
RUN CGO_ENABLED=0 go build -o server .
# 결과: /backend/server

# ==================================
# Stage 3: 최종 이미지
# ==================================
FROM alpine:3.18

RUN apk --no-cache add ca-certificates

WORKDIR /app

# 백엔드 실행 파일 복사
COPY --from=backend-builder /backend/server .

# 프론트엔드 정적 파일 복사
COPY --from=frontend-builder /frontend/dist ./public

EXPOSE 8080

CMD ["./server"]
```

**빌드 과정 시각화:**

```
[병렬 빌드]
┌────────────────────┐      ┌────────────────────┐
│ Stage 1: Frontend  │      │ Stage 2: Backend   │
│ (node:18-alpine)   │      │ (golang:1.21)      │
├────────────────────┤      ├────────────────────┤
│ npm install        │      │ go mod download    │
│ npm run build      │      │ go build           │
│ ↓                  │      │ ↓                  │
│ dist/              │      │ server (binary)    │
└────────┬───────────┘      └────────┬───────────┘
         │                           │
         └──────────┬────────────────┘
                    ↓
         ┌─────────────────────┐
         │ Stage 3: Final      │
         │ (alpine:3.18)       │
         ├─────────────────────┤
         │ ./server            │
         │ ./public/           │
         │                     │
         │ [최종 이미지: 30MB] │
         └─────────────────────┘
```

**장점:**
- ✅ 프론트엔드와 백엔드를 한 이미지로 패키징
- ✅ 배포 간소화
- ✅ 이미지 크기 최소화 (30MB)

---

### 8.3.4 특정 스테이지에서 파일 복사

```dockerfile
# ==================================
# Stage 1: 기본 설정 파일 생성
# ==================================
FROM alpine:3.18 AS config-generator

WORKDIR /config

# 동적으로 설정 파일 생성
RUN echo "server_name=prod-server" > app.conf && \
    echo "port=8080" >> app.conf && \
    echo "log_level=info" >> app.conf

# ==================================
# Stage 2: 빌드
# ==================================
FROM golang:1.21-alpine AS builder

WORKDIR /build

# 생성된 설정 파일 복사
COPY --from=config-generator /config/app.conf ./configs/

COPY go.mod go.sum ./
RUN go mod download

COPY . .
RUN go build -o myapp .

# ==================================
# Stage 3: 런타임
# ==================================
FROM alpine:3.18

WORKDIR /app

# 특정 스테이지에서 선택적 복사
COPY --from=builder /build/myapp .
COPY --from=config-generator /config/app.conf ./configs/

CMD ["./myapp"]
```

---

### 8.3.5 외부 이미지에서 파일 복사

```dockerfile
# ==================================
# 공식 nginx 이미지에서 파일 추출
# ==================================
FROM nginx:1.25-alpine AS nginx-source

# ==================================
# 최종 이미지
# ==================================
FROM alpine:3.18

# nginx 바이너리만 복사
COPY --from=nginx-source /usr/sbin/nginx /usr/sbin/nginx
COPY --from=nginx-source /etc/nginx /etc/nginx

# 필요한 라이브러리 설치
RUN apk add --no-cache pcre zlib

# 설정 파일 추가
COPY nginx.conf /etc/nginx/nginx.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

---

## 8.4 최적화 기법

### 8.4.1 레이어 캐싱 전략

**❌ 비효율적:**

```dockerfile
FROM node:18-alpine AS builder
COPY . /app
RUN npm install && npm run build
# 소스 코드 변경 시 npm install 재실행!
```

**✅ 최적화:**

```dockerfile
FROM node:18-alpine AS builder

# 1단계: 의존성 파일만 복사
COPY package*.json ./
RUN npm ci
# => 캐시됨! package.json 변경 시에만 재실행

# 2단계: 소스 복사
COPY . .
# => 소스 변경해도 npm ci는 캐시 사용

# 3단계: 빌드
RUN npm run build
```

**효과:**

```bash
# 첫 번째 빌드
[+] Building 120.5s
 => [builder 2/5] COPY package*.json ./        0.1s
 => [builder 3/5] RUN npm ci                   90.0s  ⏳
 => [builder 4/5] COPY . .                     0.5s
 => [builder 5/5] RUN npm run build            30.0s

# 소스만 변경 후 재빌드
[+] Building 31.2s
 => [builder 2/5] COPY package*.json ./        0.1s
 => [builder 3/5] RUN npm ci                   CACHED ⚡
 => [builder 4/5] COPY . .                     0.6s
 => [builder 5/5] RUN npm run build            30.5s
```

---

### 8.4.2 빌드 컨텍스트 최소화

**.dockerignore 작성:**

```
# .dockerignore
node_modules/
npm-debug.log
.git/
.gitignore
.env*
*.md
.vscode/
.idea/
dist/
build/
coverage/
.DS_Store
Thumbs.db

# 테스트 파일
__tests__/
*.test.js
*.spec.js

# 문서
docs/
*.pdf
```

**효과:**

```bash
# .dockerignore 없을 때
Sending build context to Docker daemon  850MB
Step 1/10 : FROM node:18-alpine
 ---> abc123

# .dockerignore 있을 때
Sending build context to Docker daemon  2.5MB
Step 1/10 : FROM node:18-alpine
 ---> abc123

# 절감: 850MB → 2.5MB (99.7% 감소!)
```

---

### 8.4.3 Alpine Linux 활용

**크기 비교:**

```dockerfile
# Ubuntu 베이스
FROM ubuntu:20.04
RUN apt-get update && apt-get install -y curl
# 크기: 72MB

# Alpine 베이스
FROM alpine:3.18
RUN apk add --no-cache curl
# 크기: 8MB

# 절감: 89%
```

**주의사항:**

```dockerfile
# ❌ 일부 라이브러리가 Alpine에서 작동 안 함
FROM alpine:3.18
RUN pip install numpy
# 오류: C 라이브러리 호환성 문제

# ✅ 해결: Alpine용 빌드 도구 설치
FROM alpine:3.18
RUN apk add --no-cache \
    gcc \
    musl-dev \
    python3-dev
RUN pip install numpy
```

---

### 8.4.4 Distroless 이미지 (궁극의 최소화)

**Google의 Distroless 이미지:**
- 셸 없음
- 패키지 관리자 없음
- 실행 파일 + 런타임만

```dockerfile
# ==================================
# Stage 1: 빌드
# ==================================
FROM golang:1.21 AS builder

WORKDIR /build
COPY . .
RUN CGO_ENABLED=0 go build -ldflags="-w -s" -o myapp .

# ==================================
# Stage 2: Distroless
# ==================================
FROM gcr.io/distroless/static-debian11

COPY --from=builder /build/myapp /

EXPOSE 8080
CMD ["/myapp"]
```

**크기 비교:**

| 베이스 이미지 | 크기 | 포함 요소 |
|---------------|------|-----------|
| ubuntu:20.04 | 72MB | 셸, 패키지 관리자, 유틸리티 |
| alpine:3.18 | 7MB | 셸, apk, 기본 유틸리티 |
| distroless/static | 2MB | 정적 바이너리 런타임만 |

**제약사항:**

```bash
# 디버깅 불가능
docker exec -it myapp sh
# 오류: OCI runtime exec failed: executable file not found in $PATH

# 해결: 디버그 버전 사용
FROM gcr.io/distroless/static-debian11:debug
# 최소한의 디버깅 도구 포함 (busybox)
```

---

## 8.5 실전 예시

### 8.5.1 마이크로서비스: Java Spring Boot

```dockerfile
# ==================================
# Stage 1: 빌드
# ==================================
FROM gradle:8.5-jdk17 AS builder

WORKDIR /build

# Gradle 의존성 캐싱
COPY build.gradle settings.gradle ./
COPY gradle ./gradle/
RUN gradle dependencies --no-daemon

# 소스 복사 및 빌드
COPY src ./src
RUN gradle build -x test --no-daemon

# JAR 파일 추출 (레이어 분리)
RUN mkdir -p build/dependency && \
    cd build/dependency && \
    jar -xf ../libs/*.jar

# ==================================
# Stage 2: 런타임
# ==================================
FROM eclipse-temurin:17-jre-alpine

# 보안
RUN addgroup -S spring && adduser -S spring -G spring
USER spring:spring

WORKDIR /app

# 레이어별 복사 (캐싱 최적화)
COPY --from=builder build/dependency/BOOT-INF/lib ./lib
COPY --from=builder build/dependency/META-INF ./META-INF
COPY --from=builder build/dependency/BOOT-INF/classes ./

# JVM 옵션
ENV JAVA_OPTS="-Xms256m -Xmx512m -XX:+UseContainerSupport"

EXPOSE 8080

ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -cp .:./lib/* com.example.Application"]
```

**레이어 캐싱 효과:**

```
[첫 번째 빌드]
Layer 1: 의존성 라이브러리 (200MB) → 캐시됨
Layer 2: 메타데이터 (1MB) → 캐시됨
Layer 3: 애플리케이션 코드 (5MB) → 캐시됨

[코드 변경 후 재빌드]
Layer 1: 의존성 라이브러리 (200MB) → 캐시 사용 ✅
Layer 2: 메타데이터 (1MB) → 캐시 사용 ✅
Layer 3: 애플리케이션 코드 (5MB) → 재빌드 ⚙️

전송 데이터: 5MB만 (200MB 절약!)
```

---

### 8.5.2 풀스택 애플리케이션

```dockerfile
# ==================================
# Stage 1: 프론트엔드 빌드 (React)
# ==================================
FROM node:18-alpine AS frontend

WORKDIR /frontend

COPY frontend/package*.json ./
RUN npm ci

COPY frontend/ ./
RUN npm run build
# 결과: /frontend/build/

# ==================================
# Stage 2: 백엔드 빌드 (Node.js API)
# ==================================
FROM node:18-alpine AS backend-builder

WORKDIR /backend

COPY backend/package*.json ./
RUN npm ci --only=production

# ==================================
# Stage 3: 프로덕션 서버 (Express)
# ==================================
FROM node:18-alpine

ENV NODE_ENV=production

# 보안
USER node
WORKDIR /app

# 백엔드 코드
COPY --from=backend-builder --chown=node:node /backend/node_modules ./node_modules
COPY --chown=node:node backend/ ./

# 프론트엔드 정적 파일
COPY --from=frontend --chown=node:node /frontend/build ./public

EXPOSE 3000

CMD ["node", "server.js"]
```

**server.js (백엔드):**

```javascript
const express = require('express');
const path = require('path');

const app = express();

// API 라우트
app.use('/api', require('./routes/api'));

// 정적 파일 서빙 (프론트엔드)
app.use(express.static('public'));

// SPA fallback
app.get('*', (req, res) => {
  res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

app.listen(3000, () => {
  console.log('Server running on port 3000');
});
```

---

### 8.5.3 CI/CD 파이프라인 통합

**Dockerfile:**

```dockerfile
# ==================================
# Stage 1: 테스트 환경
# ==================================
FROM node:18-alpine AS test

WORKDIR /app

COPY package*.json ./
RUN npm ci

COPY . .

# 린트 및 테스트 실행
RUN npm run lint
RUN npm run test
RUN npm run test:coverage

# ==================================
# Stage 2: 빌드
# ==================================
FROM node:18-alpine AS builder

WORKDIR /build

COPY package*.json ./
RUN npm ci --only=production

COPY . .
RUN npm run build

# ==================================
# Stage 3: 프로덕션
# ==================================
FROM node:18-alpine AS production

ENV NODE_ENV=production

USER node
WORKDIR /app

COPY --from=builder --chown=node:node /build/dist ./dist
COPY --from=builder --chown=node:node /build/node_modules ./node_modules
COPY --chown=node:node package*.json ./

EXPOSE 3000

CMD ["node", "dist/server.js"]
```

**GitLab CI 파이프라인 (.gitlab-ci.yml):**

```yaml
stages:
  - test
  - build
  - deploy

variables:
  DOCKER_IMAGE: registry.example.com/myapp
  DOCKER_TAG: $CI_COMMIT_SHORT_SHA

# 테스트 단계
test:
  stage: test
  script:
    - docker build --target test -t ${DOCKER_IMAGE}:test .
  only:
    - merge_requests
    - main

# 빌드 단계
build:
  stage: build
  script:
    - docker build --target production -t ${DOCKER_IMAGE}:${DOCKER_TAG} .
    - docker tag ${DOCKER_IMAGE}:${DOCKER_TAG} ${DOCKER_IMAGE}:latest
    - docker push ${DOCKER_IMAGE}:${DOCKER_TAG}
    - docker push ${DOCKER_IMAGE}:latest
  only:
    - main

# 배포 단계
deploy:
  stage: deploy
  script:
    - kubectl set image deployment/myapp myapp=${DOCKER_IMAGE}:${DOCKER_TAG}
  only:
    - main
  environment:
    name: production
```

---

## 8.6 문제 해결

### 8.6.1 빌드 캐시가 작동하지 않음

**증상:**

```bash
docker build -t myapp .
# 매번 모든 레이어 재빌드됨
```

**원인 및 해결:**

```dockerfile
# ❌ 문제: 타임스탬프가 매번 변경됨
RUN echo "Build time: $(date)" > /build-info.txt
COPY . .
# => 캐시 무효화

# ✅ 해결: ARG 사용
ARG BUILD_DATE
LABEL build-date="${BUILD_DATE}"
COPY . .
```

```bash
# 빌드 시 인자 전달
docker build --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') -t myapp .
```

---

### 8.6.2 COPY --from 실패

**증상:**

```bash
COPY failed: file not found in build context or excluded by .dockerignore: stat myapp: file does not exist
```

**원인:**

```dockerfile
# ❌ 잘못된 경로
FROM golang:1.21 AS builder
WORKDIR /app
RUN go build -o /myapp .

FROM alpine:3.18
COPY --from=builder /app/myapp .  # ❌ /app/myapp가 아니라 /myapp
```

**해결:**

```dockerfile
FROM golang:1.21 AS builder
WORKDIR /app
RUN go build -o myapp .  # 현재 WORKDIR에 생성

FROM alpine:3.18
COPY --from=builder /app/myapp .  # ✅ 올바른 경로
```

---

### 8.6.3 이미지 크기가 여전히 큼

**진단:**

```bash
# 레이어별 크기 확인
docker history myapp:latest

# IMAGE          CREATED       CREATED BY                                      SIZE
# abc123         2 min ago     CMD ["./myapp"]                                 0B
# def456         2 min ago     COPY /app/myapp . # buildkit                    15MB
# ghi789         5 min ago     /bin/sh -c apk add --no-cache git vim curl...   120MB  😱
```

**문제:**

```dockerfile
# ❌ 불필요한 도구가 최종 이미지에 포함됨
FROM alpine:3.18
RUN apk add --no-cache git vim curl wget  # 디버깅 도구
COPY --from=builder /app/myapp .
```

**해결:**

```dockerfile
# ✅ 최종 이미지는 최소한만
FROM alpine:3.18
RUN apk add --no-cache ca-certificates  # 필수만
COPY --from=builder /app/myapp .

# 디버깅이 필요하면 별도 이미지 생성:
FROM alpine:3.18 AS debug
RUN apk add --no-cache ca-certificates git vim curl
COPY --from=builder /app/myapp .
```

```bash
# 프로덕션
docker build --target production -t myapp:prod .

# 디버그
docker build --target debug -t myapp:debug .
```

---

## 8.7 베스트 프랙티스

### ✅ 체크리스트

- [ ] **명명된 스테이지 사용**: `FROM ... AS builder`
- [ ] **의존성 캐싱 최적화**: package.json을 소스보다 먼저 복사
- [ ] **Alpine/Distroless 사용**: 최종 이미지 크기 최소화
- [ ] **빌드 도구 제거**: 런타임 이미지에 gcc, npm 등 불포함
- [ ] **.dockerignore 작성**: 불필요한 파일 전송 방지
- [ ] **레이어 순서 최적화**: 자주 변경되는 것은 하단 배치
- [ ] **보안 사용자 설정**: USER 명령어로 root 회피
- [ ] **특정 버전 고정**: `node:18.19.0` (`:latest` 금지)
- [ ] **헬스체크 추가**: HEALTHCHECK 명령어 사용
- [ ] **ARG로 유연성 제공**: 빌드 시 커스터마이징 가능

---

## 👨‍💻 주니어 시나리오

### 시나리오 1: node_modules를 최종 이미지에 모두 포함

**상황**: 첫 프로젝트에서 Node.js 앱을 Docker로 배포하려는 신입 개발자

```dockerfile
# ❌ 주니어 개발자가 작성한 코드
FROM node:18
WORKDIR /app
COPY . .
RUN npm install
CMD ["npm", "start"]
```

```bash
docker build -t myapp .
docker images myapp
# REPOSITORY   TAG      SIZE
# myapp        latest   1.2GB  😱
```

**문제점**:
- 문제 1: devDependencies (webpack, babel 등)가 프로덕션 이미지에 포함됨 (+300MB)
- 문제 2: npm, yarn 등 패키지 관리자가 런타임에 불필요함
- 문제 3: 소스 코드가 그대로 노출됨 (빌드된 dist/만 필요한데)
- 왜 이 문제가 발생하는가: 빌드와 런타임을 분리하지 않아서

**해결책**:
```dockerfile
# ✅ 멀티스테이지로 개선한 코드
# Stage 1: 빌드 환경
FROM node:18-alpine AS builder
WORKDIR /build
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

# Stage 2: 프로덕션 환경
FROM node:18-alpine
ENV NODE_ENV=production
WORKDIR /app

# 프로덕션 의존성만 설치
COPY package*.json ./
RUN npm ci --only=production

# 빌드 결과물만 복사
COPY --from=builder /build/dist ./dist

USER node
CMD ["node", "dist/server.js"]
```

```bash
docker build -t myapp:optimized .
docker images | grep myapp
# REPOSITORY   TAG         SIZE
# myapp        optimized   150MB  🎉 (87.5% 감소!)
```

**배운 점**:
- 💡 팁 1: 빌드 도구(webpack, babel)는 builder 스테이지에만
- 💡 팁 2: 프로덕션 의존성은 `--only=production`으로 설치
- 💡 팁 3: 빌드 결과물(dist/)만 최종 이미지로 복사
- 💡 팁 4: alpine 이미지 사용으로 추가 절감

---

### 시나리오 2: Go 바이너리에 빌드 도구까지 포함

**상황**: Go 애플리케이션을 처음 배포하는 주니어 개발자

```dockerfile
# ❌ 주니어 개발자가 작성한 코드
FROM golang:1.21
WORKDIR /app
COPY . .
RUN go build -o myapp .
CMD ["./myapp"]
```

```bash
docker build -t go-app .
docker images go-app
# REPOSITORY   TAG      SIZE
# go-app       latest   1.2GB  😱
```

**문제점**:
- 문제 1: Go 컴파일러 (800MB)가 런타임에 불필요
- 문제 2: 빌드 도구 (git, gcc 등 200MB)가 포함됨
- 문제 3: 소스 코드가 이미지에 남아있음 (보안 위험)
- 문제 4: Go는 정적 바이너리를 만들 수 있는데 활용하지 않음
- 왜 이 문제가 발생하는가: 컴파일 언어의 특성을 이해하지 못함

**해결책**:
```dockerfile
# ✅ 올바른 코드
# Stage 1: 빌드
FROM golang:1.21-alpine AS builder
WORKDIR /build

COPY go.mod go.sum ./
RUN go mod download

COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -ldflags="-w -s" -o myapp .

# Stage 2: 실행 (Distroless 또는 Scratch도 가능)
FROM alpine:3.18
RUN apk --no-cache add ca-certificates
WORKDIR /app
COPY --from=builder /build/myapp .

USER nobody
EXPOSE 8080
CMD ["./myapp"]
```

```bash
docker build -t go-app:optimized .
docker images | grep go-app
# REPOSITORY   TAG         SIZE
# go-app       optimized   15MB  🎉 (98.8% 감소!)
```

**배운 점**:
- 💡 팁 1: Go는 정적 바이너리를 만들 수 있어 매우 작은 이미지 가능
- 💡 팁 2: `CGO_ENABLED=0`으로 순수 Go 바이너리 생성
- 💡 팁 3: `-ldflags="-w -s"`로 디버그 정보 제거 (추가 30% 절감)
- 💡 팁 4: scratch 또는 distroless 이미지 사용하면 2-5MB까지 가능
- 💡 팁 5: 컴파일 언어는 멀티스테이지의 최대 수혜자!

---

### 시나리오 3: Python 빌드 도구를 런타임에 포함

**상황**: Python Django 앱을 처음 컨테이너화하는 주니어 개발자

```dockerfile
# ❌ 주니어 개발자가 작성한 코드
FROM python:3.11
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["gunicorn", "myapp:app"]
```

```bash
docker build -t django-app .
# Step 5/6 : RUN pip install -r requirements.txt
# Collecting psycopg2==2.9.5
#   Downloading psycopg2-2.9.5.tar.gz
#   Installing build dependencies... done
#   ERROR: Failed building wheel for psycopg2
```

**문제점**:
- 문제 1: 네이티브 확장(psycopg2, Pillow 등) 빌드 실패
- 문제 2: 빌드에 필요한 gcc, python-dev가 없음
- 문제 3: 설치하면 이미지가 1.5GB로 급증
- 문제 4: 빌드 후에도 gcc 등이 런타임에 남아있음
- 왜 이 문제가 발생하는가: 빌드 의존성과 런타임 의존성을 구분하지 않음

**해결책**:
```dockerfile
# ✅ 올바른 코드
# Stage 1: 빌드 환경
FROM python:3.11-slim AS builder

# 빌드 도구 설치
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    g++ \
    libpq-dev \
    python3-dev \
 && rm -rf /var/lib/apt/lists/*

# 가상 환경 생성
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# 의존성 설치 (네이티브 컴파일)
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Stage 2: 런타임 환경
FROM python:3.11-slim

# 런타임 라이브러리만 설치
RUN apt-get update && apt-get install -y --no-install-recommends \
    libpq5 \
 && rm -rf /var/lib/apt/lists/*

# 컴파일된 가상 환경 복사
COPY --from=builder /opt/venv /opt/venv

# 환경 변수 설정
ENV PATH="/opt/venv/bin:$PATH" \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1

# 애플리케이션 코드
WORKDIR /app
COPY . .

# 보안
RUN useradd -m appuser && chown -R appuser:appuser /app
USER appuser

EXPOSE 8000
CMD ["gunicorn", "--bind", "0.0.0.0:8000", "myapp:app"]
```

```bash
docker build -t django-app:optimized .
docker images | grep django-app
# REPOSITORY      TAG         SIZE
# django-app      optimized   320MB  🎉
```

**배운 점**:
- 💡 팁 1: 네이티브 확장은 builder에서 컴파일, 결과만 복사
- 💡 팁 2: 빌드 도구 (gcc, python-dev)는 builder에만 설치
- 💡 팁 3: 런타임은 라이브러리만 설치 (libpq5, gcc는 불필요)
- 💡 팁 4: 가상 환경 전체를 복사하면 의존성 관리가 쉬움
- 💡 팁 5: `--no-install-recommends`로 불필요한 패키지 제외

---

### 시나리오 4: 코드 리뷰에서 "이미지 크기가 너무 큽니다" 지적

**상황**: PR을 올렸더니 시니어 개발자가 "이미지 크기 최적화 필요" 코멘트

```dockerfile
# ❌ 1차 작성 코드
FROM ubuntu:22.04
RUN apt-get update && apt-get install -y \
    nodejs \
    npm \
    git \
    vim \
    curl \
    wget
WORKDIR /app
COPY . .
RUN npm install
CMD ["npm", "start"]
```

```bash
docker build -t app:v1 .
docker images app:v1
# REPOSITORY   TAG      SIZE
# app          v1       850MB  😱

# PR 코멘트:
# "ubuntu 대신 alpine 사용하고, 멀티스테이지로 최적화해주세요."
```

**시행착오 과정**:

**2차 시도 - Alpine으로 변경**:
```dockerfile
# ⚠️ 개선했지만 여전히 문제
FROM node:18-alpine
RUN apk add --no-cache git vim curl wget
WORKDIR /app
COPY . .
RUN npm install
CMD ["npm", "start"]
```

```bash
docker build -t app:v2 .
docker images app:v2
# REPOSITORY   TAG      SIZE
# app          v2       450MB  (개선됨, 하지만 아직 부족)
```

**PR 코멘트**:
```
"더 좋아졌습니다. 하지만:
1. vim, curl, wget은 프로덕션에 불필요합니다
2. devDependencies가 포함되어 있습니다
3. 멀티스테이지로 빌드와 런타임을 분리해보세요"
```

**최종 해결책**:
```dockerfile
# ✅ 3차 시도 - 멀티스테이지 + 최적화
# Stage 1: 의존성 캐싱
FROM node:18-alpine AS deps
WORKDIR /deps
COPY package*.json ./
RUN npm ci

# Stage 2: 빌드
FROM node:18-alpine AS builder
WORKDIR /build
COPY --from=deps /deps/node_modules ./node_modules
COPY . .
RUN npm run build

# Stage 3: 프로덕션
FROM node:18-alpine
ENV NODE_ENV=production

# 프로덕션 의존성만
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production && \
    npm cache clean --force

# 빌드 결과물만
COPY --from=builder /build/dist ./dist

# 보안
USER node
EXPOSE 3000
CMD ["node", "dist/server.js"]
```

```bash
docker build -t app:v3 .
docker images app:v3
# REPOSITORY   TAG      SIZE
# app          v3       120MB  🎉 (85.9% 감소!)

# .dockerignore도 추가
echo "node_modules\n.git\n*.md\n.env" > .dockerignore

# 최종 빌드
docker build -t app:final .
docker images app:final
# REPOSITORY   TAG      SIZE
# app          final    118MB  🎉
```

**PR 승인 코멘트**:
```
"완벽합니다! 👍
1. 멀티스테이지로 의존성 캐싱 최적화
2. 프로덕션 의존성만 포함
3. 불필요한 도구 제거
4. .dockerignore로 컨텍스트 최소화
5. 보안을 위한 USER node 설정

Approved! 병합해주세요."
```

**배운 점**:
- 💡 팁 1: 코드 리뷰는 학습의 기회! 시니어의 조언을 적극 수용
- 💡 팁 2: 단계적 개선: ubuntu → alpine → 멀티스테이지
- 💡 팁 3: 프로덕션에 불필요한 도구(vim, curl) 제거
- 💡 팁 4: .dockerignore로 빌드 컨텍스트 최소화
- 💡 팁 5: 이미지 크기는 성능과 보안에 직결!
- 💡 팁 6: 850MB → 118MB (86% 감소) 달성!

---

## ❓ FAQ

<details>
<summary><strong>Q1: 멀티스테이지 빌드를 사용하면 빌드 시간이 더 오래 걸리나요?</strong></summary>

**A**: 오히려 **더 빠릅니다!** 레이어 캐싱 덕분입니다.

**상세 설명**:
- 포인트 1: 의존성을 별도 스테이지로 분리하면 캐싱 효과 극대화
- 포인트 2: 소스 코드만 변경 시 의존성 설치는 캐시 사용
- 포인트 3: 병렬 빌드도 가능 (프론트엔드 + 백엔드 동시)

**예시**:
```dockerfile
# 의존성 캐싱 전략
FROM node:18-alpine AS deps
COPY package*.json ./
RUN npm ci  # 👈 package.json 변경 시에만 재실행

FROM node:18-alpine AS builder
COPY --from=deps /deps/node_modules ./node_modules
COPY . .  # 👈 소스만 변경 시 여기부터 재실행
RUN npm run build
```

**실제 측정 결과**:
```bash
# 첫 빌드
[+] Building 180.5s

# package.json 변경 없이 소스만 수정
[+] Building 25.3s  # 85% 빠름! ⚡

# package.json 변경
[+] Building 95.0s  # 여전히 절반 수준
```

**실무 팁**:
💡 CI/CD에서 레이어 캐시를 활용하면 평균 빌드 시간 70% 감소!

</details>

<details>
<summary><strong>Q2: FROM scratch는 언제 사용하나요?</strong></summary>

**A**: **완전히 정적인 바이너리**를 실행할 때만 사용합니다.

**상세 설명**:
- 포인트 1: `scratch`는 완전히 빈 이미지 (0 바이트)
- 포인트 2: 셸도 없고, 라이브러리도 없음
- 포인트 3: Go, Rust 같은 정적 컴파일 언어에 적합

**예시 - Go 애플리케이션**:
```dockerfile
FROM golang:1.21 AS builder
WORKDIR /build
COPY . .
RUN CGO_ENABLED=0 go build -ldflags="-w -s" -o app .

FROM scratch
COPY --from=builder /build/app /app
EXPOSE 8080
ENTRYPOINT ["/app"]
```

```bash
docker images
# REPOSITORY   TAG      SIZE
# myapp        latest   5MB  🎉 (순수 바이너리 크기만!)
```

**주의사항**:
```bash
# ❌ 디버깅 불가능
docker exec -it myapp sh
# Error: OCI runtime exec failed: executable file not found

# ❌ HTTPS 호출 실패 (CA 인증서 없음)
# Get "https://api.example.com": x509: certificate signed by unknown authority
```

**해결책**:
```dockerfile
# ✅ CA 인증서 추가
FROM alpine:3.18 AS certs
RUN apk --no-cache add ca-certificates

FROM scratch
COPY --from=certs /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/
COPY --from=builder /build/app /app
ENTRYPOINT ["/app"]
```

**실무 팁**:
💡 개발: alpine 사용 (디버깅 가능)
💡 프로덕션: scratch 또는 distroless (보안 최대화)

</details>

<details>
<summary><strong>Q3: 특정 스테이지만 빌드할 수 있나요?</strong></summary>

**A**: 네! `--target` 플래그를 사용하면 됩니다.

**상세 설명**:
- 포인트 1: 개발/프로덕션 환경을 하나의 Dockerfile로 관리 가능
- 포인트 2: 테스트 스테이지를 별도로 실행 가능
- 포인트 3: CI/CD에서 단계별 빌드 가능

**예시**:
```dockerfile
# 베이스
FROM node:18-alpine AS base
WORKDIR /app
COPY package*.json ./

# 개발 환경
FROM base AS development
RUN npm install
COPY . .
CMD ["npm", "run", "dev"]

# 테스트 환경
FROM base AS test
RUN npm ci
COPY . .
RUN npm run test
RUN npm run lint

# 프로덕션 환경
FROM base AS production
RUN npm ci --only=production
COPY --from=test /app/dist ./dist
CMD ["node", "dist/server.js"]
```

**사용법**:
```bash
# 개발 환경만 빌드
docker build --target development -t myapp:dev .

# 테스트만 실행
docker build --target test -t myapp:test .

# 프로덕션 빌드
docker build --target production -t myapp:prod .
# 또는 target 생략 시 마지막 스테이지(production)까지 빌드
docker build -t myapp:prod .
```

**CI/CD 활용**:
```yaml
# .gitlab-ci.yml
stages:
  - test
  - build

test:
  script:
    - docker build --target test .

build:
  script:
    - docker build --target production -t $IMAGE .
```

**실무 팁**:
💡 하나의 Dockerfile로 모든 환경 관리 → 중복 제거!

</details>

<details>
<summary><strong>Q4: COPY --from=builder의 경로를 어떻게 확인하나요?</strong></summary>

**A**: 빌드 중에 **중간 스테이지를 컨테이너로 실행**해서 확인할 수 있습니다.

**상세 설명**:
- 포인트 1: 빌드가 실패하면 중간 이미지가 남음
- 포인트 2: `docker build` 출력에서 이미지 ID 확인
- 포인트 3: 해당 이미지로 컨테이너 실행해서 탐색

**예시**:
```dockerfile
FROM golang:1.21 AS builder
WORKDIR /build
COPY . .
RUN go build -o myapp .

FROM alpine:3.18
# 이 경로가 맞나? 🤔
COPY --from=builder /build/myapp .
```

**확인 방법 1: 빌드 ID 활용**
```bash
# 빌드 (실패해도 OK)
docker build -t myapp .
# => [builder 3/4] RUN go build -o myapp .
# => => sha256:abc123def456...

# 중간 이미지 확인
docker images -a
# REPOSITORY   TAG      IMAGE ID
# <none>       <none>   abc123def456  # 👈 builder 스테이지

# 컨테이너로 실행해서 탐색
docker run --rm -it abc123def456 sh
$ ls /build
# myapp  go.mod  go.sum  main.go
$ exit

# 확인: /build/myapp이 맞음! ✅
```

**확인 방법 2: 임시 스테이지 추가**
```dockerfile
FROM golang:1.21 AS builder
WORKDIR /build
COPY . .
RUN go build -o myapp .
RUN ls -la /build  # 👈 빌드 로그에 파일 목록 출력

FROM alpine:3.18
COPY --from=builder /build/myapp .
```

**확인 방법 3: --target으로 특정 스테이지만 빌드**
```bash
docker build --target builder -t myapp:builder .
docker run --rm myapp:builder ls -la /build
# total 15360
# -rwxr-xr-x 1 root root 15728640 Jan 10 12:34 myapp
# -rw-r--r-- 1 root root      123 Jan 10 12:30 go.mod
```

**실무 팁**:
💡 `WORKDIR`을 명확히 설정하면 경로 혼란 방지!
💡 상대 경로보다 절대 경로 사용 권장!

</details>

<details>
<summary><strong>Q5: Alpine 이미지에서 패키지 설치가 실패합니다</strong></summary>

**A**: Alpine은 **musl libc**를 사용해서 일부 바이너리가 호환되지 않을 수 있습니다.

**상세 설명**:
- 포인트 1: Alpine은 glibc가 아닌 musl libc 사용
- 포인트 2: 일부 네이티브 확장이 호환되지 않음
- 포인트 3: 해결책: 빌드 도구 설치 또는 slim 이미지 사용

**자주 발생하는 에러**:
```bash
# Python psycopg2 설치 실패
ERROR: Could not build wheels for psycopg2

# Node.js native module 빌드 실패
gyp ERR! build error
```

**해결책 1: 빌드 도구 설치**
```dockerfile
FROM python:3.11-alpine AS builder

# 빌드 도구 설치
RUN apk add --no-cache \
    gcc \
    musl-dev \
    postgresql-dev \
    python3-dev

RUN pip install psycopg2  # ✅ 성공!

FROM python:3.11-alpine
RUN apk add --no-cache libpq
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
```

**해결책 2: 바이너리 패키지 사용**
```dockerfile
FROM python:3.11-alpine

# 컴파일이 필요 없는 바이너리 버전
RUN pip install psycopg2-binary  # ✅ 간단!
```

**해결책 3: slim 이미지 사용**
```dockerfile
# Alpine 대신 slim 사용
FROM python:3.11-slim

# apt로 패키지 설치 (호환성 좋음)
RUN apt-get update && apt-get install -y libpq5
RUN pip install psycopg2  # ✅ 문제 없음
```

**크기 비교**:
```bash
# alpine + 빌드 도구
# 최종 크기: 150MB

# slim
# 최종 크기: 180MB

# 차이: 30MB (큰 차이 아님)
```

**실무 팁**:
💡 Python/Node.js: slim 권장 (호환성 좋음)
💡 Go/Rust: alpine 권장 (정적 바이너리)
💡 Java: JRE 전용 이미지 사용 (eclipse-temurin)

</details>

<details>
<summary><strong>Q6: 멀티스테이지 빌드에서 ARG 변수를 어떻게 전달하나요?</strong></summary>

**A**: **각 스테이지마다 ARG를 다시 선언**해야 합니다.

**상세 설명**:
- 포인트 1: ARG는 스테이지별로 스코프가 분리됨
- 포인트 2: 전역 ARG는 FROM 이전에 선언
- 포인트 3: 스테이지별 ARG는 FROM 이후에 선언

**예시 - ❌ 잘못된 방법**:
```dockerfile
FROM node:18-alpine AS builder
ARG NODE_ENV=production
RUN echo "Building for $NODE_ENV"

FROM node:18-alpine
# ❌ NODE_ENV를 사용할 수 없음!
RUN echo "Running in $NODE_ENV"  # 빈 문자열 출력
```

**예시 - ✅ 올바른 방법 1 (스테이지별 선언)**:
```dockerfile
FROM node:18-alpine AS builder
ARG NODE_ENV=production
RUN echo "Building for $NODE_ENV"

FROM node:18-alpine
ARG NODE_ENV=production  # 👈 다시 선언!
RUN echo "Running in $NODE_ENV"  # ✅ 정상 출력
```

**예시 - ✅ 올바른 방법 2 (전역 ARG)**:
```dockerfile
# FROM 이전에 선언하면 모든 스테이지에서 사용 가능
ARG NODE_ENV=production

FROM node:18-alpine AS builder
ARG NODE_ENV  # 👈 전역 ARG를 이 스테이지로 가져옴
RUN echo "Building for $NODE_ENV"

FROM node:18-alpine
ARG NODE_ENV  # 👈 전역 ARG를 이 스테이지로 가져옴
RUN echo "Running in $NODE_ENV"
```

**빌드 시 값 전달**:
```bash
docker build --build-arg NODE_ENV=development -t myapp .
```

**실전 예시 - 환경별 빌드**:
```dockerfile
ARG BUILD_ENV=production

FROM node:18-alpine AS base
ARG BUILD_ENV
WORKDIR /app
COPY package*.json ./

FROM base AS development
ARG BUILD_ENV
RUN npm install
CMD ["npm", "run", "dev"]

FROM base AS production
ARG BUILD_ENV
RUN npm ci --only=production
CMD ["node", "server.js"]

FROM ${BUILD_ENV} AS final
```

```bash
# 개발 환경 빌드
docker build --build-arg BUILD_ENV=development --target development -t myapp:dev .

# 프로덕션 빌드
docker build --build-arg BUILD_ENV=production --target production -t myapp:prod .
```

**실무 팁**:
💡 민감한 정보(비밀번호 등)는 ARG로 전달하지 말 것!
💡 빌드 시간 정보는 ARG로 전달 가능: `--build-arg BUILD_DATE=$(date)`

</details>

<details>
<summary><strong>Q7: 멀티스테이지 빌드와 docker-compose를 함께 사용하려면?</strong></summary>

**A**: **target** 옵션으로 특정 스테이지를 지정할 수 있습니다.

**상세 설명**:
- 포인트 1: docker-compose.yml에서 build.target 지정
- 포인트 2: 개발/프로덕션 환경을 별도 파일로 관리
- 포인트 3: 오버라이드 파일로 환경별 설정

**Dockerfile**:
```dockerfile
FROM node:18-alpine AS base
WORKDIR /app
COPY package*.json ./

FROM base AS development
RUN npm install
COPY . .
EXPOSE 3000 9229
CMD ["npm", "run", "dev"]

FROM base AS production
RUN npm ci --only=production
COPY --from=development /app/dist ./dist
EXPOSE 3000
CMD ["node", "dist/server.js"]
```

**docker-compose.yml (공통)**:
```yaml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
```

**docker-compose.dev.yml (개발)**:
```yaml
version: '3.8'

services:
  app:
    build:
      target: development  # 👈 개발 스테이지 지정
    volumes:
      - ./src:/app/src  # 핫 리로드
    ports:
      - "3000:3000"
      - "9229:9229"  # 디버거 포트
    environment:
      - NODE_ENV=development
```

**docker-compose.prod.yml (프로덕션)**:
```yaml
version: '3.8'

services:
  app:
    build:
      target: production  # 👈 프로덕션 스테이지 지정
      args:
        - NODE_ENV=production
    restart: always
    environment:
      - NODE_ENV=production
```

**사용법**:
```bash
# 개발 환경 실행
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up --build

# 프로덕션 환경 실행
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d --build

# 간단하게 사용하려면 Makefile 작성
# Makefile
dev:
	docker-compose -f docker-compose.yml -f docker-compose.dev.yml up

prod:
	docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
```

```bash
make dev   # 개발 환경
make prod  # 프로덕션 환경
```

**실무 팁**:
💡 .env 파일로 환경 변수 관리
💡 docker-compose.override.yml은 자동으로 로드됨 (개발자별 설정)

</details>

---

## 💼 면접 질문 리스트

### 📘 주니어/신입 개발자용

<details>
<summary><strong>1. 멀티스테이지 빌드란 무엇이며 왜 사용하나요?</strong></summary>

**모범 답안 포인트**
- 포인트 1: 하나의 Dockerfile에서 여러 FROM 문을 사용해 빌드 단계를 분리하는 기법
- 포인트 2: 빌드 도구와 의존성을 최종 이미지에서 제거하여 크기 감소
- 포인트 3: 보안 향상 (공격 표면 축소) 및 배포 속도 개선

**예시 답변**
> "멀티스테이지 빌드는 Docker 이미지를 만들 때 빌드 단계와 실행 단계를 분리하는 기법입니다. 예를 들어 Go 애플리케이션을 빌드할 때 첫 번째 스테이지에서는 Go 컴파일러로 바이너리를 만들고, 두 번째 스테이지에서는 작은 Alpine 이미지에 바이너리만 복사합니다. 이렇게 하면 1.2GB였던 이미지가 20MB로 줄어들고, 빌드 도구가 포함되지 않아 보안도 강화됩니다."

**꼬리 질문**
- Q: 싱글 스테이지와 멀티스테이지의 크기 차이는 얼마나 되나요?
- A: 언어에 따라 다르지만 보통 70-99% 감소합니다. Go는 98%, Node.js는 73%, Python은 77% 정도 감소합니다.

**실무 연관**
- 이 개념이 실무에서 어떻게 활용되는지: 마이크로서비스 환경에서 100개의 컨테이너를 운영할 때 이미지 크기가 작으면 배포 시간이 10분에서 2분으로 줄어들어 CI/CD 속도가 80% 향상됩니다.

</details>

<details>
<summary><strong>2. COPY --from 명령어는 무엇을 하나요?</strong></summary>

**모범 답안 포인트**
- 포인트 1: 이전 스테이지에서 특정 파일이나 디렉토리를 현재 스테이지로 복사
- 포인트 2: 빌드 결과물만 선택적으로 가져올 수 있음
- 포인트 3: 외부 이미지에서도 파일 복사 가능

**예시 답변**
> "COPY --from은 멀티스테이지 빌드에서 이전 스테이지의 파일을 현재 스테이지로 복사하는 명령어입니다. 예를 들어 'COPY --from=builder /app/myapp .'는 builder 스테이지의 /app/myapp 파일을 현재 스테이지로 복사합니다. 빌드 도구나 소스 코드는 가져오지 않고 필요한 실행 파일만 선택적으로 복사할 수 있어서 이미지 크기를 획기적으로 줄일 수 있습니다."

**꼬리 질문**
- Q: --from에 외부 이미지도 사용할 수 있나요?
- A: 네, 가능합니다. 예: `COPY --from=nginx:1.25-alpine /etc/nginx /etc/nginx`로 공식 이미지에서 설정 파일을 가져올 수 있습니다.

**실무 연관**
- Go 애플리케이션에서 1.2GB 이미지 중 실제 필요한 바이너리는 15MB뿐이므로, COPY --from으로 바이너리만 가져와 98% 크기 감소를 달성합니다.

</details>

<details>
<summary><strong>3. Alpine 이미지를 사용하는 이유는 무엇인가요?</strong></summary>

**모범 답안 포인트**
- 포인트 1: Alpine Linux는 매우 작은 크기 (약 5-7MB)
- 포인트 2: 보안 최소화 철학 (최소한의 패키지만 포함)
- 포인트 3: 멀티스테이지 빌드의 최종 스테이지에 적합

**예시 답변**
> "Alpine은 5MB 크기의 초경량 리눅스 배포판입니다. Ubuntu가 72MB인 것에 비해 매우 작고, 보안 최소화 원칙으로 설계되어 불필요한 패키지가 없어 공격 표면이 작습니다. 멀티스테이지 빌드에서 최종 런타임 이미지로 사용하면 전체 이미지 크기를 크게 줄일 수 있습니다."

**꼬리 질문**
- Q: Alpine의 단점은 없나요?
- A: Alpine은 glibc 대신 musl libc를 사용해서 일부 네이티브 확장 (Python psycopg2 등)이 호환되지 않을 수 있습니다. 이 경우 빌드 도구를 설치하거나 slim 이미지를 사용합니다.

**실무 연관**
- Node.js 앱에서 node:18 (900MB) 대신 node:18-alpine (120MB)을 사용하면 배포 시간이 3분에서 30초로 단축됩니다.

</details>

<details>
<summary><strong>4. 멀티스테이지 빌드에서 레이어 캐싱은 어떻게 작동하나요?</strong></summary>

**모범 답안 포인트**
- 포인트 1: 각 스테이지의 레이어가 독립적으로 캐시됨
- 포인트 2: package.json만 먼저 복사하면 의존성 설치가 캐시됨
- 포인트 3: 소스 코드 변경 시 의존성 설치는 건너뛸 수 있음

**예시 답변**
> "멀티스테이지 빌드에서도 일반 Docker 빌드와 동일하게 레이어 캐싱이 작동합니다. 중요한 팁은 자주 변경되지 않는 파일 (package.json)을 먼저 COPY하고 의존성을 설치한 뒤, 자주 변경되는 소스 코드를 나중에 COPY하는 것입니다. 이렇게 하면 소스만 수정했을 때 npm install이 캐시되어 빌드 시간이 5분에서 30초로 단축됩니다."

**꼬리 질문**
- Q: 의존성 캐싱 전략의 구체적인 예시는?
- A: `COPY package*.json ./` → `RUN npm ci` → `COPY . .` 순서로 작성하면, package.json이 변경되지 않으면 npm ci는 캐시를 사용합니다.

**실무 연관**
- CI/CD 파이프라인에서 레이어 캐시를 활용하면 평균 빌드 시간이 70% 감소하여 개발 속도가 크게 향상됩니다.

</details>

<details>
<summary><strong>5. --target 플래그는 언제 사용하나요?</strong></summary>

**모범 답안 포인트**
- 포인트 1: 특정 스테이지까지만 빌드하고 싶을 때 사용
- 포인트 2: 개발/프로덕션 환경을 하나의 Dockerfile로 관리
- 포인트 3: 테스트 스테이지를 별도로 실행 가능

**예시 답변**
> "--target 플래그는 멀티스테이지 Dockerfile에서 특정 스테이지까지만 빌드할 때 사용합니다. 예를 들어 'docker build --target development -t myapp:dev .'는 development 스테이지까지만 빌드합니다. 이를 활용하면 하나의 Dockerfile로 개발 환경 (모든 도구 포함)과 프로덕션 환경 (최소 구성)을 모두 관리할 수 있어 중복을 줄일 수 있습니다."

**꼬리 질문**
- Q: --target 없이 빌드하면 어떻게 되나요?
- A: Dockerfile의 마지막 스테이지까지 모두 빌드됩니다. 보통 마지막 스테이지를 프로덕션으로 설정합니다.

**실무 연관**
- CI/CD에서 테스트 스테이지 (`--target test`)를 먼저 실행해 테스트를 통과한 후에만 프로덕션 이미지를 빌드하여 품질을 보장합니다.

</details>

<details>
<summary><strong>6. 멀티스테이지 빌드의 보안상 이점은 무엇인가요?</strong></summary>

**모범 답안 포인트**
- 포인트 1: 빌드 도구 (gcc, make 등)가 최종 이미지에 포함되지 않음
- 포인트 2: 소스 코드가 최종 이미지에 남지 않음
- 포인트 3: 공격 표면 축소 (CVE 취약점 84% 감소)

**예시 답변**
> "멀티스테이지 빌드는 보안 측면에서 큰 이점이 있습니다. 빌드 도구 (gcc, make)나 패키지 관리자 (apt, npm)가 최종 이미지에 포함되지 않아 공격자가 악용할 수 있는 도구가 없어집니다. 또한 소스 코드도 최종 이미지에 남지 않아 코드 유출 위험이 없습니다. 실제로 싱글 스테이지는 CVE 취약점이 147개인 반면, 멀티스테이지는 23개로 84% 감소합니다."

**꼬리 질문**
- Q: 공격 표면이란 무엇인가요?
- A: 공격자가 시스템을 공격할 수 있는 진입점의 총합입니다. 패키지와 도구가 많을수록 공격 표면이 넓어집니다.

**실무 연관**
- 금융권이나 보안이 중요한 서비스에서는 멀티스테이지 빌드가 필수입니다. 빌드 도구를 제거함으로써 컨테이너 탈출 공격의 위험이 크게 줄어듭니다.

</details>

<details>
<summary><strong>7. Go 애플리케이션에 멀티스테이지 빌드가 특히 효과적인 이유는?</strong></summary>

**모범 답안 포인트**
- 포인트 1: Go는 정적 바이너리를 생성할 수 있음 (모든 의존성 포함)
- 포인트 2: 런타임에 Go 컴파일러가 필요 없음
- 포인트 3: scratch 또는 Alpine 이미지로 2-20MB까지 축소 가능

**예시 답변**
> "Go는 정적 바이너리를 생성할 수 있어 멀티스테이지 빌드의 최대 수혜자입니다. CGO_ENABLED=0로 컴파일하면 모든 의존성이 바이너리에 포함되어 런타임에 아무 것도 필요하지 않습니다. 따라서 빌드 스테이지에서 golang:1.21 (1.2GB)로 컴파일하고, 최종 스테이지에서는 scratch (0MB) 또는 alpine (5MB)에 바이너리만 복사하면 됩니다. 결과적으로 1.2GB → 15MB로 98% 감소합니다."

**꼬리 질문**
- Q: scratch 이미지를 사용할 때 주의할 점은?
- A: CA 인증서가 없어서 HTTPS 호출이 실패할 수 있습니다. alpine에서 ca-certificates를 복사하거나 distroless 이미지를 사용하면 해결됩니다.

**실무 연관**
- 마이크로서비스 아키텍처에서 50개의 Go 서비스를 운영할 때, 각 이미지가 15MB면 총 750MB이지만 최적화하지 않으면 60GB가 됩니다. 배포 시간과 비용이 80배 차이납니다.

</details>

---

### 📗 중급 개발자용

<details>
<summary><strong>1. 멀티스테이지 빌드에서 의존성 캐싱을 최대화하는 고급 전략은?</strong></summary>

**모범 답안 포인트**
- 심화 포인트 1: 의존성 설치를 별도 스테이지로 분리
- 심화 포인트 2: 개발/프로덕션 의존성을 각각 캐싱
- 내부 동작 원리: Docker 빌드 캐시는 레이어 해시로 작동

**예시 답변**
> "고급 전략은 의존성 설치를 별도 스테이지로 분리하는 것입니다. 첫 번째 스테이지에서 package.json만 복사하고 npm ci로 개발 의존성을 설치하고, 두 번째 스테이지에서 프로덕션 의존성만 설치합니다. 세 번째 스테이지에서 소스를 복사하고 빌드하며, 마지막 스테이지에서 프로덕션 의존성과 빌드 결과물만 복사합니다. 이렇게 하면 package.json이 변경되지 않는 한 모든 의존성 설치가 캐시되어 빌드 시간이 2분에서 5초로 단축됩니다."

**실무 예시**
```dockerfile
# Stage 1: 개발 의존성 캐싱
FROM node:18-alpine AS dev-deps
WORKDIR /deps
COPY package*.json ./
RUN npm ci

# Stage 2: 프로덕션 의존성 캐싱
FROM node:18-alpine AS prod-deps
WORKDIR /deps
COPY package*.json ./
RUN npm ci --only=production

# Stage 3: 빌드
FROM node:18-alpine AS builder
WORKDIR /build
COPY --from=dev-deps /deps/node_modules ./node_modules
COPY . .
RUN npm run build && npm run test

# Stage 4: 최종
FROM node:18-alpine
WORKDIR /app
COPY --from=prod-deps /deps/node_modules ./node_modules
COPY --from=builder /build/dist ./dist
CMD ["node", "dist/server.js"]
```

**꼬리 질문**
- Q: BuildKit의 캐시 마운트 기능은 어떻게 다릅니까?
- A: `RUN --mount=type=cache,target=/root/.npm`을 사용하면 빌드 간에 캐시를 공유할 수 있어 CI/CD에서 더 효과적입니다.

**실무 연관**
- 실제 프로젝트에서의 적용 사례: 대규모 모노레포에서 여러 패키지를 빌드할 때, 공통 의존성을 캐싱하면 전체 빌드 시간이 30분에서 5분으로 단축됩니다.
- 성능 측정 결과: 첫 빌드 120초, 소스만 변경 시 8초, package.json 변경 시 45초

</details>

<details>
<summary><strong>2. Distroless 이미지와 Alpine의 차이점과 선택 기준은?</strong></summary>

**모범 답안 포인트**
- 심화 포인트 1: Distroless는 셸이 없어 최고 수준의 보안
- 심화 포인트 2: Alpine은 디버깅 가능, Distroless는 불가능
- 내부 동작 원리: Distroless는 런타임만 포함 (언어별로 다름)

**예시 답변**
> "Distroless는 Google이 만든 초경량 이미지로 셸, 패키지 관리자, 디버깅 도구가 전혀 없습니다. 반면 Alpine은 5MB 크기지만 apk 패키지 관리자와 busybox 셸이 있어 디버깅이 가능합니다. Distroless는 Go, Java 같은 컴파일 언어에 적합하고 (정적 바이너리), Alpine은 Python, Node.js 같은 동적 언어에 적합합니다. 선택 기준은 개발 단계에서는 Alpine (디버깅 가능), 프로덕션에서는 Distroless (보안 최대화)입니다."

**실무 예시**
```dockerfile
# 개발: Alpine 사용
FROM golang:1.21-alpine AS builder
WORKDIR /build
COPY . .
RUN go build -o app .

FROM alpine:3.18 AS development
RUN apk add --no-cache curl vim  # 디버깅 도구
COPY --from=builder /build/app .
CMD ["./app"]

# 프로덕션: Distroless 사용
FROM gcr.io/distroless/static-debian11 AS production
COPY --from=builder /build/app /app
CMD ["/app"]
```

**크기 및 보안 비교**:
| 이미지 | 크기 | 셸 | 패키지 관리자 | CVE 취약점 |
|--------|------|-----|---------------|-----------|
| ubuntu:20.04 | 72MB | O | apt | 147개 |
| alpine:3.18 | 7MB | O | apk | 23개 |
| distroless/static | 2MB | X | X | 0개 |

**꼬리 질문**
- Q: Distroless에서 디버깅이 필요하면 어떻게 하나요?
- A: :debug 태그를 사용하거나 (busybox 포함), 개발 환경에서는 Alpine을 사용하고 프로덕션만 Distroless를 사용합니다.

**실무 연관**
- 금융권에서는 PCI-DSS 준수를 위해 Distroless를 사용합니다. 셸이 없어 컨테이너 탈출 공격의 위험이 거의 제로입니다.

</details>

<details>
<summary><strong>3. 멀티스테이지 빌드에서 병렬 빌드를 어떻게 구현하나요?</strong></summary>

**모범 답안 포인트**
- 심화 포인트 1: 독립적인 스테이지는 자동으로 병렬 실행됨
- 심화 포인트 2: BuildKit을 활성화해야 병렬 빌드 가능
- 내부 동작 원리: DAG (의존성 그래프)로 병렬 가능 여부 판단

**예시 답변**
> "Docker BuildKit은 의존성 그래프를 분석하여 독립적인 스테이지를 자동으로 병렬 실행합니다. 예를 들어 프론트엔드 빌드와 백엔드 빌드가 서로 독립적이면 동시에 실행됩니다. DOCKER_BUILDKIT=1을 설정하면 활성화되며, 병렬 빌드로 전체 빌드 시간이 50% 단축됩니다."

**실무 예시**
```dockerfile
# 프론트엔드와 백엔드를 병렬로 빌드
# Stage 1: 프론트엔드 (독립적)
FROM node:18-alpine AS frontend
WORKDIR /frontend
COPY frontend/package*.json ./
RUN npm ci
COPY frontend/ ./
RUN npm run build
# 결과: /frontend/dist

# Stage 2: 백엔드 (독립적, 프론트엔드와 병렬 실행)
FROM golang:1.21-alpine AS backend
WORKDIR /backend
COPY backend/go.mod backend/go.sum ./
RUN go mod download
COPY backend/ ./
RUN go build -o server .
# 결과: /backend/server

# Stage 3: 최종 (frontend와 backend를 모두 기다림)
FROM alpine:3.18
COPY --from=backend /backend/server /app/server
COPY --from=frontend /frontend/dist /app/public
CMD ["/app/server"]
```

**병렬 실행 확인**:
```bash
DOCKER_BUILDKIT=1 docker build -t fullstack .
# [frontend 4/5] RUN npm run build...  ⚙️
# [backend 4/5] RUN go build...       ⚙️ (동시 실행!)
```

**꼬리 질문**
- Q: 병렬 빌드의 한계는 무엇인가요?
- A: CPU 코어 수에 제한되며, 의존성이 있는 스테이지는 병렬 실행 불가능합니다.

**실무 연관**
- 대규모 모노레포에서 10개의 마이크로서비스를 동시에 빌드하면 병렬 처리로 전체 빌드 시간이 100분에서 20분으로 단축됩니다 (5배 빠름).

</details>

<details>
<summary><strong>4. 멀티스테이지 빌드에서 비밀 정보(secrets)를 안전하게 다루는 방법은?</strong></summary>

**모범 답안 포인트**
- 심화 포인트 1: ARG/ENV로 비밀 정보를 전달하면 이미지에 남음 (위험)
- 심화 포인트 2: BuildKit의 --secret 플래그 사용
- 내부 동작 원리: 비밀 정보는 임시 마운트로만 전달되어 레이어에 남지 않음

**예시 답변**
> "비밀 정보 (API 키, 비밀번호)를 ARG나 ENV로 전달하면 docker history로 볼 수 있어 위험합니다. BuildKit의 --secret 플래그를 사용하면 비밀 정보가 임시 마운트로만 전달되어 최종 이미지에 남지 않습니다. RUN --mount=type=secret,id=npm_token 형태로 사용하고, docker build --secret id=npm_token,src=.npmrc로 전달합니다."

**실무 예시**
```dockerfile
# ❌ 위험한 방법
FROM node:18-alpine
ARG NPM_TOKEN  # 👈 이미지 레이어에 기록됨!
RUN echo "//registry.npmjs.org/:_authToken=${NPM_TOKEN}" > .npmrc
RUN npm install
```

```bash
docker history myapp
# ARG NPM_TOKEN=abc123def456...  😱 노출됨!
```

```dockerfile
# ✅ 안전한 방법 (BuildKit)
# syntax=docker/dockerfile:1.4
FROM node:18-alpine AS builder

WORKDIR /app
COPY package*.json ./

# 비밀 정보를 임시 마운트로만 사용
RUN --mount=type=secret,id=npm_token \
    echo "//registry.npmjs.org/:_authToken=$(cat /run/secrets/npm_token)" > .npmrc && \
    npm ci && \
    rm -f .npmrc  # 👈 비밀 정보 즉시 삭제

COPY . .
RUN npm run build

FROM node:18-alpine
WORKDIR /app
COPY --from=builder /app/dist ./dist
CMD ["node", "dist/server.js"]
```

```bash
# 빌드 시 비밀 정보 전달
DOCKER_BUILDKIT=1 docker build \
  --secret id=npm_token,src=$HOME/.npmrc \
  -t myapp .

# 확인: 이미지에 비밀 정보가 없음
docker history myapp  # NPM_TOKEN 없음 ✅
```

**추가 보안 팁**:
```dockerfile
# SSH 키도 안전하게 사용
RUN --mount=type=ssh \
    git clone git@github.com:private/repo.git

# 다중 비밀 정보
RUN --mount=type=secret,id=db_password \
    --mount=type=secret,id=api_key \
    ./configure.sh
```

**꼬리 질문**
- Q: --secret 없이 BuildKit 이전에는 어떻게 했나요?
- A: 다단계 빌드로 비밀 정보를 사용하는 레이어를 중간 스테이지에 두고 최종 스테이지에는 복사하지 않는 방법을 사용했습니다.

**실무 연관**
- 금융권에서는 PCI-DSS 준수를 위해 비밀 정보가 이미지에 남지 않도록 --secret을 필수로 사용합니다. 코드 감사 시 docker history로 비밀 정보가 노출되지 않음을 증명해야 합니다.

</details>

<details>
<summary><strong>5. 멀티스테이지 빌드의 성능을 프로파일링하고 최적화하는 방법은?</strong></summary>

**모범 답안 포인트**
- 심화 포인트 1: docker build --progress=plain으로 상세 로그 확인
- 심화 포인트 2: 각 레이어의 실행 시간 측정
- 내부 동작 원리: BuildKit의 트레이스 로그 분석

**예시 답변**
> "멀티스테이지 빌드의 병목을 찾으려면 --progress=plain 플래그로 각 레이어의 실행 시간을 확인합니다. 예를 들어 npm install이 2분 걸린다면 package.json을 먼저 복사해 캐싱하거나, --mount=type=cache로 npm 캐시를 공유하면 30초로 단축됩니다. BuildKit의 --debug 플래그로 더 상세한 트레이스 로그를 확인할 수도 있습니다."

**실무 예시**
```bash
# 상세 빌드 로그 확인
DOCKER_BUILDKIT=1 docker build --progress=plain -t myapp . 2>&1 | tee build.log

# 출력 예시:
# [builder 3/8] COPY package*.json ./                0.1s
# [builder 4/8] RUN npm ci                           120.5s  👈 병목!
# [builder 5/8] COPY . .                             2.3s
# [builder 6/8] RUN npm run build                    45.2s
```

**최적화 전략**:

**1. 캐시 마운트 활용**
```dockerfile
# ❌ 최적화 전
RUN npm ci  # 매번 120초 소요

# ✅ 최적화 후
RUN --mount=type=cache,target=/root/.npm \
    npm ci  # 첫 실행 후 15초로 단축!
```

**2. 병렬 실행 최적화**
```dockerfile
# ❌ 순차 실행
FROM node:18-alpine AS builder
RUN npm install  # 60초
RUN npm run build  # 40초
RUN npm run test  # 30초
# 총 130초

# ✅ 병렬 실행
FROM node:18-alpine AS build
RUN npm install && npm run build  # 100초 (병렬)

FROM node:18-alpine AS test
RUN npm install && npm run test  # 90초 (build와 병렬 실행)
# 총 100초 (build와 test가 동시 실행)
```

**3. 레이어 크기 분석**
```bash
# 각 레이어의 크기 확인
docker history myapp --no-trunc

# 출력:
# IMAGE          SIZE
# abc123         150MB  # RUN npm install  👈 너무 큼!
# def456         2MB    # COPY package*.json
```

**최적화 체크리스트**:
```bash
# 1. 불필요한 파일 제거
RUN npm ci --only=production && \
    npm cache clean --force  # 캐시 제거

# 2. 멀티 코어 활용
RUN make -j$(nproc)  # 병렬 컴파일

# 3. 레이어 병합
RUN apt-get update && \
    apt-get install -y pkg && \
    rm -rf /var/lib/apt/lists/*  # 한 레이어로 병합
```

**꼬리 질문**
- Q: BuildKit의 LLB (Low-Level Builder)는 무엇인가요?
- A: BuildKit의 내부 중간 표현으로, Dockerfile을 최적화된 빌드 그래프로 변환합니다. 병렬 실행과 캐싱 최적화가 가능합니다.

**실무 연관**
- 대규모 CI/CD 환경에서 빌드 시간이 15분이었던 프로젝트를 프로파일링한 결과, 테스트 스테이지가 병목임을 발견하고 병렬화하여 5분으로 단축했습니다 (67% 개선).
- 성능 측정 결과: 빌드 시간 15분 → 5분, 캐시 적중률 30% → 85%, CI/CD 비용 월 $500 → $150 (70% 절감)

</details>

---

## 🎉 축하합니다!

**Docker 멀티스테이지 빌드 마스터를 축하드립니다!**

**이제 여러분은**:
✅ 멀티스테이지 빌드로 이미지 크기를 80-99% 감소시킬 수 있습니다
✅ 빌드와 런타임을 분리하여 보안을 강화할 수 있습니다
✅ 레이어 캐싱을 최적화하여 빌드 시간을 90% 단축할 수 있습니다
✅ Go, Node.js, Python 등 다양한 언어에 멀티스테이지를 적용할 수 있습니다
✅ Alpine, Distroless 등 최적의 베이스 이미지를 선택할 수 있습니다
✅ --target, --secret 등 고급 기능을 활용할 수 있습니다
✅ 프로덕션 환경에 최적화된 Docker 이미지를 만들 수 있습니다

**다음 단계**:
- [ ] 다음 장 (섹션 9: 이미지 최적화 심화)으로 진행
- [ ] 실전 프로젝트: 풀스택 애플리케이션 멀티스테이지 빌드 도전
- [ ] 면접 질문 복습 및 답변 연습

**실무 적용 체크리스트**:
- [ ] 기존 싱글 스테이지 Dockerfile을 멀티스테이지로 변환
- [ ] 이미지 크기 측정 및 비교 (before/after)
- [ ] .dockerignore 파일 작성
- [ ] 레이어 캐싱 전략 적용
- [ ] CI/CD 파이프라인에 멀티스테이지 빌드 통합
- [ ] 보안 스캔 (trivy 등)으로 취약점 확인

**추가 학습 자료**:
- 📖 Docker 공식 문서: Multi-stage builds
- 📖 Best practices for writing Dockerfiles
- 🎥 BuildKit 고급 기능 가이드

---

## 8.8 다음 단계

멀티스테이지 빌드를 마스터했습니다! 다음 섹션에서는:

- **섹션 9: 이미지 최적화 심화** - 이미지 크기를 더 줄이는 고급 기법
- **섹션 10: Docker 네트워크** - 컨테이너 간 통신 설정

계속 학습하세요!