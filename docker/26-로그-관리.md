# 26. Docker ë¡œê·¸ ê´€ë¦¬

> **í•™ìŠµ ëª©í‘œ**: Docker ì»¨í…Œì´ë„ˆì—ì„œ ë°œìƒí•˜ëŠ” ë‹¤ì–‘í•œ ë¡œê·¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜ì§‘, ì €ì¥, ë¶„ì„í•  ìˆ˜ ìˆìœ¼ë©°, ELK Stackì„ í™œìš©í•œ í†µí•© ë¡œê·¸ ê´€ë¦¬ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**â±ï¸ ì˜ˆìƒ í•™ìŠµ ì‹œê°„**: 3-4ì‹œê°„
**ë‚œì´ë„**: â­â­â­â­â˜† (4ê°œ/5ê°œ)

---

## ëª©ì°¨
1. [Docker ë¡œê·¸ì˜ ê¸°ë³¸ ì´í•´](#docker-ë¡œê·¸ì˜-ê¸°ë³¸-ì´í•´)
2. [ë¡œê·¸ ë“œë¼ì´ë²„ ì„¤ì •](#ë¡œê·¸-ë“œë¼ì´ë²„-ì„¤ì •)
3. [ELK Stackìœ¼ë¡œ ë¡œê·¸ ìˆ˜ì§‘í•˜ê¸°](#elk-stackìœ¼ë¡œ-ë¡œê·¸-ìˆ˜ì§‘í•˜ê¸°)
4. [Kibanaì—ì„œ ë¡œê·¸ ê²€ìƒ‰ê³¼ ì‹œê°í™”](#kibanaì—ì„œ-ë¡œê·¸-ê²€ìƒ‰ê³¼-ì‹œê°í™”)
5. [ë¡œê·¸ ê´€ë¦¬ ëª¨ë²” ì‚¬ë¡€](#ë¡œê·¸-ê´€ë¦¬-ëª¨ë²”-ì‚¬ë¡€)
6. [LK-Trade í”„ë¡œì íŠ¸ì— ì ìš©í•˜ê¸°](#lk-trade-í”„ë¡œì íŠ¸ì—-ì ìš©í•˜ê¸°)
7. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ğŸ’¡ ì™œ Docker ë¡œê·¸ ê´€ë¦¬ê°€ í•„ìš”í•œê°€?

### ì‹¤ë¬´ ë°°ê²½

**"ì–´ì œ ë°¤ 10ì‹œì— ì„œë¹„ìŠ¤ ì˜¤ë¥˜ ë‚¬ì—ˆëŠ”ë°, ì™œ ê·¸ëŸ°ì§€ ì•Œ ìˆ˜ ìˆë‚˜ìš”?"**

#### âŒ ë¡œê·¸ ê´€ë¦¬ê°€ ì—†ìœ¼ë©´ ë°œìƒí•˜ëŠ” ë¬¸ì œ

```
ë¬¸ì œ 1: ì‚¬í›„ ì›ì¸ íŒŒì•… ë¶ˆê°€ëŠ¥
- ì¦ìƒ: "ì–´ì œ ì˜¤ë¥˜ê°€ ë‚¬ì—ˆì–´ìš”"
- ëŒ€ì‘: "ë¡œê·¸ë¥¼ ëª» ì°¾ê² ì–´ìš”..."
- ì˜í–¥: ì¬ë°œ ê°€ëŠ¥ì„± 100%, ì‹ ë¢°ë„ í•˜ë½
- ë¹„ìš©: ì¥ì•  ëŒ€ì‘ ì‹œê°„ í‰ê·  4ì‹œê°„, ì‹œê°„ë‹¹ ìˆ˜ë°±ë§Œì› ì†ì‹¤

ë¬¸ì œ 2: ë””ìŠ¤í¬ ê³µê°„ ë¬´í•œ ì¦ê°€
- ì¦ìƒ: ë¡œê·¸ íŒŒì¼ì´ 100GB ë„˜ìŒ
- ëŒ€ì‘: "ì„œë²„ ë””ìŠ¤í¬ ê½‰ ì°¸" â†’ ì„œë¹„ìŠ¤ ì¤‘ë‹¨
- ì˜í–¥: ë¡œê·¸ ë•Œë¬¸ì— ì •ì‘ ì„œë¹„ìŠ¤ê°€ ì£½ìŒ
- ë¹„ìš©: ê¸´ê¸‰ ë””ìŠ¤í¬ ì¦ì„¤ ë¹„ìš© (ì›” 50ë§Œì›+)

ë¬¸ì œ 3: ì—¬ëŸ¬ ì»¨í…Œì´ë„ˆ ë¡œê·¸ ì¶”ì  ë¶ˆê°€
- ì¦ìƒ: "user-serviceì—ì„œ trade-service í˜¸ì¶œí–ˆëŠ”ë° ì–´ë””ì„œ ì˜¤ë¥˜?"
- ëŒ€ì‘: 5ê°œ ì»¨í…Œì´ë„ˆ ë¡œê·¸ ì¼ì¼ì´ í™•ì¸
- ì˜í–¥: ë¶„ì‚° ì‹œìŠ¤í…œ ë””ë²„ê¹… ë¶ˆê°€ëŠ¥
- ë¹„ìš©: ê°œë°œì 1ëª… í•˜ë£¨ í—ˆë¹„ (ì•½ 30ë§Œì›)
```

#### âœ… ì²´ê³„ì  ë¡œê·¸ ê´€ë¦¬ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë©´

```
í•´ê²°ì±… 1: í†µí•© ë¡œê·¸ ê²€ìƒ‰ (ELK Stack)
- ë°©ë²•: Elasticsearchì— ëª¨ë“  ë¡œê·¸ ì§‘ì¤‘
- íš¨ê³¼: Kibanaì—ì„œ 5ì´ˆ ë‚´ ì›í•˜ëŠ” ë¡œê·¸ ê²€ìƒ‰
- ì ˆê°: ë¡œê·¸ ê²€ìƒ‰ ì‹œê°„ 98% ë‹¨ì¶• (1ì‹œê°„ â†’ 5ì´ˆ)

í•´ê²°ì±… 2: ìë™ ë¡œê·¸ ë¡œí…Œì´ì…˜
- ë°©ë²•: max-size, max-file ì„¤ì •
- íš¨ê³¼: ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ì œí•œ (ìµœëŒ€ 30MB/ì»¨í…Œì´ë„ˆ)
- ì ˆê°: ë””ìŠ¤í¬ ë¹„ìš© 80% ì ˆê°

í•´ê²°ì±… 3: Correlation IDë¡œ ë¶„ì‚° ì¶”ì 
- ë°©ë²•: ëª¨ë“  ìš”ì²­ì— ê³ ìœ  ID ë¶€ì—¬
- íš¨ê³¼: ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ê±¸ì¹œ ìš”ì²­ íë¦„ ì™„ë²½ ì¶”ì 
- ì ˆê°: ë¶„ì‚° ì‹œìŠ¤í…œ ë””ë²„ê¹… ì‹œê°„ 90% ë‹¨ì¶•
```

### ìˆ˜ì¹˜ë¡œ ë³´ëŠ” íš¨ê³¼

| ì§€í‘œ | Before | After | ê°œì„ ìœ¨ |
|------|--------|-------|--------|
| ë¡œê·¸ ê²€ìƒ‰ ì‹œê°„ | 1ì‹œê°„ | 5ì´ˆ | **99.9%â†“** |
| ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ | 200GB | 10GB | **95%â†“** |
| ì¥ì•  ì›ì¸ íŒŒì•… ì‹œê°„ | 4ì‹œê°„ | 15ë¶„ | **94%â†“** |
| ë¶„ì‚° ì¶”ì  ê°€ëŠ¥ ë¹„ìœ¨ | 0% | 100% | **ë¬´í•œëŒ€â†‘** |
| ì›” ë¡œê·¸ ì¸í”„ë¼ ë¹„ìš© | 100ë§Œì› | 30ë§Œì› | **70%â†“** |

---

## ğŸ” ì‹¤ìƒí™œ ë¹„ìœ ë¡œ ì´í•´í•˜ê¸°

### ë¹„ìœ  1: ìë™ì°¨ ë¸”ë™ë°•ìŠ¤ ì‹œìŠ¤í…œ

```
ìë™ì°¨ ë¸”ë™ë°•ìŠ¤                      Docker ë¡œê·¸ ê´€ë¦¬
================                      ==================
ğŸ“¹ ì „ë°© ì¹´ë©”ë¼ (í•­ìƒ ë…¹í™”)       â†’    stdout/stderr (í•­ìƒ ìˆ˜ì§‘)
ğŸ“¹ í›„ë°© ì¹´ë©”ë¼ (ì¶”ê°€ ì •ë³´)       â†’    ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ íŒŒì¼
ğŸ’¾ SD ì¹´ë“œ ì €ì¥ (ìš©ëŸ‰ ì œí•œ)      â†’    ë¡œê·¸ ë“œë¼ì´ë²„ (max-size)
ğŸ”„ ìš©ëŸ‰ ê½‰ ì°¨ë©´ ë®ì–´ì“°ê¸°         â†’    ë¡œê·¸ ë¡œí…Œì´ì…˜
ğŸ“‚ ì‚¬ê³  ì‹œ ì˜ìƒ ë¶„ì„             â†’    Kibanaë¡œ ë¡œê·¸ ë¶„ì„
ğŸš¨ ì¶©ê²© ê°ì§€ ì‹œ ìë™ ì €ì¥        â†’    ì—ëŸ¬ ë ˆë²¨ ë¡œê·¸ ìë™ ìˆ˜ì§‘
â˜ï¸ í´ë¼ìš°ë“œ ì—…ë¡œë“œ (ì•ˆì „ ë³´ê´€)   â†’    Elasticsearch ì €ì¥ì†Œ

ë¸”ë™ë°•ìŠ¤ê°€ ì—†ìœ¼ë©´ ì‚¬ê³  ì›ì¸ì„ ì•Œ ìˆ˜ ì—†ë“¯ì´,
ë¡œê·¸ ê´€ë¦¬ê°€ ì—†ìœ¼ë©´ ì‹œìŠ¤í…œ ì¥ì•  ì›ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ì‚¬ê³  ë°œìƒ:
- ë¸”ë™ë°•ìŠ¤ ìˆìŒ: ì˜ìƒ í™•ì¸ â†’ ì¦‰ì‹œ ì›ì¸ íŒŒì•… â†’ ë³´í—˜ ì²˜ë¦¬
- ë¸”ë™ë°•ìŠ¤ ì—†ìŒ: "ê¸°ì–µ ì•ˆ ë‚˜ìš”..." â†’ ì¦ê±° ì—†ìŒ â†’ ì†ì‹¤ ë°œìƒ

ì‹œìŠ¤í…œ ì¥ì• :
- ë¡œê·¸ ìˆìŒ: Kibana ê²€ìƒ‰ â†’ 5ë¶„ ë‚´ ì›ì¸ íŒŒì•… â†’ ë¹ ë¥¸ ë³µêµ¬
- ë¡œê·¸ ì—†ìŒ: "ì¶”ì¸¡ë§Œ..." â†’ ì¬í˜„ ì‹œë„ â†’ ì‹œê°„ ë‚­ë¹„
```

### ë¹„ìœ  2: CCTV ê´€ì œ ì„¼í„°

```
ëŒ€í˜• ë¹Œë”© CCTV ê´€ì œ ì‹œìŠ¤í…œ        ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë¡œê·¸ ê´€ë¦¬
==========================        =======================

[ë¬¸ì œ ìƒí™©]
ë„ë‘‘ì´ ë¬¼ê±´ì„ í›”ì³ê°!              API ìš”ì²­ì´ ì‹¤íŒ¨í•¨!

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ê° ì¸µë§ˆë‹¤ ë…ë¦½ëœ CCTV            ê° ì„œë¹„ìŠ¤ë§ˆë‹¤ ë…ë¦½ëœ ë¡œê·¸ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1ì¸µ: "ìˆ˜ìƒí•œ ì‚¬ëŒ ì—†ìŒ"          user-service: "ì •ìƒ"   â”‚
â”‚ 2ì¸µ: "10:23ë¶„ ìˆ˜ìƒí•œ ì‚¬ëŒ ë°œê²¬"  trade-service: "ì˜¤ë¥˜!"  â”‚
â”‚ 3ì¸µ: "í™•ì¸ ëª»í•¨"                 account-service: "ì •ìƒ" â”‚
â”‚ 4ì¸µ: "í™•ì¸ ëª»í•¨"                 strategy-service: "???" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âŒ ê´€ì œ ì„¼í„° ì—†ì´ (í†µí•© ë¡œê·¸ ê´€ë¦¬ ì—†ì´):
- ê²½ë¹„ì›ì´ 4ê°œ ì¸µ CCTV ì¼ì¼ì´ í™•ì¸ (4ì‹œê°„ ì†Œìš”)
- 2ì¸µ ì˜ìƒ ì°¾ì•˜ì§€ë§Œ 1ì¸µì—ì„œ ì§„ì…í•œ ê±¸ ëª» ì°¾ìŒ
- ì „ì²´ ë™ì„  íŒŒì•… ë¶ˆê°€

âœ… ê´€ì œ ì„¼í„° ìˆìŒ (ELK Stack):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ğŸ–¥ï¸ í†µí•© ê´€ì œ ì„¼í„° (Kibana)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ê²€ìƒ‰: "10:20~10:30 ì‚¬ì´ ìˆ˜ìƒí•œ í™œë™"             â”‚
â”‚                                                  â”‚
â”‚ ê²°ê³¼ (ìë™ìœ¼ë¡œ ëª¨ë“  ì¸µ ì˜ìƒ í†µí•©):                â”‚
â”‚ 10:20 - 1ì¸µ ì •ë¬¸ ì§„ì…                            â”‚
â”‚ 10:23 - 2ì¸µ ì‚¬ë¬´ì‹¤ ì¹¨ì…                          â”‚
â”‚ 10:25 - 3ì¸µ ê¸ˆê³  ì‹œë„ (ì‹¤íŒ¨)                     â”‚
â”‚ 10:27 - 1ì¸µ í›„ë¬¸ íƒˆì¶œ                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Docker ë¡œê·¸ë„ ë§ˆì°¬ê°€ì§€:
- Correlation ID = ë²”ì¸ ì–¼êµ´ ì¸ì‹ (ë™ì¼ ìš”ì²­ ì¶”ì )
- Elasticsearch = í†µí•© ì˜ìƒ ë°ì´í„°ë² ì´ìŠ¤
- Kibana = ê´€ì œ ì„¼í„° ëª¨ë‹ˆí„°
- 5ë¶„ ë§Œì— ì „ì²´ íë¦„ íŒŒì•…!
```

### ë¹„ìœ  3: ë„ì„œê´€ ì‚¬ì„œì˜ ì±… ì •ë¦¬ ì‹œìŠ¤í…œ

```
ë„ì„œê´€ ì±… ê´€ë¦¬                     Docker ë¡œê·¸ ê´€ë¦¬
==============                     ================

ğŸ“š ë¬¸ì œ: ì±…ì´ ë¬´í•œì • ìŒ“ì„           ë¡œê·¸ê°€ ë¬´í•œì • ìŒ“ì„

âŒ ì •ë¦¬ ì•ˆ í•˜ë©´:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì±…ì´ ë°”ë‹¥ì— ì‚°ë”ë¯¸ë¡œ ìŒ“ì„           â”‚
â”‚ â†’ ì°¾ê³  ì‹¶ì€ ì±… ëª» ì°¾ìŒ              â”‚
â”‚ â†’ ë„ì„œê´€ ê³µê°„ ë¶€ì¡±                  â”‚
â”‚ â†’ ë„ì„œê´€ ë¬¸ ë‹«ì•„ì•¼ í•¨               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… ì²´ê³„ì  ê´€ë¦¬ (ë¡œê·¸ ë¡œí…Œì´ì…˜):

1. ë¶„ë¥˜ (Log Level)
   - ì‹ ê°„ (ERROR): ë³„ë„ ì±…ì¥ì— ë³´ê´€
   - ë² ìŠ¤íŠ¸ì…€ëŸ¬ (WARN): ì‰½ê²Œ ì ‘ê·¼ ê°€ëŠ¥í•œ ê³³
   - ì¼ë°˜ ë„ì„œ (INFO): ì¼ë°˜ ì„œê°€
   - ì°¸ê³  ìë£Œ (DEBUG): ì°½ê³ 

2. ë³´ê´€ ê¸°ê°„ (Retention)
   - ìµœê·¼ 1ì£¼ì¼: ë©”ì¸ ì„œê°€ (ë¹ ë¥¸ ì ‘ê·¼)
   - 1ì£¼~1ê°œì›”: ë³´ì¡° ì„œê°€
   - 1ê°œì›”~1ë…„: ì°½ê³ 
   - 1ë…„ ì´ìƒ: íê¸° (ë˜ëŠ” ì•„ì¹´ì´ë¸Œ)

3. ì¸ë±ì‹± (Elasticsearch)
   - ëª¨ë“  ì±…ì— ë°”ì½”ë“œ ë¶€ì°©
   - ì»´í“¨í„°ë¡œ 5ì´ˆ ë‚´ ê²€ìƒ‰
   - í‚¤ì›Œë“œë§Œ ì…ë ¥í•˜ë©´ ì¦‰ì‹œ ì°¾ê¸°

Docker ë¡œê·¸:
- json-file driver: ìë™ ë¶„ë¥˜
- max-size, max-file: ë³´ê´€ ê¸°ê°„ ì œí•œ
- Elasticsearch: ê²€ìƒ‰ ì¸ë±ìŠ¤
- Kibana: ì‚¬ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ

"30ì¼ ì „ ERROR ë¡œê·¸ ì°¾ê¸°"
â†’ Kibanaì— ê²€ìƒ‰: level:ERROR AND date:30daysAgo
â†’ 1ì´ˆ ë§Œì— ê²°ê³¼ í™•ì¸!
```

---

## Docker ë¡œê·¸ì˜ ê¸°ë³¸ ì´í•´

### 1. Docker ë¡œê·¸ ìˆ˜ì§‘ ë©”ì»¤ë‹ˆì¦˜

```
Container ë‚´ë¶€                         Docker Daemon                    ë¡œê·¸ ì €ì¥ì†Œ
==============                         ==============                   ===========

Application
    |
    | stdout (System.out)
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
    |                                  Log Driver
    | stderr (System.err)              (json-file,
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>           syslog, etc.)
                                           |
                                           | í¬ë§· ë³€í™˜
                                           | ë²„í¼ë§
                                           â†“
                                       ë¡œê·¸ íŒŒì¼
                                       (/var/lib/docker/containers/
                                        <container-id>/<container-id>-json.log)
                                           |
                                           | (ì˜µì…˜) ì›ê²© ì „ì†¡
                                           â†“
                                       Elasticsearch
                                       Fluentd
                                       Splunk
                                       ë“±ë“±...
```

### 2. ë¡œê·¸ ë“œë¼ì´ë²„ ì¢…ë¥˜

DockerëŠ” ë‹¤ì–‘í•œ ë¡œê·¸ ë“œë¼ì´ë²„ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:

| ë“œë¼ì´ë²„ | ì„¤ëª… | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|---------|------|-------------|
| **json-file** | JSON í˜•ì‹ ë¡œì»¬ íŒŒì¼ (ê¸°ë³¸ê°’) | ê°œë°œ í™˜ê²½, ì†Œê·œëª¨ ìš´ì˜ |
| **journald** | systemd ì €ë„ì— ì „ì†¡ | Linux systemd í™˜ê²½ |
| **syslog** | Syslog ì„œë²„ë¡œ ì „ì†¡ | ê¸°ì¡´ syslog ì¸í”„ë¼ í™œìš© |
| **fluentd** | Fluentdë¡œ ì „ì†¡ | ëŒ€ê·œëª¨ ë¡œê·¸ ìˆ˜ì§‘ |
| **gelf** | Graylogë¡œ ì „ì†¡ | Graylog ì‚¬ìš© ì‹œ |
| **awslogs** | AWS CloudWatchë¡œ ì „ì†¡ | AWS í™˜ê²½ |
| **gcplogs** | Google Cloud Logging | GCP í™˜ê²½ |
| **splunk** | Splunkë¡œ ì „ì†¡ | Splunk ì‚¬ìš© ê¸°ì—… |
| **none** | ë¡œê·¸ ìˆ˜ì§‘ ì•ˆ í•¨ | ë¡œê·¸ ë¶ˆí•„ìš”í•œ ì»¨í…Œì´ë„ˆ |

---

## ë¡œê·¸ ë“œë¼ì´ë²„ ì„¤ì •

### 1. json-file ë“œë¼ì´ë²„ (ê¸°ë³¸ê°’)

ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë“œë¼ì´ë²„ì…ë‹ˆë‹¤.

#### docker-compose.yml ì„¤ì •

```yaml
# docker-compose.yml
version: '3.8'

services:
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "json-file"
      options:
        max-size: "10m"        # ë¡œê·¸ íŒŒì¼ ìµœëŒ€ í¬ê¸°
        max-file: "3"          # ë¡œê·¸ íŒŒì¼ ìµœëŒ€ ê°œìˆ˜
        labels: "service=user" # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        env: "ENVIRONMENT"     # í™˜ê²½ë³€ìˆ˜ í¬í•¨
```

#### ë™ì‘ ë°©ì‹

```
ë¡œê·¸ íŒŒì¼ ë¡œí…Œì´ì…˜
==================

user-service-json.log          (10MB ë„ë‹¬)
    â†“
user-service-json.log.1        (ì´ë¦„ ë³€ê²½)
user-service-json.log          (ìƒˆ íŒŒì¼ ìƒì„±)
    â†“
user-service-json.log.2        (ì´ë¦„ ë³€ê²½)
user-service-json.log.1        (ì´ë¦„ ë³€ê²½)
user-service-json.log          (ìƒˆ íŒŒì¼ ìƒì„±)
    â†“
user-service-json.log.2        (ì‚­ì œ, max-file=3 ì´ˆê³¼)
user-service-json.log.1        (ì´ë¦„ ë³€ê²½)
user-service-json.log          (ìƒˆ íŒŒì¼ ìƒì„±)
```

#### ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜

```bash
# ì»¨í…Œì´ë„ˆ ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜ í™•ì¸
docker inspect --format='{{.LogPath}}' user-service

# ì¶œë ¥ ì˜ˆì‹œ:
# /var/lib/docker/containers/abc123.../abc123...-json.log

# ë¡œê·¸ íŒŒì¼ ì§ì ‘ ë³´ê¸° (Linux/Mac)
sudo tail -f /var/lib/docker/containers/abc123.../abc123...-json.log

# ë¡œê·¸ íŒŒì¼ ë‚´ìš© ì˜ˆì‹œ
{"log":"2025-09-30 10:15:32.123 INFO  [main] Application started\n","stream":"stdout","time":"2025-09-30T01:15:32.123456789Z"}
{"log":"2025-09-30 10:15:33.456 ERROR [http-nio-8080-exec-1] Connection refused\n","stream":"stderr","time":"2025-09-30T01:15:33.456789012Z"}
```

### 2. syslog ë“œë¼ì´ë²„

ê¸°ì¡´ syslog ì¸í”„ë¼ê°€ ìˆì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

```yaml
# docker-compose.yml
services:
  trade-service:
    image: lk-trade/trade-service:latest
    logging:
      driver: "syslog"
      options:
        syslog-address: "tcp://syslog-server:514"
        syslog-facility: "daemon"
        tag: "{{.Name}}/{{.ID}}"
```

### 3. fluentd ë“œë¼ì´ë²„ (ê¶Œì¥ - ëŒ€ê·œëª¨ í™˜ê²½)

FluentdëŠ” ê°•ë ¥í•œ ë¡œê·¸ ìˆ˜ì§‘ê¸°ì…ë‹ˆë‹¤.

```yaml
# docker-compose.yml
services:
  # Fluentd ì»¨í…Œì´ë„ˆ
  fluentd:
    image: fluent/fluentd:v1.16-1
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    volumes:
      - ./fluentd/conf:/fluentd/etc
      - ./fluentd/logs:/fluentd/log
    networks:
      - lk-trade-network

  # ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆ
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "localhost:24224"
        tag: "lk-trade.user-service"
        fluentd-async: "true"      # ë¹„ë™ê¸° ì „ì†¡
        fluentd-buffer-limit: "1m" # ë²„í¼ í¬ê¸°
    depends_on:
      - fluentd
    networks:
      - lk-trade-network
```

#### Fluentd ì„¤ì • íŒŒì¼

```ruby
# fluentd/conf/fluent.conf

# ì…ë ¥: Docker ì»¨í…Œì´ë„ˆë¡œë¶€í„° ë¡œê·¸ ìˆ˜ì‹ 
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# í•„í„°: JSON íŒŒì‹±
<filter lk-trade.**>
  @type parser
  key_name log
  <parse>
    @type json
  </parse>
</filter>

# í•„í„°: ë¡œê·¸ ë ˆë²¨ ì¶”ì¶œ
<filter lk-trade.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    level ${record["level"] || "INFO"}
  </record>
</filter>

# ì¶œë ¥ 1: Elasticsearchë¡œ ì „ì†¡
<match lk-trade.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix lk-trade
  <buffer>
    @type file
    path /fluentd/log/buffer
    flush_interval 10s
  </buffer>
</match>

# ì¶œë ¥ 2: íŒŒì¼ë¡œë„ ë°±ì—… ì €ì¥
<match lk-trade.**>
  @type copy
  <store>
    @type file
    path /fluentd/log/${tag}/%Y%m%d
    <buffer tag,time>
      timekey 1d
      timekey_wait 10m
    </buffer>
  </store>
</match>
```

---

## ELK Stackìœ¼ë¡œ ë¡œê·¸ ìˆ˜ì§‘í•˜ê¸°

ELK = **E**lasticsearch + **L**ogstash + **K**ibana

```
ì „ì²´ ì•„í‚¤í…ì²˜
=============

Docker Containers                     Filebeat                  Logstash                Elasticsearch         Kibana
=================                     ========                  ========                =============         ======

[user-service]
   stdout/stderr  â”€â”€â”€â”€â”
                      â”‚
[trade-service]       â”œâ”€â”€â”€> Filebeat â”€â”€â”€> Logstash â”€â”€â”€> Elasticsearch â”€â”€â”€> Kibana
   stdout/stderr  â”€â”€â”€â”€â”¤      (ìˆ˜ì§‘)        (ê°€ê³µ)         (ì €ì¥)           (ì‹œê°í™”)
                      â”‚
[account-service]     â”‚
   stdout/stderr  â”€â”€â”€â”€â”˜

ê° ì—­í• :
- Filebeat: ë¡œê·¸ íŒŒì¼ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì½ì–´ì„œ Logstashë¡œ ì „ì†¡
- Logstash: ë¡œê·¸ë¥¼ íŒŒì‹±í•˜ê³  í•„í„°ë§í•˜ì—¬ êµ¬ì¡°í™”
- Elasticsearch: ë¡œê·¸ë¥¼ ìƒ‰ì¸í•˜ê³  ì €ì¥
- Kibana: ë¡œê·¸ë¥¼ ê²€ìƒ‰í•˜ê³  ì‹œê°í™”
```

### 1. ELK Stack docker-compose êµ¬ì„±

```yaml
# docker-compose.elk.yml
version: '3.8'

services:
  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"  # JVM í™ í¬ê¸°
      - xpack.security.enabled=false   # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ë³´ì•ˆ ë¹„í™œì„±í™”
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - elk-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"  # Filebeat ì…ë ¥
      - "9600:9600"  # Logstash API
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
    networks:
      - elk-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  # Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - elk-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  # Filebeat
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: filebeat
    user: root  # Docker ì†Œì¼“ ì ‘ê·¼ ê¶Œí•œ í•„ìš”
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data:/usr/share/filebeat/data
    command: filebeat -e -strict.perms=false
    networks:
      - elk-network
    depends_on:
      - logstash

volumes:
  elasticsearch-data:
    driver: local
  filebeat-data:
    driver: local

networks:
  elk-network:
    driver: bridge
```

### 2. Filebeat ì„¤ì •

FilebeatëŠ” Docker ì»¨í…Œì´ë„ˆì˜ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

```yaml
# filebeat/filebeat.yml
filebeat.inputs:
  # Docker ì»¨í…Œì´ë„ˆ ë¡œê·¸ ìë™ ìˆ˜ì§‘
  - type: container
    enabled: true
    paths:
      - '/var/lib/docker/containers/*/*.log'

    # JSON ë¡œê·¸ íŒŒì‹±
    json.keys_under_root: true
    json.add_error_key: true
    json.message_key: log

    # Docker ë©”íƒ€ë°ì´í„° ì¶”ê°€
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"

      - decode_json_fields:
          fields: ["message"]
          target: ""
          overwrite_keys: true

      # ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°
      - drop_fields:
          fields: ["agent", "ecs", "host", "input"]

# Logstashë¡œ ì¶œë ¥
output.logstash:
  hosts: ["logstash:5044"]

# ë¡œê·¸ ë ˆë²¨ ì„¤ì •
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

### 3. Logstash íŒŒì´í”„ë¼ì¸ ì„¤ì •

LogstashëŠ” ë¡œê·¸ë¥¼ íŒŒì‹±í•˜ê³  ê°€ê³µí•©ë‹ˆë‹¤.

```ruby
# logstash/pipeline/logstash.conf

input {
  beats {
    port => 5044
  }
}

filter {
  # Docker ì»¨í…Œì´ë„ˆ ë¡œê·¸ í•„í„°
  if [container] {
    # ì»¨í…Œì´ë„ˆ ì´ë¦„ì—ì„œ ì„œë¹„ìŠ¤ ì´ë¦„ ì¶”ì¶œ
    grok {
      match => {
        "[container][name]" => "^/?(%{DATA:service_name})[-_]"
      }
    }

    # Spring Boot ë¡œê·¸ íŒŒì‹±
    if [service_name] =~ /user|trade|account|strategy/ {
      grok {
        match => {
          "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} +\[%{DATA:thread}\] %{DATA:logger} : %{GREEDYDATA:log_message}"
        }
      }

      # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹±
      date {
        match => ["timestamp", "ISO8601"]
        target => "@timestamp"
      }
    }

    # ì—ëŸ¬ ë¡œê·¸ íƒœê·¸ ì¶”ê°€
    if [log_level] == "ERROR" or [log_level] == "FATAL" {
      mutate {
        add_tag => ["error"]
      }
    }

    # ì„±ëŠ¥ ê´€ë ¨ ë¡œê·¸ íƒœê·¸
    if [message] =~ /took \d+ms/ or [message] =~ /response time/ {
      grok {
        match => {
          "message" => "took %{NUMBER:response_time_ms:int}ms"
        }
      }
      mutate {
        add_tag => ["performance"]
      }
    }
  }

  # ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°
  mutate {
    remove_field => ["agent", "ecs", "input", "host"]
  }
}

output {
  # Elasticsearchë¡œ ì¶œë ¥
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "lk-trade-%{+YYYY.MM.dd}"

    # í…œí”Œë¦¿ ì„¤ì •
    template_name => "lk-trade"
    template_pattern => "lk-trade-*"
  }

  # ë””ë²„ê¹…ìš© stdout (ê°œë°œ í™˜ê²½ì—ì„œë§Œ)
  stdout {
    codec => rubydebug
  }
}
```

### 4. ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ êµ¬ì¡°í™”ëœ ë¡œê·¸ ì¶œë ¥

Spring Boot ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ JSON í˜•ì‹ìœ¼ë¡œ ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ë©´ íŒŒì‹±ì´ ì‰¬ì›Œì§‘ë‹ˆë‹¤.

#### Logback ì„¤ì • (JSON ë¡œê·¸)

```xml
<!-- src/main/resources/logback-spring.xml -->
<configuration>
    <springProperty scope="context" name="serviceName" source="spring.application.name"/>

    <!-- JSON Encoder ì˜ì¡´ì„± í•„ìš”: net.logstash.logback:logstash-logback-encoder -->
    <appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>{"service":"${serviceName}"}</customFields>
            <fieldNames>
                <timestamp>timestamp</timestamp>
                <message>message</message>
                <logger>logger</logger>
                <thread>thread</thread>
                <level>level</level>
                <stackTrace>stack_trace</stackTrace>
            </fieldNames>
        </encoder>
    </appender>

    <root level="INFO">
        <appender-ref ref="JSON"/>
    </root>
</configuration>
```

#### Gradle ì˜ì¡´ì„± ì¶”ê°€

```kotlin
// build.gradle.kts
dependencies {
    // JSON ë¡œê·¸ ì¶œë ¥
    implementation("net.logstash.logback:logstash-logback-encoder:7.4")
}
```

#### ë¡œê·¸ ì¶œë ¥ ì˜ˆì‹œ

```kotlin
// UserService.kt
import org.slf4j.LoggerFactory
import org.slf4j.MDC

class UserService {
    private val logger = LoggerFactory.getLogger(UserService::class.java)

    fun createUser(request: CreateUserRequest): User {
        // MDCë¡œ ì¶”ì  ID ì¶”ê°€ (ì „ì²´ ìš”ì²­ì—ì„œ ì¶”ì  ê°€ëŠ¥)
        MDC.put("userId", request.email)
        MDC.put("requestId", UUID.randomUUID().toString())

        try {
            logger.info("Creating user: {}", request.email)

            val user = userRepository.save(User(email = request.email))

            logger.info("User created successfully: {}", user.id)
            return user

        } catch (e: Exception) {
            logger.error("Failed to create user: {}", request.email, e)
            throw e
        } finally {
            MDC.clear()
        }
    }
}
```

#### JSON ë¡œê·¸ ì¶œë ¥ ì˜ˆì‹œ

```json
{
  "timestamp": "2025-09-30T10:15:32.123+09:00",
  "level": "INFO",
  "thread": "http-nio-8080-exec-1",
  "logger": "com.lk.trade.user.service.UserService",
  "message": "Creating user: test@example.com",
  "service": "user-service",
  "userId": "test@example.com",
  "requestId": "abc-123-def-456"
}
```

---

## Kibanaì—ì„œ ë¡œê·¸ ê²€ìƒ‰ê³¼ ì‹œê°í™”

### 1. Kibana ì ‘ì† ë° Index Pattern ì„¤ì •

```bash
# Kibana ì ‘ì†
http://localhost:5601

# ìµœì´ˆ ì ‘ì† ì‹œ Index Pattern ìƒì„±
1. Management > Stack Management > Index Patterns
2. "Create index pattern" í´ë¦­
3. Index pattern name: lk-trade-*
4. Time field: @timestamp
5. "Create index pattern" í´ë¦­
```

### 2. ê¸°ë³¸ ë¡œê·¸ ê²€ìƒ‰

```
Kibana Discover í™”ë©´
====================

ê²€ìƒ‰ ì¿¼ë¦¬ ì˜ˆì‹œ:

1. íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸ ê²€ìƒ‰
   service_name: "user-service"

2. ì—ëŸ¬ ë¡œê·¸ë§Œ ê²€ìƒ‰
   log_level: "ERROR"

3. íŠ¹ì • ì‚¬ìš©ì ê´€ë ¨ ë¡œê·¸
   userId: "test@example.com"

4. íŠ¹ì • ì‹œê°„ëŒ€ ë¡œê·¸
   @timestamp: [2025-09-30T00:00:00 TO 2025-09-30T23:59:59]

5. ë³µí•© ì¡°ê±´ (AND, OR)
   service_name: "trade-service" AND log_level: "ERROR"

6. ì‘ë‹µ ì‹œê°„ì´ ëŠë¦° ìš”ì²­
   response_time_ms: >1000

7. íŠ¹ì • ë©”ì‹œì§€ í¬í•¨
   message: *"Connection refused"*
```

### 3. ì‹œê°í™” ëŒ€ì‹œë³´ë“œ êµ¬ì„±

Kibanaì—ì„œ ìœ ìš©í•œ ì‹œê°í™”:

#### ë¡œê·¸ ë ˆë²¨ë³„ ë¶„í¬ (Pie Chart)

```
Visualization Type: Pie Chart
Metrics: Count
Buckets:
  - Split slices
  - Aggregation: Terms
  - Field: log_level.keyword
  - Size: 10
```

#### ì‹œê°„ëŒ€ë³„ ì—ëŸ¬ ë°œìƒ ì¶”ì´ (Line Chart)

```
Visualization Type: Line Chart
Metrics: Count
Buckets:
  - X-Axis
  - Aggregation: Date Histogram
  - Field: @timestamp
  - Interval: Auto

Filters: log_level: "ERROR"
```

#### ì„œë¹„ìŠ¤ë³„ ë¡œê·¸ ì–‘ (Bar Chart)

```
Visualization Type: Bar Chart (Vertical)
Metrics: Count
Buckets:
  - X-Axis
  - Aggregation: Terms
  - Field: service_name.keyword
  - Order By: metric: Count
  - Order: Descending
  - Size: 10
```

#### ì‘ë‹µ ì‹œê°„ ë¶„í¬ (Histogram)

```
Visualization Type: Histogram
Metrics: Average response_time_ms
Buckets:
  - X-Axis
  - Aggregation: Histogram
  - Field: response_time_ms
  - Interval: 100
```

### 4. ëŒ€ì‹œë³´ë“œ êµ¬ì„± ì˜ˆì‹œ

```
LK-Trade ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
====================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì‹œê°„ ë²”ìœ„: Last 24 hours                  ğŸ”„ Auto-refresh  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì´ ë¡œê·¸ ìˆ˜      â”‚  ì—ëŸ¬ ìˆ˜         â”‚  í‰ê·  ì‘ë‹µ ì‹œê°„      â”‚
â”‚  1,234,567       â”‚  42 (0.003%)     â”‚  123ms               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì‹œê°„ëŒ€ë³„ ë¡œê·¸ ë°œìƒëŸ‰       â”‚  ì„œë¹„ìŠ¤ë³„ ë¡œê·¸ ë¶„í¬         â”‚
â”‚  [Line Chart]               â”‚  [Pie Chart]                â”‚
â”‚                             â”‚  - user-service: 35%        â”‚
â”‚     â•±â•²                      â”‚  - trade-service: 28%       â”‚
â”‚    â•±  â•²      â•±â•²            â”‚  - account-service: 20%     â”‚
â”‚   â•±    â•²    â•±  â•²           â”‚  - strategy-service: 17%    â”‚
â”‚  â•±      â•²  â•±    â•²          â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì—ëŸ¬ ë¡œê·¸ ì¶”ì´             â”‚  ì‘ë‹µ ì‹œê°„ ë¶„í¬             â”‚
â”‚  [Area Chart]               â”‚  [Histogram]                â”‚
â”‚                             â”‚                             â”‚
â”‚      â•±â•²                     â”‚      â”ƒ                      â”‚
â”‚     â•±  â•²â•±â•²                  â”‚      â”ƒ                      â”‚
â”‚    â•±       â•²â•±â•²              â”‚  â”ƒ   â”ƒ                      â”‚
â”‚   â•±            â•²            â”‚  â”ƒ   â”ƒ  â”ƒ                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ìµœê·¼ ì—ëŸ¬ ë¡œê·¸ (ì‹¤ì‹œê°„)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [10:15:32] user-service | ERROR | Connection refused     â”‚
â”‚  [10:14:28] trade-service | ERROR | Insufficient balance â”‚
â”‚  [10:13:45] account-service | ERROR | API rate limit     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ë¡œê·¸ ê´€ë¦¬ ëª¨ë²” ì‚¬ë¡€

### 1. ë¡œê·¸ ë ˆë²¨ ì „ëµ

```kotlin
// âŒ ë‚˜ìœ ì˜ˆ
logger.info("User: $user, Password: ${user.password}, Request: $request")
// ë¬¸ì œ: ë¯¼ê° ì •ë³´ ë…¸ì¶œ, ë„ˆë¬´ ìƒì„¸

logger.debug("Step 1")
logger.debug("Step 2")
logger.debug("Step 3")
// ë¬¸ì œ: ì˜ë¯¸ ì—†ëŠ” ë¡œê·¸

logger.error("Error occurred")
// ë¬¸ì œ: êµ¬ì²´ì ì¸ ì •ë³´ ì—†ìŒ


// âœ… ì¢‹ì€ ì˜ˆ
// INFO: ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ìš” ì´ë²¤íŠ¸
logger.info("User registered successfully",
    kv("userId", user.id),
    kv("email", user.email.maskEmail())  // ì´ë©”ì¼ ë§ˆìŠ¤í‚¹
)

// DEBUG: ë””ë²„ê¹…ì— í•„ìš”í•œ ìƒì„¸ ì •ë³´
logger.debug("Processing order",
    kv("orderId", order.id),
    kv("items", order.items.size),
    kv("totalAmount", order.totalAmount)
)

// ERROR: ì˜ˆì™¸ ìƒí™©, ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ í¬í•¨
logger.error("Failed to process payment",
    kv("orderId", order.id),
    kv("errorCode", errorCode),
    e  // Exception ê°ì²´
)
```

### 2. ë¡œê·¸ ë ˆë²¨ ê°€ì´ë“œë¼ì¸

| ë ˆë²¨ | ìš©ë„ | ì˜ˆì‹œ |
|-----|------|-----|
| **TRACE** | ë§¤ìš° ìƒì„¸í•œ ë””ë²„ê·¸ ì •ë³´ | "Entering method", "Loop iteration 5" |
| **DEBUG** | ë””ë²„ê¹…ì— í•„ìš”í•œ ì •ë³´ | "Query: SELECT * FROM users WHERE...", "Cache hit" |
| **INFO** | ì¤‘ìš” ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë²¤íŠ¸ | "User login successful", "Order created" |
| **WARN** | ì ì¬ì  ë¬¸ì œ ìƒí™© | "API rate limit 80% reached", "Retrying connection" |
| **ERROR** | ì—ëŸ¬ ë°œìƒ, ë³µêµ¬ ê°€ëŠ¥ | "Payment failed", "External API timeout" |
| **FATAL** | ì¹˜ëª…ì  ì˜¤ë¥˜, ë³µêµ¬ ë¶ˆê°€ | "Database connection lost", "Out of memory" |

### 3. êµ¬ì¡°í™”ëœ ë¡œê¹… (Structured Logging)

```kotlin
// âŒ ë¹„êµ¬ì¡°í™”ëœ ë¡œê·¸ (íŒŒì‹± ì–´ë ¤ì›€)
logger.info("User test@example.com created order #12345 with amount $99.99")

// âœ… êµ¬ì¡°í™”ëœ ë¡œê·¸ (ê²€ìƒ‰ ì‰¬ì›€)
logger.info("Order created",
    kv("userId", user.id),
    kv("userEmail", user.email),
    kv("orderId", order.id),
    kv("amount", order.amount),
    kv("currency", "USD")
)

// JSON ì¶œë ¥ ì˜ˆì‹œ:
// {
//   "message": "Order created",
//   "userId": 123,
//   "userEmail": "test@example.com",
//   "orderId": 12345,
//   "amount": 99.99,
//   "currency": "USD"
// }
```

### 4. ìƒê´€ ê´€ê³„ ì¶”ì  (Correlation ID)

ìš”ì²­ ì „ì²´ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•œ ìƒê´€ ID ì‚¬ìš©:

```kotlin
// Spring Boot Interceptor
@Component
class CorrelationIdInterceptor : HandlerInterceptor {
    companion object {
        const val CORRELATION_ID_HEADER = "X-Correlation-ID"
        const val CORRELATION_ID_MDC_KEY = "correlationId"
    }

    override fun preHandle(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any
    ): Boolean {
        // í—¤ë”ì—ì„œ Correlation ID ê°€ì ¸ì˜¤ê¸° or ìƒˆë¡œ ìƒì„±
        val correlationId = request.getHeader(CORRELATION_ID_HEADER)
            ?: UUID.randomUUID().toString()

        // MDCì— ì €ì¥ (ëª¨ë“  ë¡œê·¸ì— ìë™ í¬í•¨ë¨)
        MDC.put(CORRELATION_ID_MDC_KEY, correlationId)

        // ì‘ë‹µ í—¤ë”ì—ë„ ì¶”ê°€
        response.setHeader(CORRELATION_ID_HEADER, correlationId)

        return true
    }

    override fun afterCompletion(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any,
        ex: Exception?
    ) {
        // ìš”ì²­ ì™„ë£Œ í›„ MDC ì •ë¦¬
        MDC.clear()
    }
}

// ì‚¬ìš© ì˜ˆì‹œ
class OrderService {
    private val logger = LoggerFactory.getLogger(OrderService::class.java)

    fun createOrder(request: CreateOrderRequest): Order {
        // correlationIdëŠ” ìë™ìœ¼ë¡œ ëª¨ë“  ë¡œê·¸ì— í¬í•¨ë¨
        logger.info("Creating order for user {}", request.userId)

        // ë‹¤ë¥¸ ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹œì—ë„ Correlation ID ì „ë‹¬
        val user = userClient.getUser(request.userId)

        logger.info("Order created successfully")
        return order
    }
}

// Feign Clientì—ì„œ Correlation ID ì „ë‹¬
@Component
class CorrelationIdFeignInterceptor : RequestInterceptor {
    override fun apply(template: RequestTemplate) {
        val correlationId = MDC.get(CorrelationIdInterceptor.CORRELATION_ID_MDC_KEY)
        if (correlationId != null) {
            template.header(
                CorrelationIdInterceptor.CORRELATION_ID_HEADER,
                correlationId
            )
        }
    }
}
```

ì´ë ‡ê²Œ í•˜ë©´ Kibanaì—ì„œ `correlationId`ë¡œ ê²€ìƒ‰í•˜ì—¬ ì „ì²´ ìš”ì²­ íë¦„ì„ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```
Kibana ê²€ìƒ‰:
correlationId: "abc-123-def-456"

ê²°ê³¼:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10:15:32.123 | user-service     | Authenticating user       â”‚
â”‚ 10:15:32.234 | user-service     | User authenticated        â”‚
â”‚ 10:15:32.345 | account-service  | Fetching account balance  â”‚
â”‚ 10:15:32.456 | account-service  | Balance: $1,000           â”‚
â”‚ 10:15:32.567 | trade-service    | Creating order            â”‚
â”‚ 10:15:32.678 | trade-service    | Order created: #12345     â”‚
â”‚ 10:15:32.789 | notification     | Sending email             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. ë¯¼ê° ì •ë³´ ë³´í˜¸

```kotlin
// ì´ë©”ì¼ ë§ˆìŠ¤í‚¹
fun String.maskEmail(): String {
    val parts = this.split("@")
    if (parts.size != 2) return "***"
    val local = parts[0]
    val domain = parts[1]
    val masked = local.take(2) + "*".repeat(local.length - 2)
    return "$masked@$domain"
}

// ì „í™”ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
fun String.maskPhone(): String {
    return this.replaceRange(4, this.length - 4, "*".repeat(this.length - 8))
}

// ì¹´ë“œ ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
fun String.maskCardNumber(): String {
    return this.replaceRange(4, 12, "****-****")
}

// ì‚¬ìš© ì˜ˆì‹œ
logger.info("User registered",
    kv("email", user.email.maskEmail()),  // te**@example.com
    kv("phone", user.phone.maskPhone())   // 010-****-5678
)
```

---

## LK-Trade í”„ë¡œì íŠ¸ì— ì ìš©í•˜ê¸°

### 1. ì „ì²´ docker-compose í†µí•©

```yaml
# docker-compose.yml (ì „ì²´ í†µí•© ë²„ì „)
version: '3.8'

services:
  # ========================================
  # ELK Stack
  # ========================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: lk-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - lk-trade-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: lk-logstash
    volumes:
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5044:5044"
      - "9600:9600"
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
    networks:
      - lk-trade-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: lk-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - lk-trade-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: lk-filebeat
    user: root
    volumes:
      - ./elk/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data:/usr/share/filebeat/data
    command: filebeat -e -strict.perms=false
    networks:
      - lk-trade-network
    depends_on:
      - logstash

  # ========================================
  # Application Services (ë¡œê·¸ ì„¤ì • í¬í•¨)
  # ========================================
  user-service:
    build:
      context: ./modules/user/api
      dockerfile: Dockerfile
    container_name: lk-user-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=user"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/lk_trade
    ports:
      - "8081:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres
      - redis

  trade-service:
    build:
      context: ./modules/trade/api
      dockerfile: Dockerfile
    container_name: lk-trade-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=trade"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8082:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres
      - redis

  account-service:
    build:
      context: ./modules/account/api
      dockerfile: Dockerfile
    container_name: lk-account-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=account"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8083:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres

  strategy-service:
    build:
      context: ./modules/strategy/api
      dockerfile: Dockerfile
    container_name: lk-strategy-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=strategy"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8084:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres

  # ========================================
  # Infrastructure
  # ========================================
  postgres:
    image: postgres:16-alpine
    container_name: lk-postgres
    environment:
      - POSTGRES_DB=lk_trade
      - POSTGRES_USER=lk_admin
      - POSTGRES_PASSWORD=secure_password
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - lk-trade-network

  redis:
    image: redis:7-alpine
    container_name: lk-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - lk-trade-network

volumes:
  elasticsearch-data:
  filebeat-data:
  postgres-data:
  redis-data:

networks:
  lk-trade-network:
    driver: bridge
```

### 2. ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
C:\trade\backend1\
â”œâ”€â”€ elk/
â”‚   â”œâ”€â”€ filebeat/
â”‚   â”‚   â””â”€â”€ filebeat.yml
â”‚   â””â”€â”€ logstash/
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â””â”€â”€ logstash.yml
â”‚       â””â”€â”€ pipeline/
â”‚           â””â”€â”€ logstash.conf
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ user/api/
â”‚   â”‚   â””â”€â”€ src/main/resources/
â”‚   â”‚       â””â”€â”€ logback-spring.xml
â”‚   â”œâ”€â”€ trade/api/
â”‚   â”‚   â””â”€â”€ src/main/resources/
â”‚   â”‚       â””â”€â”€ logback-spring.xml
â”‚   â””â”€â”€ ...
â””â”€â”€ scripts/
    â”œâ”€â”€ start-elk.sh
    â””â”€â”€ stop-elk.sh
```

### 3. ì‹œì‘/ì¤‘ì§€ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/start-elk.sh

echo "ğŸš€ Starting ELK Stack..."

# Elasticsearch ì‹œì‘
docker-compose up -d elasticsearch
echo "â³ Waiting for Elasticsearch to be healthy..."
until docker exec lk-elasticsearch curl -s http://localhost:9200 > /dev/null; do
    sleep 5
done
echo "âœ… Elasticsearch is ready"

# Logstash ì‹œì‘
docker-compose up -d logstash
echo "â³ Waiting for Logstash..."
sleep 30
echo "âœ… Logstash is ready"

# Kibana ì‹œì‘
docker-compose up -d kibana
echo "â³ Waiting for Kibana..."
sleep 30
echo "âœ… Kibana is ready"

# Filebeat ì‹œì‘
docker-compose up -d filebeat
echo "âœ… Filebeat is ready"

echo "
========================================
ELK Stack started successfully! ğŸ‰
========================================

ğŸ“Š Kibana: http://localhost:5601
ğŸ” Elasticsearch: http://localhost:9200
ğŸ“ Logstash: http://localhost:9600

Next steps:
1. Open Kibana: http://localhost:5601
2. Create index pattern: lk-trade-*
3. Start exploring logs in Discover
========================================
"
```

```bash
#!/bin/bash
# scripts/stop-elk.sh

echo "ğŸ›‘ Stopping ELK Stack..."

docker-compose stop filebeat
docker-compose stop kibana
docker-compose stop logstash
docker-compose stop elasticsearch

echo "âœ… ELK Stack stopped"
```

### 4. Makefile í†µí•©

```makefile
# Makefile
.PHONY: elk-start elk-stop elk-logs elk-status logs-view logs-search

# ELK Stack ê´€ë¦¬
elk-start:
	@echo "ğŸš€ Starting ELK Stack..."
	@bash scripts/start-elk.sh

elk-stop:
	@echo "ğŸ›‘ Stopping ELK Stack..."
	@bash scripts/stop-elk.sh

elk-logs:
	@docker-compose logs -f elasticsearch logstash kibana filebeat

elk-status:
	@echo "ğŸ“Š Elasticsearch:"
	@curl -s http://localhost:9200 | jq
	@echo "\nğŸ“ Logstash:"
	@curl -s http://localhost:9600 | jq
	@echo "\nğŸ” Kibana:"
	@curl -s http://localhost:5601/api/status | jq

# ë¡œê·¸ ì¡°íšŒ
logs-view:
	@echo "Select service:"
	@echo "1) user-service"
	@echo "2) trade-service"
	@echo "3) account-service"
	@echo "4) strategy-service"
	@echo "5) all services"
	@read -p "Enter number: " choice; \
	case $$choice in \
		1) docker-compose logs -f user-service ;; \
		2) docker-compose logs -f trade-service ;; \
		3) docker-compose logs -f account-service ;; \
		4) docker-compose logs -f strategy-service ;; \
		5) docker-compose logs -f ;; \
		*) echo "Invalid choice" ;; \
	esac

# Kibanaì—ì„œ ìµœê·¼ ì—ëŸ¬ ê²€ìƒ‰
logs-search-errors:
	@echo "ğŸ” Searching for recent errors in Kibana..."
	@curl -s -X GET "http://localhost:9200/lk-trade-*/_search" \
		-H 'Content-Type: application/json' \
		-d '{"query":{"match":{"log_level":"ERROR"}},"size":10,"sort":[{"@timestamp":{"order":"desc"}}]}' \
		| jq '.hits.hits[]._source | {time: .timestamp, service: .service_name, message: .message}'
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: Filebeatê°€ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í•¨

```bash
# ì¦ìƒ
Kibanaì— ë¡œê·¸ê°€ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŒ

# ì›ì¸ í™•ì¸
docker logs lk-filebeat

# ì¼ë°˜ì ì¸ ì›ì¸:
# 1. Docker ì†Œì¼“ ê¶Œí•œ ë¬¸ì œ
# 2. ë¡œê·¸ ê²½ë¡œ ë§ˆìš´íŠ¸ ì˜¤ë¥˜
# 3. Logstash ì—°ê²° ì‹¤íŒ¨

# í•´ê²°ì±… 1: ê¶Œí•œ í™•ì¸
docker exec lk-filebeat ls -la /var/run/docker.sock
# ì¶œë ¥: srw-rw---- 1 root docker 0 Sep 30 10:00 /var/run/docker.sock

# í•´ê²°ì±… 2: Logstash ì—°ê²° í™•ì¸
docker exec lk-filebeat cat /usr/share/filebeat/filebeat.yml | grep logstash
# output.logstash.hostsê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸

# í•´ê²°ì±… 3: Filebeat ì¬ì‹œì‘
docker-compose restart filebeat
```

### ë¬¸ì œ 2: Logstashê°€ ë¡œê·¸ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í•¨

```bash
# ì¦ìƒ
Elasticsearchì— ë¡œê·¸ê°€ ì €ì¥ë˜ì§€ë§Œ í•„ë“œê°€ íŒŒì‹±ë˜ì§€ ì•ŠìŒ

# ì›ì¸ í™•ì¸
docker logs lk-logstash

# ì¼ë°˜ì ì¸ ì›ì¸:
# - grok íŒ¨í„´ ì˜¤ë¥˜
# - JSON íŒŒì‹± ì‹¤íŒ¨

# í•´ê²°ì±…: Logstash íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
docker exec -it lk-logstash bash

# ìƒ˜í”Œ ë¡œê·¸ë¡œ í…ŒìŠ¤íŠ¸
echo '{"log":"2025-09-30 10:15:32.123 INFO [main] Application started\n","stream":"stdout"}' \
  | /usr/share/logstash/bin/logstash -f /usr/share/logstash/pipeline/logstash.conf --config.test_and_exit

# ì¶œë ¥ì—ì„œ íŒŒì‹± ê²°ê³¼ í™•ì¸
```

### ë¬¸ì œ 3: Elasticsearch ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

```bash
# ì¦ìƒ
Elasticsearchê°€ read-only ëª¨ë“œë¡œ ì „í™˜

# í™•ì¸
curl -X GET "http://localhost:9200/_cluster/health?pretty"

# í•´ê²°ì±… 1: ì˜¤ë˜ëœ ì¸ë±ìŠ¤ ì‚­ì œ
# 30ì¼ ì´ì „ ì¸ë±ìŠ¤ ì‚­ì œ
curl -X DELETE "http://localhost:9200/lk-trade-2025.08.*"

# í•´ê²°ì±… 2: Index Lifecycle Management (ILM) ì„¤ì •
curl -X PUT "http://localhost:9200/_ilm/policy/lk-trade-policy" -H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_size": "50gb",
            "max_age": "7d"
          }
        }
      },
      "delete": {
        "min_age": "30d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
'

# í•´ê²°ì±… 3: read-only ëª¨ë“œ í•´ì œ
curl -X PUT "http://localhost:9200/_cluster/settings" -H 'Content-Type: application/json' -d'
{
  "persistent": {
    "cluster.routing.allocation.disk.threshold_enabled": false
  }
}
'
curl -X PUT "http://localhost:9200/*/_settings" -H 'Content-Type: application/json' -d'
{
  "index.blocks.read_only_allow_delete": null
}
'
```

### ë¬¸ì œ 4: Kibanaê°€ ëŠë¦¼

```bash
# ì¦ìƒ
Kibana ëŒ€ì‹œë³´ë“œ ë¡œë”©ì´ ë§¤ìš° ëŠë¦¼

# ì›ì¸:
# - ë„ˆë¬´ ë§ì€ ë°ì´í„° ì¡°íšŒ
# - ì¸ë±ìŠ¤ê°€ ìµœì í™”ë˜ì§€ ì•ŠìŒ

# í•´ê²°ì±… 1: ì‹œê°„ ë²”ìœ„ ì¤„ì´ê¸°
# Kibanaì—ì„œ "Last 15 minutes" ë“±ìœ¼ë¡œ ë²”ìœ„ ì¶•ì†Œ

# í•´ê²°ì±… 2: ì¸ë±ìŠ¤ ìµœì í™”
curl -X POST "http://localhost:9200/lk-trade-*/_forcemerge?max_num_segments=1"

# í•´ê²°ì±… 3: Kibana ë©”ëª¨ë¦¬ ì¦ê°€
# docker-compose.ymlì—ì„œ:
kibana:
  environment:
    - NODE_OPTIONS="--max-old-space-size=4096"
```

---

## ğŸ‘¨â€ğŸ’» ì£¼ë‹ˆì–´ ê°œë°œì ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì²« ë¡œê·¸ ë””ë²„ê¹… - ì—ëŸ¬ ë¡œê·¸ë¥¼ ëª» ì°¾ê² ì–´ìš”

**ìƒí™©**:
```
íŒ€ì¥: "user-serviceì—ì„œ ì˜¤ë¥˜ ë‚¬ëŠ”ë° í™•ì¸ ì¢€ í•´ë´ìš”."
ì£¼ë‹ˆì–´ A (ë‹¹í™©): "ì–´... ë¡œê·¸ë¥¼ ì–´ë””ì„œ ë´ì•¼ í•˜ë‚˜ìš”?"
íŒ€ì¥: "docker logs ëª…ë ¹ì–´ ì¨ë³´ì„¸ìš”."
ì£¼ë‹ˆì–´ A: "ë„¤! (ê·¸ëŸ°ë° docker logsê°€ ë­ì§€...?)"
```

**ë‹¨ê³„ë³„ í•´ê²°**:
```bash
# Step 1: ì‹¤í–‰ ì¤‘ì¸ ì»¨í…Œì´ë„ˆ í™•ì¸
$ docker ps
CONTAINER ID   NAME           STATUS
abc123def456   user-service   Up 10 minutes

# Step 2: ë¡œê·¸ í™•ì¸ (ê°€ì¥ ê¸°ë³¸!)
$ docker logs user-service

# ì¶œë ¥:
2025-09-30 10:15:32.123 INFO  [main] Application started
2025-09-30 10:16:45.456 ERROR [http-thread-1] NullPointerException at UserService.java:123
...
(ë„ˆë¬´ ë§ì•„ì„œ ìŠ¤í¬ë¡¤ì´ ê³„ì† ì˜¬ë¼ê°... ğŸ˜µ)

# Step 3: ìµœê·¼ ë¡œê·¸ë§Œ ë³´ê¸° (tail ì˜µì…˜)
$ docker logs --tail 50 user-service
# ìµœê·¼ 50ì¤„ë§Œ ì¶œë ¥ â†’ í›¨ì”¬ ë³´ê¸° ì‰¬ì›€!

# Step 4: ì‹¤ì‹œê°„ ë¡œê·¸ ë³´ê¸° (follow ì˜µì…˜)
$ docker logs -f user-service
# tail -fì²˜ëŸ¼ ìƒˆ ë¡œê·¸ê°€ ê³„ì† ì¶œë ¥ë¨

# Step 5: ì—ëŸ¬ë§Œ í•„í„°ë§
$ docker logs user-service 2>&1 | grep ERROR
2025-09-30 10:16:45.456 ERROR [http-thread-1] NullPointerException
2025-09-30 10:17:12.789 ERROR [http-thread-2] Database connection failed
# ì•„í•˜! ì—ëŸ¬ë§Œ ê³¨ë¼ì„œ ë³¼ ìˆ˜ ìˆêµ¬ë‚˜!

# Step 6: íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨í•´ì„œ ë³´ê¸°
$ docker logs -t --tail 100 user-service | grep ERROR
2025-09-30T10:16:45.456789Z 2025-09-30 10:16:45.456 ERROR ...
# ì •í™•í•œ ì‹œê°„ í™•ì¸ ê°€ëŠ¥!

âœ… í•´ê²°!
```

**ë°°ìš´ ì **:
- `docker logs <container>`: ê¸°ë³¸ ë¡œê·¸ í™•ì¸
- `--tail N`: ìµœê·¼ Nì¤„ë§Œ ë³´ê¸°
- `-f`: ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°
- `-t`: íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
- `grep`ìœ¼ë¡œ í•„í„°ë§ ê°€ëŠ¥

---

### ì‹œë‚˜ë¦¬ì˜¤ 2: ë¡œê·¸ê°€ ë„ˆë¬´ ë§ì•„ì„œ ë””ìŠ¤í¬ê°€ ê½‰ ì°¸

**ìƒí™©**:
```
ì‹œë‹ˆì–´: "ì„œë²„ ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ì´ 95%ì¸ë°, ë­ê°€ ë¬¸ì œì£ ?"
ì£¼ë‹ˆì–´ B: "í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤!"

$ df -h
/dev/sda1  100G   95G   5G  95% /

$ du -sh /var/lib/docker/containers/*
15G  /var/lib/docker/containers/abc123...  # user-service
8G   /var/lib/docker/containers/def456...  # trade-service
...

ì£¼ë‹ˆì–´ B (ë†€ëŒ): "ë¡œê·¸ íŒŒì¼ì´ 15GBë‚˜ ë¼ìš”!!"
ì‹œë‹ˆì–´: "ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì • ì•ˆ í–ˆë‚˜ë´ìš”. ê³ ì³ë³¼ê¹Œìš”?"
```

**ë‹¨ê³„ë³„ í•´ê²°**:
```bash
# Step 1: ë¡œê·¸ í¬ê¸° í™•ì¸
$ docker inspect user-service | grep LogPath
"LogPath": "/var/lib/docker/containers/abc123.../abc123...-json.log"

$ sudo ls -lh /var/lib/docker/containers/abc123.../*-json.log
-rw-r----- 1 root root 15G Sep 30 10:00 abc123...-json.log
# 15GB!! ğŸ˜±

# Step 2: docker-compose.ymlì— ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì •
# docker-compose.yml ìˆ˜ì •:
services:
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # ìµœëŒ€ 10MB
        max-file: "3"     # ìµœëŒ€ 3ê°œ íŒŒì¼
        # â†’ ì´ ìµœëŒ€ 30MBë¡œ ì œí•œ!

# Step 3: ì„œë¹„ìŠ¤ ì¬ì‹œì‘
$ docker-compose down
$ docker-compose up -d

# Step 4: ê¸°ì¡´ ë¡œê·¸ íŒŒì¼ ì •ë¦¬ (ì£¼ì˜!)
$ docker system prune -a --volumes
# ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ:
$ sudo rm /var/lib/docker/containers/abc123.../*-json.log.1
$ sudo rm /var/lib/docker/containers/abc123.../*-json.log.2

# Step 5: í™•ì¸
$ docker logs user-service
# ë¡œê·¸ê°€ ì´ˆê¸°í™”ë¨ (ì´ì „ ë¡œê·¸ëŠ” ì‚¬ë¼ì§)

# ë©°ì¹  í›„ ë‹¤ì‹œ í™•ì¸:
$ sudo ls -lh /var/lib/docker/containers/abc123.../*
-rw-r----- 1 root root 10M Oct 3 15:00 abc123...-json.log
-rw-r----- 1 root root 10M Oct 3 14:00 abc123...-json.log.1
-rw-r----- 1 root root 10M Oct 3 13:00 abc123...-json.log.2
# ì´ 30MBë¡œ ìœ ì§€ë¨! âœ…
```

**ë°°ìš´ ì **:
- ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì • í•„ìˆ˜ (max-size, max-file)
- ì„¤ì • ì•ˆ í•˜ë©´ ë””ìŠ¤í¬ ê½‰ ì°¸
- ê°œë°œ í™˜ê²½: 10MB x 3ê°œ = 30MB
- í”„ë¡œë•ì…˜: 100MB x 5ê°œ = 500MB ê¶Œì¥

---

### ì‹œë‚˜ë¦¬ì˜¤ 3: ELK Stack ì„¤ì¹˜í–ˆëŠ”ë° ë¡œê·¸ê°€ ì•ˆ ë³´ì„

**ìƒí™©**:
```
ì£¼ë‹ˆì–´ C: "ELK Stack ì„¤ì¹˜ ì™„ë£Œí–ˆì–´ìš”!"
íŒ€ì¥: "Kibanaì—ì„œ ë¡œê·¸ ë³´ì´ë‚˜ìš”?"
ì£¼ë‹ˆì–´ C: (Kibana ì ‘ì†) "ì•„ë¬´ê²ƒë„ ì•ˆ ë³´ì—¬ìš”... ğŸ˜¢"
íŒ€ì¥: "Filebeat ì„¤ì • í™•ì¸í•´ë´¤ì–´ìš”?"
ì£¼ë‹ˆì–´ C: "???"
```

**ë‹¨ê³„ë³„ í•´ê²°**:
```bash
# Step 1: Elasticsearch ì •ìƒ ì‘ë™ í™•ì¸
$ curl http://localhost:9200
{
  "name" : "elasticsearch",
  "cluster_name" : "docker-cluster",
  "version" : { ... }
}
# âœ… Elasticsearch ì •ìƒ

# Step 2: Filebeat ë¡œê·¸ í™•ì¸
$ docker logs lk-filebeat
ERROR: Failed to connect to Logstash at localhost:5044
# ì•„í•˜! Logstash ì—°ê²° ì‹¤íŒ¨!

# Step 3: Logstash ìƒíƒœ í™•ì¸
$ docker ps | grep logstash
(ì•„ë¬´ê²ƒë„ ì—†ìŒ)
# Logstashê°€ ì•ˆ ë– ìˆìŒ!

# Step 4: Logstash ì‹œì‘
$ docker-compose up -d logstash

# Step 5: Logstash ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸° (30ì´ˆ ì •ë„)
$ docker logs -f lk-logstash
[INFO] Successfully started Logstash API endpoint

# Step 6: Filebeat ì¬ì‹œì‘
$ docker-compose restart filebeat

# Step 7: Filebeat ë¡œê·¸ ë‹¤ì‹œ í™•ì¸
$ docker logs lk-filebeat
[INFO] Connection to Logstash established
# âœ… ì—°ê²° ì„±ê³µ!

# Step 8: Kibanaì—ì„œ í™•ì¸
# http://localhost:5601
# Management > Index Patterns > Create index pattern
# lk-trade-* ì…ë ¥ â†’ Create
# Discover íƒ­ìœ¼ë¡œ ì´ë™
# ë¡œê·¸ê°€ ë³´ì„! ğŸ‰
```

**ë°°ìš´ ì **:
- ELK Stack ì‹œì‘ ìˆœì„œ ì¤‘ìš”:
  1. Elasticsearch ë¨¼ì €
  2. Logstash (Elasticsearch ì¤€ë¹„ í›„)
  3. Kibana
  4. Filebeat (Logstash ì¤€ë¹„ í›„)
- `docker logs`ë¡œ ê° ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
- ì—°ê²° ì‹¤íŒ¨ ì‹œ ìˆœì„œëŒ€ë¡œ í•˜ë‚˜ì”© í™•ì¸

---

### ì‹œë‚˜ë¦¬ì˜¤ 4: Correlation IDë¡œ ë¶„ì‚° ì¶”ì í•˜ê¸°

**ìƒí™©**:
```
ì£¼ë‹ˆì–´ D: "user-serviceì—ì„œ trade-service í˜¸ì¶œí–ˆëŠ”ë°, trade-service ë¡œê·¸ë¥¼ ì–´ë–»ê²Œ ì°¾ì£ ?"
ì‹œë‹ˆì–´: "Correlation ID êµ¬í˜„í–ˆì–´ìš”?"
ì£¼ë‹ˆì–´ D: "ê·¸ê²Œ ë­”ê°€ìš”?"
ì‹œë‹ˆì–´: "ìš”ì²­ë§ˆë‹¤ ê³ ìœ  IDë¥¼ ë¶€ì—¬í•´ì„œ ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ë¡œê·¸ë¥¼ ì¶”ì í•˜ëŠ” ê±°ì˜ˆìš”."
```

**êµ¬í˜„ ê³¼ì •**:
```kotlin
// Step 1: Interceptor ìƒì„±
@Component
class CorrelationIdInterceptor : HandlerInterceptor {
    companion object {
        const val CORRELATION_ID_HEADER = "X-Correlation-ID"
        const val CORRELATION_ID_MDC_KEY = "correlationId"
    }

    override fun preHandle(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any
    ): Boolean {
        // í—¤ë”ì—ì„œ Correlation ID ê°€ì ¸ì˜¤ê¸° or ìƒì„±
        val correlationId = request.getHeader(CORRELATION_ID_HEADER)
            ?: UUID.randomUUID().toString()

        // MDCì— ì €ì¥ (ëª¨ë“  ë¡œê·¸ì— ìë™ í¬í•¨)
        MDC.put(CORRELATION_ID_MDC_KEY, correlationId)

        // ì‘ë‹µ í—¤ë”ì—ë„ ì¶”ê°€
        response.setHeader(CORRELATION_ID_HEADER, correlationId)

        return true
    }

    override fun afterCompletion(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any,
        ex: Exception?
    ) {
        MDC.clear()
    }
}

// Step 2: Feign Clientì—ì„œ Correlation ID ì „ë‹¬
@Component
class CorrelationIdFeignInterceptor : RequestInterceptor {
    override fun apply(template: RequestTemplate) {
        val correlationId = MDC.get("correlationId")
        if (correlationId != null) {
            template.header("X-Correlation-ID", correlationId)
        }
    }
}

// Step 3: Logback ì„¤ì • (correlationId í¬í•¨)
<!-- logback-spring.xml -->
<appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
    <encoder class="net.logstash.logback.encoder.LogstashEncoder">
        <includeMdcKeyName>correlationId</includeMdcKeyName>
    </encoder>
</appender>
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# Kibanaì—ì„œ ê²€ìƒ‰:
correlationId: "abc-123-def-456"

# ê²°ê³¼ (ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ë¡œê·¸ê°€ í•œ ë²ˆì— ì¡°íšŒë¨):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10:15:32.123 | user-service     | Authenticating user       â”‚
â”‚ 10:15:32.234 | user-service     | User authenticated        â”‚
â”‚ 10:15:32.345 | trade-service    | Creating order            â”‚
â”‚ 10:15:32.456 | trade-service    | Order created: #12345     â”‚
â”‚ 10:15:32.567 | account-service  | Deducting balance         â”‚
â”‚ 10:15:32.678 | account-service  | Balance updated           â”‚
â”‚ 10:15:32.789 | notification     | Sending email             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# ì „ì²´ ìš”ì²­ íë¦„ì´ í•œëˆˆì—! ğŸ‰
```

**ë°°ìš´ ì **:
- Correlation ID = ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œ í•„ìˆ˜
- MDC (Mapped Diagnostic Context) í™œìš©
- ëª¨ë“  ì„œë¹„ìŠ¤ ê°„ í˜¸ì¶œì— ì „ë‹¬
- Kibanaì—ì„œ ì†ì‰¬ìš´ ì¶”ì  ê°€ëŠ¥

---

## â“ FAQ

<details>
<summary><strong>Q1: docker logs ëª…ë ¹ì–´ë¡œ ë¡œê·¸ë¥¼ ë³¼ ìˆ˜ ì—†ëŠ”ë° ì–´ë–»ê²Œ í•˜ë‚˜ìš”?</strong></summary>

**A**: ì• í”Œë¦¬ì¼€ì´ì…˜ì´ stdout/stderrë¡œ ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

**ìƒì„¸ ì„¤ëª…**:

**ë¬¸ì œ**:
```bash
$ docker logs myapp
(ì•„ë¬´ê²ƒë„ ì¶œë ¥ ì•ˆ ë¨)

# í•˜ì§€ë§Œ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ëŠ” ë¡œê·¸ íŒŒì¼ì´ ìˆìŒ:
$ docker exec myapp ls /var/log/app
app.log  # íŒŒì¼ë¡œë§Œ ë¡œê·¸ ì €ì¥ë¨
```

**ì›ì¸**:
ì• í”Œë¦¬ì¼€ì´ì…˜ì´ íŒŒì¼ì—ë§Œ ë¡œê·¸ë¥¼ ì“°ê³ , stdout/stderrë¡œëŠ” ì¶œë ¥í•˜ì§€ ì•ŠìŒ.

**í•´ê²° ë°©ë²•**:

**ë°©ë²• 1: ì‹¬ë³¼ë¦­ ë§í¬ë¡œ stdout ì—°ê²° (ê¶Œì¥)**
```dockerfile
# Dockerfile
FROM openjdk:17-jre-alpine

# ë¡œê·¸ë¥¼ stdoutìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
RUN ln -sf /dev/stdout /var/log/app.log

CMD ["java", "-jar", "app.jar"]
```

**ë°©ë²• 2: ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ë³€ê²½ (Logback ì˜ˆì‹œ)**
```xml
<!-- logback-spring.xml -->
<configuration>
    <!-- íŒŒì¼ ëŒ€ì‹  ì½˜ì†”ë¡œ ì¶œë ¥ -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level [%thread] %logger : %msg%n</pattern>
        </encoder>
    </appender>

    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
    </root>
</configuration>
```

**ë°©ë²• 3: íŒŒì¼ ë¡œê·¸ë¥¼ ì§ì ‘ í™•ì¸**
```bash
# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ tail
$ docker exec myapp tail -f /var/log/app.log

# ë˜ëŠ” í˜¸ìŠ¤íŠ¸ë¡œ ë³µì‚¬
$ docker cp myapp:/var/log/app.log ./app.log
$ tail -f ./app.log
```

**Best Practice**:
> **"ì»¨í…Œì´ë„ˆ ë¡œê·¸ëŠ” í•­ìƒ stdout/stderrë¡œ ì¶œë ¥í•˜ì„¸ìš”!"**
>
> ì´ìœ :
> - Docker ë¡œê¹… ë“œë¼ì´ë²„ í™œìš© ê°€ëŠ¥
> - Kubernetes ë“± ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íˆ´ê³¼ í˜¸í™˜
> - 12-Factor App ì›ì¹™ ì¤€ìˆ˜

</details>

<details>
<summary><strong>Q2: ELK Stackì´ ë©”ëª¨ë¦¬ë¥¼ ë„ˆë¬´ ë§ì´ ì‚¬ìš©í•˜ëŠ”ë° ì–´ë–»ê²Œ ì¤„ì´ë‚˜ìš”?</strong></summary>

**A**: JVM í™ ë©”ëª¨ë¦¬ ì„¤ì •ê³¼ ì¸ë±ìŠ¤ ê´€ë¦¬ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ìƒì„¸ ì„¤ëª…**:

**ë¬¸ì œ**:
```bash
$ docker stats
CONTAINER        MEM USAGE / LIMIT
elasticsearch    7.5GiB / 8GiB   (94%)
logstash         3.2GiB / 4GiB   (80%)
kibana           1.8GiB / 2GiB   (90%)
# ì´ 12.5GB ì‚¬ìš© ì¤‘! ğŸ˜±
```

**í•´ê²° ë°©ë²•**:

**1. Elasticsearch ë©”ëª¨ë¦¬ ìµœì í™”**
```yaml
# docker-compose.yml
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      # JVM í™ ë©”ëª¨ë¦¬ ì„¤ì • (ë¬¼ë¦¬ ë©”ëª¨ë¦¬ì˜ 50% ì´í•˜)
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"  # 8GB â†’ 2GBë¡œ ê°ì†Œ
      - discovery.type=single-node
      - xpack.security.enabled=false
    deploy:
      resources:
        limits:
          memory: 4g  # ì»¨í…Œì´ë„ˆ ì „ì²´ ë©”ëª¨ë¦¬ ì œí•œ
```

**2. Logstash ë©”ëª¨ë¦¬ ìµœì í™”**
```yaml
services:
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    environment:
      - "LS_JAVA_OPTS=-Xms512m -Xmx1g"  # 4GB â†’ 1GBë¡œ ê°ì†Œ
    deploy:
      resources:
        limits:
          memory: 2g
```

**3. ì˜¤ë˜ëœ ì¸ë±ìŠ¤ ìë™ ì‚­ì œ (ILM)**
```bash
# Index Lifecycle Management ì •ì±… ì„¤ì •
curl -X PUT "http://localhost:9200/_ilm/policy/lk-trade-policy" \
  -H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_size": "50gb",
            "max_age": "7d"
          }
        }
      },
      "delete": {
        "min_age": "30d",  # 30ì¼ í›„ ìë™ ì‚­ì œ
        "actions": {
          "delete": {}
        }
      }
    }
  }
}'
```

**4. ì‘ì€ í™˜ê²½ìš© ì„¤ì • (ê°œë°œ/í…ŒìŠ¤íŠ¸)**
```yaml
# docker-compose.dev.yml
services:
  elasticsearch:
    environment:
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"  # ìµœì†Œ ì„¤ì •
    deploy:
      resources:
        limits:
          memory: 1g

  logstash:
    environment:
      - "LS_JAVA_OPTS=-Xms256m -Xmx512m"
    deploy:
      resources:
        limits:
          memory: 1g

  kibana:
    environment:
      - NODE_OPTIONS="--max-old-space-size=512"
    deploy:
      resources:
        limits:
          memory: 1g

# ì´ 3GBë¡œ ì¶•ì†Œ!
```

**ë©”ëª¨ë¦¬ ìµœì í™” ê°€ì´ë“œë¼ì¸**:

| í™˜ê²½ | Elasticsearch | Logstash | Kibana | ì´í•© |
|-----|--------------|----------|--------|------|
| **ê°œë°œ** | 512MB | 512MB | 512MB | 1.5GB |
| **ì†Œê·œëª¨** | 2GB | 1GB | 1GB | 4GB |
| **ì¤‘ê·œëª¨** | 4GB | 2GB | 2GB | 8GB |
| **ëŒ€ê·œëª¨** | 8GB+ | 4GB+ | 2GB | 14GB+ |

</details>

<details>
<summary><strong>Q3: Kibanaì—ì„œ ë¡œê·¸ë¥¼ ê²€ìƒ‰í–ˆëŠ”ë° ë„ˆë¬´ ëŠë¦°ë° ì–´ë–»ê²Œ í•˜ë‚˜ìš”?</strong></summary>

**A**: ì‹œê°„ ë²”ìœ„ ì¶•ì†Œ, ì¸ë±ìŠ¤ ìµœì í™”, í•„ë“œ í•„í„°ë§ìœ¼ë¡œ ê²€ìƒ‰ ì†ë„ë¥¼ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ìƒì„¸ ì„¤ëª…**:

**ë¬¸ì œ**:
```
Kibana ê²€ìƒ‰ ì‹œ 30ì´ˆ ì´ìƒ ì†Œìš”... ğŸ˜´
```

**ì›ì¸ ì§„ë‹¨**:
```bash
# 1. ì¸ë±ìŠ¤ í¬ê¸° í™•ì¸
$ curl -X GET "http://localhost:9200/_cat/indices?v&h=index,docs.count,store.size"
index                    docs.count  store.size
lk-trade-2025.09.01     10,000,000      15gb
lk-trade-2025.09.02     12,000,000      18gb
lk-trade-2025.09.30      8,000,000      12gb
# ì´ 3000ë§Œ ê±´, 45GB! ğŸ˜±
```

**í•´ê²°ì±…**:

**1. ì‹œê°„ ë²”ìœ„ ì¶•ì†Œ (ê°€ì¥ íš¨ê³¼ì !)**
```
Kibana UI:
- "Last 15 minutes" ì„ íƒ (ê¸°ë³¸: Last 15 minutes)
- í•„ìš”ì‹œì—ë§Œ "Last 24 hours" ë˜ëŠ” "Last 7 days" ì‚¬ìš©

íš¨ê³¼:
- Last 7 days: 30ì´ˆ
- Last 24 hours: 5ì´ˆ
- Last 1 hour: 0.5ì´ˆ
```

**2. í•„ë“œ í•„í„°ë§ (ì •í™•í•œ ê²€ìƒ‰)**
```
âŒ ëŠë¦° ê²€ìƒ‰:
message: *error*
# ëª¨ë“  message í•„ë“œë¥¼ ì™€ì¼ë“œì¹´ë“œ ê²€ìƒ‰ â†’ ëŠë¦¼

âœ… ë¹ ë¥¸ ê²€ìƒ‰:
log_level: "ERROR"
# ì •í™•í•œ í•„ë“œ ë§¤ì¹­ â†’ ë¹ ë¦„

âœ… ë” ë¹ ë¥¸ ê²€ìƒ‰:
log_level: "ERROR" AND service_name: "user-service" AND @timestamp: [now-1h TO now]
# ë³µí•© ì¡°ê±´ìœ¼ë¡œ ë²”ìœ„ ì¢íˆê¸°
```

**3. ì¸ë±ìŠ¤ ìµœì í™”**
```bash
# ì¸ë±ìŠ¤ ë³‘í•© (merge)
curl -X POST "http://localhost:9200/lk-trade-*/_forcemerge?max_num_segments=1"

# íš¨ê³¼: ê²€ìƒ‰ ì†ë„ 30~50% í–¥ìƒ
```

**4. ìƒ¤ë“œ ìˆ˜ ì¡°ì •**
```bash
# ì¸ë±ìŠ¤ í…œí”Œë¦¿ ì„¤ì •
curl -X PUT "http://localhost:9200/_index_template/lk-trade-template" \
  -H 'Content-Type: application/json' -d'
{
  "index_patterns": ["lk-trade-*"],
  "template": {
    "settings": {
      "number_of_shards": 1,      # ë‹¨ì¼ ë…¸ë“œ: 1ê°œ (ê¸°ë³¸: 5ê°œ)
      "number_of_replicas": 0     # ê°œë°œ í™˜ê²½: 0ê°œ (í”„ë¡œë•ì…˜: 1~2ê°œ)
    }
  }
}'

# íš¨ê³¼: ë¶ˆí•„ìš”í•œ ìƒ¤ë“œ ì œê±°ë¡œ ê²€ìƒ‰ ì†ë„ í–¥ìƒ
```

**5. ìì£¼ ê²€ìƒ‰í•˜ëŠ” ì¿¼ë¦¬ ì €ì¥**
```
Kibana > Discover > Save Search
ì´ë¦„: "ìµœê·¼ 1ì‹œê°„ ì—ëŸ¬ ë¡œê·¸"
í•„í„°: log_level: "ERROR" AND @timestamp: [now-1h TO now]

â†’ ë‹¤ìŒë¶€í„° í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ì¦‰ì‹œ ê²€ìƒ‰!
```

**ì„±ëŠ¥ ë¹„êµ**:

| ë°©ë²• | Before | After | ê°œì„ ìœ¨ |
|-----|--------|-------|--------|
| ì‹œê°„ ë²”ìœ„ ì¶•ì†Œ (7ì¼â†’1ì‹œê°„) | 30ì´ˆ | 0.5ì´ˆ | 98% â†“ |
| í•„ë“œ í•„í„°ë§ (ì™€ì¼ë“œì¹´ë“œâ†’ì •í™•í•œ ë§¤ì¹­) | 10ì´ˆ | 2ì´ˆ | 80% â†“ |
| ì¸ë±ìŠ¤ ë³‘í•© | 5ì´ˆ | 2.5ì´ˆ | 50% â†“ |
| ìƒ¤ë“œ ìˆ˜ ìµœì í™” | 3ì´ˆ | 1.5ì´ˆ | 50% â†“ |

</details>

<details>
<summary><strong>Q4: ë¡œê·¸ì— ë¯¼ê° ì •ë³´(ë¹„ë°€ë²ˆí˜¸, ì¹´ë“œë²ˆí˜¸)ê°€ ë…¸ì¶œë˜ëŠ”ë° ì–´ë–»ê²Œ ë§‰ë‚˜ìš”?</strong></summary>

**A**: ë¡œê·¸ ì¶œë ¥ ì „ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ì™€ Logback í•„í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

**ìƒì„¸ ì„¤ëª…**:

**ë¬¸ì œ**:
```kotlin
// âŒ ìœ„í—˜í•œ ë¡œê·¸
logger.info("User login: email=${user.email}, password=${user.password}")
// ì¶œë ¥: User login: email=user@example.com, password=mySecretPassword123

logger.info("Payment: cardNumber=${payment.cardNumber}")
// ì¶œë ¥: Payment: cardNumber=1234-5678-9012-3456
```

**í•´ê²° ë°©ë²•**:

**1. ë§ˆìŠ¤í‚¹ í™•ì¥ í•¨ìˆ˜ (Kotlin)**
```kotlin
// MaskingExtensions.kt
fun String.maskEmail(): String {
    val parts = this.split("@")
    if (parts.size != 2) return "***@***.***"
    val local = parts[0]
    val domain = parts[1]
    val masked = local.take(2) + "*".repeat(maxOf(0, local.length - 2))
    return "$masked@$domain"
}

fun String.maskPhone(): String {
    return this.replaceRange(4, this.length - 4, "*".repeat(this.length - 8))
}

fun String.maskCardNumber(): String {
    return this.replaceRange(4, 15, " **** **** ****")
}

fun String.maskPassword(): String {
    return "***"  // ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ì•ŠìŒ
}

// ì‚¬ìš© ì˜ˆì‹œ
logger.info("User login: email=${user.email.maskEmail()}")
// ì¶œë ¥: User login: email=us**@example.com

logger.info("Payment: cardNumber=${payment.cardNumber.maskCardNumber()}")
// ì¶œë ¥: Payment: cardNumber=1234 **** **** ****
```

**2. ë°ì´í„° í´ë˜ìŠ¤ì— ë§ˆìŠ¤í‚¹ toString() êµ¬í˜„**
```kotlin
data class User(
    val id: Long,
    val email: String,
    val password: String,  // ì›ë³¸
    val phone: String
) {
    // ë¡œê·¸ìš© ì•ˆì „í•œ toString
    fun toLogString(): String {
        return "User(id=$id, email=${email.maskEmail()}, phone=${phone.maskPhone()})"
        // passwordëŠ” ì•„ì˜ˆ ì¶œë ¥ ì•ˆ í•¨!
    }
}

// ì‚¬ìš©
logger.info("Created user: ${user.toLogString()}")
// ì¶œë ¥: Created user: User(id=123, email=us**@example.com, phone=010-****-5678)
```

**3. Logback í•„í„° (ìë™ ë§ˆìŠ¤í‚¹)**
```xml
<!-- logback-spring.xml -->
<configuration>
    <!-- ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹ í•„í„° -->
    <conversionRule conversionWord="mask"
                    converterClass="com.lk.trade.logging.MaskingConverter" />

    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level [%thread] %logger : %mask%msg%n</pattern>
        </encoder>
    </appender>
</configuration>
```

```kotlin
// MaskingConverter.kt
class MaskingConverter : MessageConverter() {
    private val patterns = mapOf(
        Regex(""""password"\s*:\s*"([^"]+)"""") to """"password":"***"""",
        Regex(Regex("\\b\\d{4}-\\d{4}-\\d{4}-\\d{4}\\b")) to "****-****-****-****",
        Regex(Regex("\\b\\d{3}-\\d{4}-\\d{4}\\b")) to "***-****-****"
    )

    override fun convert(event: ILoggingEvent): String {
        var message = event.formattedMessage
        patterns.forEach { (regex, replacement) ->
            message = regex.replace(message, replacement)
        }
        return message
    }
}
```

**4. êµ¬ì¡°í™”ëœ ë¡œê¹…ì—ì„œ í•„ë“œ ì œì™¸**
```kotlin
logger.info("User created",
    kv("userId", user.id),
    kv("email", user.email.maskEmail()),
    // passwordëŠ” ì•„ì˜ˆ ë¡œê·¸ì— í¬í•¨í•˜ì§€ ì•ŠìŒ!
)

// JSON ì¶œë ¥:
{
  "message": "User created",
  "userId": 123,
  "email": "us**@example.com"
  // password í•„ë“œ ì—†ìŒ!
}
```

**Best Practice**:
- âœ… ë¹„ë°€ë²ˆí˜¸, í† í°: ì ˆëŒ€ ë¡œê·¸ì— ì¶œë ¥í•˜ì§€ ì•ŠìŒ
- âœ… ì´ë©”ì¼, ì „í™”ë²ˆí˜¸: ë¶€ë¶„ ë§ˆìŠ¤í‚¹
- âœ… ì¹´ë“œë²ˆí˜¸: ì• 4ìë¦¬ë§Œ í‘œì‹œ
- âœ… ê°œì¸ ì‹ë³„ ì •ë³´ (ì£¼ë¯¼ë²ˆí˜¸ ë“±): ì™„ì „ ë§ˆìŠ¤í‚¹

</details>

<details>
<summary><strong>Q5: docker-compose logsì™€ docker logsì˜ ì°¨ì´ê°€ ë­”ê°€ìš”?</strong></summary>

**A**: `docker logs`ëŠ” ê°œë³„ ì»¨í…Œì´ë„ˆ ë¡œê·¸ë¥¼, `docker-compose logs`ëŠ” ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ë¡œê·¸ë¥¼ í†µí•©í•´ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ìƒì„¸ ì„¤ëª…**:

**docker logs (ê°œë³„ ì»¨í…Œì´ë„ˆ)**:
```bash
# íŠ¹ì • ì»¨í…Œì´ë„ˆ í•˜ë‚˜ì˜ ë¡œê·¸ë§Œ
$ docker logs lk-user-service
2025-09-30 10:15:32.123 INFO  Application started
2025-09-30 10:16:45.456 ERROR Connection failed
...

# ì¥ì : ë¹ ë¦„, ë‹¨ìˆœí•¨
# ë‹¨ì : ì—¬ëŸ¬ ì»¨í…Œì´ë„ˆ ë¡œê·¸ë¥¼ í•œ ë²ˆì— ëª» ë´„
```

**docker-compose logs (ì—¬ëŸ¬ ì„œë¹„ìŠ¤ í†µí•©)**:
```bash
# ëª¨ë“  ì„œë¹„ìŠ¤ ë¡œê·¸ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ í†µí•©
$ docker-compose logs -f
user-service     | 2025-09-30 10:15:32.123 INFO  User login
trade-service    | 2025-09-30 10:15:33.456 INFO  Order created
account-service  | 2025-09-30 10:15:34.789 INFO  Balance updated
user-service     | 2025-09-30 10:15:35.012 INFO  User logout
# ì—¬ëŸ¬ ì„œë¹„ìŠ¤ê°€ ì„ì—¬ì„œ ë‚˜ì˜´ (ì‹œê°„ìˆœ ì •ë ¬)

# íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ë³´ê¸°
$ docker-compose logs -f user-service trade-service
user-service     | 2025-09-30 10:15:32.123 INFO  User login
trade-service    | 2025-09-30 10:15:33.456 INFO  Order created
# user-serviceì™€ trade-serviceë§Œ ì¶œë ¥

# ì¥ì : ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ë¡œê·¸ë¥¼ í•œ í™”ë©´ì—ì„œ ë³¼ ìˆ˜ ìˆìŒ
# ë‹¨ì : ë¡œê·¸ê°€ ë§ìœ¼ë©´ ì½ê¸° ì–´ë ¤ì›€
```

**ë¹„êµí‘œ**:

| ëª…ë ¹ì–´ | ëŒ€ìƒ | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|--------|------|------------|
| `docker logs <container>` | ê°œë³„ ì»¨í…Œì´ë„ˆ | íŠ¹ì • ì»¨í…Œì´ë„ˆë§Œ ì§‘ì¤‘ ë¶„ì„ |
| `docker-compose logs` | ëª¨ë“  ì„œë¹„ìŠ¤ | ì „ì²´ ì‹œìŠ¤í…œ íë¦„ íŒŒì•… |
| `docker-compose logs <service1> <service2>` | íŠ¹ì • ì„œë¹„ìŠ¤ë“¤ | ê´€ë ¨ ì„œë¹„ìŠ¤ë“¤ë§Œ í•¨ê»˜ ë¶„ì„ |

**ì‹¤ì „ ì‚¬ìš© íŒ**:

```bash
# 1. ì „ì²´ íë¦„ íŒŒì•… (ì²˜ìŒ)
$ docker-compose logs --tail 100

# 2. ë¬¸ì œ ìˆëŠ” ì„œë¹„ìŠ¤ ë°œê²¬
user-service     | ERROR: Something went wrong

# 3. í•´ë‹¹ ì„œë¹„ìŠ¤ë§Œ ì§‘ì¤‘ ë¶„ì„
$ docker logs -f lk-user-service --tail 500

# 4. ê´€ë ¨ ì„œë¹„ìŠ¤ë“¤ë„ í•¨ê»˜ í™•ì¸
$ docker-compose logs -f user-service account-service

# 5. ì—ëŸ¬ë§Œ í•„í„°ë§
$ docker-compose logs --tail 1000 | grep ERROR
```

**ì¶”ì²œ ì›Œí¬í”Œë¡œìš°**:
1. `docker-compose logs --tail 100`: ì „ì²´ ê°œìš” íŒŒì•…
2. `docker logs <íŠ¹ì •_ì»¨í…Œì´ë„ˆ>`: ë¬¸ì œ ì»¨í…Œì´ë„ˆ ì§‘ì¤‘ ë¶„ì„
3. `docker-compose logs <ì„œë¹„ìŠ¤1> <ì„œë¹„ìŠ¤2>`: ì—°ê´€ ì„œë¹„ìŠ¤ í•¨ê»˜ ë¶„ì„

</details>

---

## ğŸ“ ë©´ì ‘ ì§ˆë¬¸

### ì£¼ë‹ˆì–´ ë ˆë²¨

**Q1: Docker ì»¨í…Œì´ë„ˆì˜ ë¡œê·¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì–´ë””ì— ì €ì¥ë˜ë‚˜ìš”?**

**A**: `/var/lib/docker/containers/<container-id>/<container-id>-json.log` íŒŒì¼ì— JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.

**ìƒì„¸ ë‹µë³€**:
```bash
# ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜ í™•ì¸
$ docker inspect user-service | grep LogPath
"LogPath": "/var/lib/docker/containers/abc123.../abc123...-json.log"

# ë¡œê·¸ íŒŒì¼ ì§ì ‘ í™•ì¸ (Linux/Mac)
$ sudo tail -f /var/lib/docker/containers/abc123.../abc123...-json.log

# ë¡œê·¸ íŒŒì¼ í˜•ì‹ (JSON)
{"log":"2025-09-30 10:15:32.123 INFO  Application started\n","stream":"stdout","time":"2025-09-30T01:15:32.123456789Z"}
{"log":"2025-09-30 10:15:33.456 ERROR Connection failed\n","stream":"stderr","time":"2025-09-30T01:15:33.456789012Z"}
```

**ê¸°ë³¸ ë¡œê·¸ ë“œë¼ì´ë²„**:
- ë“œë¼ì´ë²„: `json-file` (ê¸°ë³¸ê°’)
- ìœ„ì¹˜: `/var/lib/docker/containers/`
- í˜•ì‹: JSON Lines (ê° ì¤„ì´ í•˜ë‚˜ì˜ JSON ê°ì²´)

**í•µì‹¬ í¬ì¸íŠ¸**:
- stdout/stderr ì¶œë ¥ì´ ìë™ìœ¼ë¡œ ìˆ˜ì§‘ë¨
- Docker Daemonì´ ìë™ìœ¼ë¡œ ì €ì¥
- ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì • ì•ˆ í•˜ë©´ ë¬´í•œì • ì¦ê°€ (ì£¼ì˜!)

---

**Q2: docker logs ëª…ë ¹ì–´ì˜ ì£¼ìš” ì˜µì…˜ 3ê°€ì§€ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.**

**A**: `--tail`, `-f`, `-t` ì˜µì…˜ì´ ê°€ì¥ ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.

**ìƒì„¸ ë‹µë³€**:

**1. `--tail N` (ìµœê·¼ Nì¤„ë§Œ ì¶œë ¥)**
```bash
# ìµœê·¼ 50ì¤„ë§Œ ë³´ê¸°
$ docker logs --tail 50 user-service

# ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
# - ì „ì²´ ë¡œê·¸ê°€ ë„ˆë¬´ ë§ì„ ë•Œ
# - ìµœì‹  ìƒíƒœë§Œ ë¹ ë¥´ê²Œ í™•ì¸í•  ë•Œ
# - ê¸°ë³¸ docker logsëŠ” ëª¨ë“  ë¡œê·¸ ì¶œë ¥ (ëŠë¦¼)
```

**2. `-f, --follow` (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°)**
```bash
# ì‹¤ì‹œê°„ìœ¼ë¡œ ë¡œê·¸ ë”°ë¼ê°€ê¸°
$ docker logs -f user-service

# Linuxì˜ tail -fì™€ ë™ì¼
# Ctrl+Cë¡œ ì¤‘ë‹¨í•  ë•Œê¹Œì§€ ê³„ì† ì¶œë ¥
# ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
# - ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ë¡œê·¸ ëª¨ë‹ˆí„°ë§
# - ì—ëŸ¬ ë°œìƒ ì—¬ë¶€ ì‹¤ì‹œê°„ í™•ì¸
# - ê°œë°œ ì¤‘ ë””ë²„ê¹…
```

**3. `-t, --timestamps` (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)**
```bash
# íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í•¨ê»˜ ì¶œë ¥
$ docker logs -t user-service
2025-09-30T01:15:32.123456789Z 2025-09-30 10:15:32.123 INFO  Application started
2025-09-30T01:15:33.456789012Z 2025-09-30 10:15:33.456 ERROR Connection failed

# ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
# - ì •í™•í•œ ì‹œê°„ íŒŒì•… í•„ìš”í•  ë•Œ
# - ì—¬ëŸ¬ ì»¨í…Œì´ë„ˆ ë¡œê·¸ ë¹„êµ ì‹œ
# - ì¥ì•  ì‹œê°„ ë¶„ì„
```

**ì¡°í•© ì‚¬ìš© (ì‹¤ì „)**:
```bash
# ìµœê·¼ 100ì¤„ì„ íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í•¨ê»˜ ì‹¤ì‹œê°„ìœ¼ë¡œ
$ docker logs --tail 100 -ft user-service

# íŠ¹ì • ì‹œê°„ ì´í›„ ë¡œê·¸ë§Œ
$ docker logs --since 2025-09-30T10:00:00 user-service

# ìµœê·¼ 1ì‹œê°„ ë¡œê·¸
$ docker logs --since 1h user-service
```

---

### ì¤‘ê¸‰ ë ˆë²¨

**Q3: ELK Stackì˜ ê° êµ¬ì„± ìš”ì†Œ ì—­í• ì„ ì„¤ëª…í•˜ê³ , Docker í™˜ê²½ì—ì„œ ë¡œê·¸ê°€ ì–´ë–»ê²Œ íë¥´ëŠ”ì§€ ì„¤ëª…í•˜ì„¸ìš”.**

**A**: **E**lasticsearch, **L**ogstash, **K**ibanaëŠ” ê°ê° ì €ì¥, ê°€ê³µ, ì‹œê°í™” ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

**ìƒì„¸ ë‹µë³€**:

**ì „ì²´ ë¡œê·¸ íë¦„**:
```
Docker Containers
    â†“ (stdout/stderr)
Docker Daemon
    â†“ (json-file)
JSON ë¡œê·¸ íŒŒì¼
    â†“
Filebeat (ìˆ˜ì§‘)
    â†“ (Beats Protocol)
Logstash (ê°€ê³µ)
    â†“ (HTTP/JSON)
Elasticsearch (ì €ì¥)
    â†“ (REST API)
Kibana (ì‹œê°í™”)
```

**ê° êµ¬ì„± ìš”ì†Œ ìƒì„¸**:

**1. Filebeat (ë¡œê·¸ ìˆ˜ì§‘ê¸°)**
```yaml
ì—­í• : Docker ì»¨í…Œì´ë„ˆ ë¡œê·¸ íŒŒì¼ì„ ì½ì–´ì„œ Logstashë¡œ ì „ì†¡

filebeat.inputs:
  - type: container
    paths:
      - '/var/lib/docker/containers/*/*.log'

output.logstash:
  hosts: ["logstash:5044"]

ì¥ì :
- ê°€ë³ê³  ë¹ ë¦„ (Goì–¸ì–´)
- ìë™ìœ¼ë¡œ Docker ë©”íƒ€ë°ì´í„° ì¶”ê°€
- ë„¤íŠ¸ì›Œí¬ ë‹¨ì ˆ ì‹œ ì¬ì „ì†¡ ë³´ì¥
```

**2. Logstash (ë¡œê·¸ ê°€ê³µ)**
```ruby
ì—­í• : ë¡œê·¸ë¥¼ íŒŒì‹±í•˜ê³  í•„í„°ë§í•˜ì—¬ êµ¬ì¡°í™”

input {
  beats {
    port => 5044  # Filebeatë¡œë¶€í„° ìˆ˜ì‹ 
  }
}

filter {
  # Spring Boot ë¡œê·¸ íŒŒì‹±
  grok {
    match => {
      "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} ..."
    }
  }

  # ë‚ ì§œ íŒŒì‹±
  date {
    match => ["timestamp", "ISO8601"]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "lk-trade-%{+YYYY.MM.dd}"
  }
}

ê¸°ëŠ¥:
- Grok íŒ¨í„´ìœ¼ë¡œ ë¹„êµ¬ì¡°í™” ë¡œê·¸ â†’ êµ¬ì¡°í™”
- í•„ë“œ ì¶”ê°€/ì œê±°/ë³€í™˜
- ì—¬ëŸ¬ ì†ŒìŠ¤ í†µí•©
```

**3. Elasticsearch (ë¡œê·¸ ì €ì¥ ë° ê²€ìƒ‰)**
```
ì—­í• : ë¡œê·¸ë¥¼ ìƒ‰ì¸í•˜ê³  ë¹ ë¥´ê²Œ ê²€ìƒ‰

íŠ¹ì§•:
- ë¶„ì‚° ê²€ìƒ‰ ì—”ì§„
- ì—­ìƒ‰ì¸(Inverted Index)ìœ¼ë¡œ ë¹ ë¥¸ ì „ë¬¸ ê²€ìƒ‰
- JSON ê¸°ë°˜ REST API
- ìˆ˜í‰ í™•ì¥ ê°€ëŠ¥ (ìƒ¤ë”©)

ë°ì´í„° ì €ì¥:
- ì¸ë±ìŠ¤: ë‚ ì§œë³„ ë¶„ë¦¬ (lk-trade-2025.09.30)
- ë„íë¨¼íŠ¸: ê° ë¡œê·¸ ë¼ì¸ì´ í•˜ë‚˜ì˜ JSON ë¬¸ì„œ
- í•„ë“œ: log_level, service_name, message, timestamp ë“±
```

**4. Kibana (ë¡œê·¸ ì‹œê°í™”)**
```
ì—­í• : Elasticsearch ë°ì´í„°ë¥¼ ì›¹ UIë¡œ ì‹œê°í™”

ê¸°ëŠ¥:
- Discover: ë¡œê·¸ ê²€ìƒ‰ ë° í•„í„°ë§
- Visualize: ì°¨íŠ¸, ê·¸ë˜í”„ ìƒì„±
- Dashboard: ì—¬ëŸ¬ ì‹œê°í™”ë¥¼ í•˜ë‚˜ì˜ ëŒ€ì‹œë³´ë“œë¡œ

ê²€ìƒ‰ ì˜ˆì‹œ:
- log_level: "ERROR"
- service_name: "user-service" AND response_time_ms: >1000
- @timestamp: [now-1h TO now]
```

**ì‹¤ì „ ì˜ˆì‹œ**:
```bash
# 1. ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ ì¶œë ¥
[user-service] 2025-09-30 10:15:32.123 ERROR Connection failed

# 2. Dockerê°€ JSONìœ¼ë¡œ ì €ì¥
{"log":"2025-09-30 10:15:32.123 ERROR Connection failed\n","stream":"stderr","time":"..."}

# 3. Filebeatê°€ ìˆ˜ì§‘í•˜ê³  Docker ë©”íƒ€ë°ì´í„° ì¶”ê°€
{
  "log": "2025-09-30 10:15:32.123 ERROR Connection failed",
  "container": {"name": "user-service"},
  ...
}

# 4. Logstashê°€ íŒŒì‹±
{
  "timestamp": "2025-09-30T10:15:32.123",
  "log_level": "ERROR",
  "message": "Connection failed",
  "service_name": "user-service"
}

# 5. Elasticsearchì— ì €ì¥
PUT /lk-trade-2025.09.30/_doc/abc123
{
  "@timestamp": "2025-09-30T10:15:32.123Z",
  "log_level": "ERROR",
  "message": "Connection failed",
  "service_name": "user-service"
}

# 6. Kibanaì—ì„œ ê²€ìƒ‰
log_level: "ERROR" AND service_name: "user-service"
â†’ ì¦‰ì‹œ ê²°ê³¼ í‘œì‹œ!
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- Filebeat: ê°€ë²¼ìš´ ìˆ˜ì§‘ê¸°
- Logstash: ê°•ë ¥í•œ íŒŒì‹± ì—”ì§„
- Elasticsearch: ë¹ ë¥¸ ê²€ìƒ‰ ì—”ì§„
- Kibana: ì§ê´€ì ì¸ UI

---

**Q4: ë¡œê·¸ ë¡œí…Œì´ì…˜ì´ ì™œ í•„ìš”í•˜ê³ , Dockerì—ì„œ ì–´ë–»ê²Œ ì„¤ì •í•˜ë‚˜ìš”?**

**A**: ë””ìŠ¤í¬ ê³µê°„ ê³ ê°ˆì„ ë°©ì§€í•˜ê¸° ìœ„í•´ í•„ìˆ˜ì´ë©°, `max-size`ì™€ `max-file` ì˜µì…˜ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

**ìƒì„¸ ë‹µë³€**:

**ë¬¸ì œ ìƒí™©**:
```bash
# ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì • ì•ˆ í–ˆì„ ë•Œ:
$ du -sh /var/lib/docker/containers/*/
18G  /var/lib/docker/containers/abc123.../  # user-service
12G  /var/lib/docker/containers/def456.../  # trade-service
...

# ë””ìŠ¤í¬ ê±°ì˜ ê½‰ ì°¸!
$ df -h
/dev/sda1  100G  95G  5G  95% /

# ê²°ê³¼: ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ìœ„í—˜!
```

**ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì •**:
```yaml
# docker-compose.yml
services:
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # íŒŒì¼ í•˜ë‚˜ë‹¹ ìµœëŒ€ 10MB
        max-file: "3"     # ìµœëŒ€ 3ê°œ íŒŒì¼ ìœ ì§€
        # â†’ ì´ ìµœëŒ€ 30MBë¡œ ì œí•œ
```

**ë™ì‘ ë°©ì‹**:
```
1. user-service-json.log (0MB â†’ 10MBê¹Œì§€ ì¦ê°€)
   â””â†’ 10MB ë„ë‹¬

2. user-service-json.log â†’ user-service-json.log.1 (ì´ë¦„ ë³€ê²½)
   user-service-json.log (ìƒˆë¡œ ìƒì„±, 0MBë¶€í„° ì‹œì‘)

3. user-service-json.log (10MB)
   user-service-json.log.1 (10MB)

4. user-service-json.log â†’ user-service-json.log.1
   user-service-json.log.1 â†’ user-service-json.log.2
   user-service-json.log (ìƒˆë¡œ ìƒì„±)

5. user-service-json.log (10MB)
   user-service-json.log.1 (10MB)
   user-service-json.log.2 (10MB)
   â†’ ì´ 30MB

6. max-file=3 ë„ë‹¬, ê°€ì¥ ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ:
   user-service-json.log.2 ì‚­ì œ
   user-service-json.log â†’ user-service-json.log.1
   user-service-json.log.1 â†’ user-service-json.log.2
   user-service-json.log (ìƒˆë¡œ ìƒì„±)

â†’ í•­ìƒ 30MB ì´í•˜ ìœ ì§€!
```

**ê¶Œì¥ ì„¤ì •ê°’**:

| í™˜ê²½ | max-size | max-file | ì´ ìš©ëŸ‰ | ë³´ì¡´ ê¸°ê°„ |
|-----|----------|----------|---------|----------|
| **ê°œë°œ** | 10m | 3 | 30MB | ~1ì¼ |
| **í…ŒìŠ¤íŠ¸** | 50m | 5 | 250MB | ~1ì£¼ |
| **í”„ë¡œë•ì…˜** | 100m | 10 | 1GB | ~1ê°œì›” |
| **ëŒ€ìš©ëŸ‰** | 500m | 20 | 10GB | ~3ê°œì›” |

**ì„¤ì • ê²€ì¦**:
```bash
# í˜„ì¬ ë¡œê·¸ ì„¤ì • í™•ì¸
$ docker inspect user-service | jq '.[0].HostConfig.LogConfig'
{
  "Type": "json-file",
  "Config": {
    "max-size": "10m",
    "max-file": "3"
  }
}

# ë¡œê·¸ íŒŒì¼ í¬ê¸° í™•ì¸
$ sudo ls -lh /var/lib/docker/containers/abc123.../
-rw-r----- 1 root root 10M Oct 1 10:00 abc123...-json.log
-rw-r----- 1 root root 10M Oct 1 09:00 abc123...-json.log.1
-rw-r----- 1 root root 10M Oct 1 08:00 abc123...-json.log.2
# ì´ 30MB âœ…
```

**ì£¼ì˜ì‚¬í•­**:
- ì„¤ì • ë³€ê²½ í›„ ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘ í•„ìš”
- ê¸°ì¡´ ë¡œê·¸ íŒŒì¼ì€ ìë™ìœ¼ë¡œ ì •ë¦¬ ì•ˆ ë¨ (ìˆ˜ë™ ì‚­ì œ í•„ìš”)
- `max-file=1`ì€ ë„ˆë¬´ ì ìŒ (ìµœì†Œ 3ê°œ ê¶Œì¥)

---

**Q5: Correlation IDë¥¼ ì‚¬ìš©í•œ ë¶„ì‚° ì¶”ì ì˜ ì›ë¦¬ë¥¼ ì„¤ëª…í•˜ê³ , ì‹¤ì œ êµ¬í˜„ ë°©ë²•ì„ ì½”ë“œë¡œ ë³´ì—¬ì£¼ì„¸ìš”.**

**A**: ìš”ì²­ë§ˆë‹¤ ê³ ìœ  IDë¥¼ ë¶€ì—¬í•˜ê³  ëª¨ë“  ì„œë¹„ìŠ¤ í˜¸ì¶œì— ì „ë‹¬í•˜ì—¬, ì—¬ëŸ¬ ì„œë¹„ìŠ¤ë¥¼ ê±°ì¹˜ëŠ” ìš”ì²­ íë¦„ì„ ì¶”ì í•©ë‹ˆë‹¤.

**ìƒì„¸ ë‹µë³€**:

**ë¬¸ì œ ìƒí™©**:
```
ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í™˜ê²½:

ì‚¬ìš©ì ìš”ì²­
  â†“
API Gateway â†’ user-service â†’ account-service â†’ trade-service
                     â†“              â†“                â†“
                  ë¡œê·¸ A         ë¡œê·¸ B           ë¡œê·¸ C

ë¬¸ì œ: ë¡œê·¸ A, B, Cê°€ ê°™ì€ ìš”ì²­ì¸ì§€ ì•Œ ìˆ˜ ì—†ìŒ!

user-service ë¡œê·¸:
10:15:32.123 INFO User authenticated
10:15:35.456 INFO User authenticated  # ë‹¤ë¥¸ ìš”ì²­ì¸ì§€ ê°™ì€ ìš”ì²­ì¸ì§€?

account-service ë¡œê·¸:
10:15:33.789 INFO Balance checked
10:15:34.012 INFO Balance checked  # ì–´ë–¤ user-service ìš”ì²­ì—ì„œ ì˜¨ ê±´ì§€?
```

**Correlation ID ì›ë¦¬**:
```
ì‚¬ìš©ì ìš”ì²­ (correlationId: abc-123-def)
  â†“
API Gateway (abc-123-def ìƒì„±, í—¤ë”ì— ì¶”ê°€)
  â†“
user-service (abc-123-def ìˆ˜ì‹ , ë¡œê·¸ì— ê¸°ë¡)
  â†“ ë‹¤ìŒ ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹œ ì „ë‹¬
account-service (abc-123-def ìˆ˜ì‹ , ë¡œê·¸ì— ê¸°ë¡)
  â†“ ë‹¤ìŒ ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹œ ì „ë‹¬
trade-service (abc-123-def ìˆ˜ì‹ , ë¡œê·¸ì— ê¸°ë¡)

ëª¨ë“  ë¡œê·¸ì— abc-123-defê°€ í¬í•¨ë¨!
```

**êµ¬í˜„ ì½”ë“œ (Spring Boot + Kotlin)**:

**1. Interceptorë¡œ Correlation ID ê´€ë¦¬**
```kotlin
// CorrelationIdInterceptor.kt
@Component
class CorrelationIdInterceptor : HandlerInterceptor {
    companion object {
        const val CORRELATION_ID_HEADER = "X-Correlation-ID"
        const val CORRELATION_ID_MDC_KEY = "correlationId"
    }

    override fun preHandle(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any
    ): Boolean {
        // 1. í—¤ë”ì—ì„œ Correlation ID ê°€ì ¸ì˜¤ê¸°
        val correlationId = request.getHeader(CORRELATION_ID_HEADER)
            ?: UUID.randomUUID().toString()  // ì—†ìœ¼ë©´ ìƒì„±

        // 2. MDCì— ì €ì¥ (ëª¨ë“  ë¡œê·¸ì— ìë™ í¬í•¨ë¨)
        MDC.put(CORRELATION_ID_MDC_KEY, correlationId)

        // 3. ì‘ë‹µ í—¤ë”ì—ë„ ì¶”ê°€ (í´ë¼ì´ì–¸íŠ¸ê°€ í™•ì¸ ê°€ëŠ¥)
        response.setHeader(CORRELATION_ID_HEADER, correlationId)

        return true
    }

    override fun afterCompletion(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any,
        ex: Exception?
    ) {
        // ìš”ì²­ ì™„ë£Œ í›„ MDC ì •ë¦¬ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
        MDC.clear()
    }
}

// WebMvcConfig.kt (ë“±ë¡)
@Configuration
class WebMvcConfig(
    private val correlationIdInterceptor: CorrelationIdInterceptor
) : WebMvcConfigurer {
    override fun addInterceptors(registry: InterceptorRegistry) {
        registry.addInterceptor(correlationIdInterceptor)
    }
}
```

**2. Feign Clientì—ì„œ Correlation ID ì „ë‹¬**
```kotlin
// CorrelationIdFeignInterceptor.kt
@Component
class CorrelationIdFeignInterceptor : RequestInterceptor {
    override fun apply(template: RequestTemplate) {
        // MDCì—ì„œ Correlation ID ê°€ì ¸ì™€ì„œ í—¤ë”ì— ì¶”ê°€
        val correlationId = MDC.get(CorrelationIdInterceptor.CORRELATION_ID_MDC_KEY)
        if (correlationId != null) {
            template.header(
                CorrelationIdInterceptor.CORRELATION_ID_HEADER,
                correlationId
            )
        }
    }
}

// Feign Client ì„¤ì •
@FeignClient(
    name = "account-service",
    configuration = [CorrelationIdFeignInterceptor::class]
)
interface AccountServiceClient {
    @GetMapping("/api/accounts/{userId}/balance")
    fun getBalance(@PathVariable userId: Long): BalanceResponse
}
```

**3. Logback ì„¤ì • (Correlation ID í¬í•¨)**
```xml
<!-- logback-spring.xml -->
<configuration>
    <appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <!-- MDCì˜ correlationIdë¥¼ ìë™ìœ¼ë¡œ í¬í•¨ -->
            <includeMdcKeyName>correlationId</includeMdcKeyName>
            <fieldNames>
                <timestamp>timestamp</timestamp>
                <message>message</message>
                <logger>logger</logger>
                <level>level</level>
            </fieldNames>
        </encoder>
    </appender>

    <root level="INFO">
        <appender-ref ref="JSON"/>
    </root>
</configuration>
```

**4. ë¡œê·¸ ì¶œë ¥ ì˜ˆì‹œ**
```kotlin
// UserService.kt
class UserService(
    private val accountServiceClient: AccountServiceClient
) {
    private val logger = LoggerFactory.getLogger(UserService::class.java)

    fun getUserBalance(userId: Long): Balance {
        logger.info("Fetching balance for user {}", userId)
        // correlationIdëŠ” MDCì—ì„œ ìë™ìœ¼ë¡œ ë¡œê·¸ì— í¬í•¨ë¨!

        val balance = accountServiceClient.getBalance(userId)
        // Feign Clientê°€ ìë™ìœ¼ë¡œ Correlation IDë¥¼ í—¤ë”ì— ì¶”ê°€

        logger.info("Balance fetched: {}", balance.amount)
        return balance
    }
}
```

**ì‹¤ì œ ë¡œê·¸ ì¶œë ¥**:
```json
// user-service ë¡œê·¸:
{
  "timestamp": "2025-09-30T10:15:32.123Z",
  "level": "INFO",
  "logger": "com.lk.trade.user.UserService",
  "message": "Fetching balance for user 123",
  "correlationId": "abc-123-def-456",  // â† ì—¬ê¸°!
  "service": "user-service"
}

// account-service ë¡œê·¸:
{
  "timestamp": "2025-09-30T10:15:32.345Z",
  "level": "INFO",
  "logger": "com.lk.trade.account.AccountService",
  "message": "Getting balance for user 123",
  "correlationId": "abc-123-def-456",  // â† ê°™ì€ ID!
  "service": "account-service"
}
```

**Kibanaì—ì„œ ì¶”ì **:
```
ê²€ìƒ‰: correlationId: "abc-123-def-456"

ê²°ê³¼ (ì‹œê°„ìˆœ):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
10:15:32.123 | user-service     | Fetching balance for user 123
10:15:32.345 | account-service  | Getting balance for user 123
10:15:32.456 | account-service  | Balance: $1,000
10:15:32.567 | user-service     | Balance fetched: $1,000
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â†’ ì „ì²´ ìš”ì²­ íë¦„ì´ í•œëˆˆì—!
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- **MDC (Mapped Diagnostic Context)**: ThreadLocal ê¸°ë°˜, í˜„ì¬ ìŠ¤ë ˆë“œì˜ ë¡œê·¸ì— ìë™ í¬í•¨
- **HTTP í—¤ë” ì „ë‹¬**: X-Correlation-ID í—¤ë”ë¡œ ì„œë¹„ìŠ¤ ê°„ ì „ë‹¬
- **ìë™í™”**: Interceptorì™€ Feign Interceptorë¡œ ê°œë°œìê°€ ì‹ ê²½ ì•ˆ ì¨ë„ ë¨

---

## ë‹¤ìŒ ë‹¨ê³„

ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰ ì´ì œ Docker ë¡œê·¸ ê´€ë¦¬ì˜ ëª¨ë“  ê²ƒì„ ë°°ì› ìŠµë‹ˆë‹¤.

### ì´ë²ˆ ì„¹ì…˜ì—ì„œ ë°°ìš´ ê²ƒ

âœ… Docker ë¡œê·¸ ë“œë¼ì´ë²„ ì¢…ë¥˜ì™€ ì„¤ì •
âœ… ELK Stack (Elasticsearch + Logstash + Kibana) êµ¬ì¶•
âœ… Filebeatë¡œ Docker ì»¨í…Œì´ë„ˆ ë¡œê·¸ ìë™ ìˆ˜ì§‘
âœ… Logstashë¡œ ë¡œê·¸ íŒŒì‹± ë° ê°€ê³µ
âœ… Kibanaì—ì„œ ë¡œê·¸ ê²€ìƒ‰ ë° ì‹œê°í™”
âœ… êµ¬ì¡°í™”ëœ ë¡œê¹… ë° Correlation ID ì¶”ì 
âœ… ë¡œê·¸ ê´€ë¦¬ ëª¨ë²” ì‚¬ë¡€
âœ… LK-Trade í”„ë¡œì íŠ¸ì— ë¡œê·¸ ê´€ë¦¬ í†µí•©

### ë‹¤ìŒì— ë°°ìš¸ ê²ƒ

**ì„¹ì…˜ 27: ë³´ì•ˆ (Security)**ì—ì„œëŠ”:
- Docker ë³´ì•ˆ ëª¨ë²” ì‚¬ë¡€
- ì»¨í…Œì´ë„ˆ ê²©ë¦¬ ë° ê¶Œí•œ ê´€ë¦¬
- ì´ë¯¸ì§€ ì·¨ì•½ì  ìŠ¤ìº”
- Secrets ê´€ë¦¬
- ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ
- ë³´ì•ˆ ì •ì±… ì ìš©

### ì¶”ê°€ í•™ìŠµ ìë£Œ

**ê³µì‹ ë¬¸ì„œ:**
- [Docker Logging](https://docs.docker.com/config/containers/logging/)
- [Elastic Stack](https://www.elastic.co/guide/index.html)
- [Filebeat Reference](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)
- [Logstash Reference](https://www.elastic.co/guide/en/logstash/current/index.html)

**ì‹¬í™” í•™ìŠµ:**
- [ELK Stack Tutorial](https://www.elastic.co/webinars/getting-started-elasticsearch)
- [Structured Logging Best Practices](https://betterstack.com/community/guides/logging/structured-logging/)
- [Distributed Tracing with OpenTelemetry](https://opentelemetry.io/)

**ì‹¤ì „ ì—°ìŠµ:**
1. LK-Trade í”„ë¡œì íŠ¸ì— ELK Stack ì ìš©
2. Kibana ëŒ€ì‹œë³´ë“œ ì»¤ìŠ¤í„°ë§ˆì´ì§•
3. ì•Œë¦¼ ê·œì¹™ ì„¤ì • (Elasticsearch Watcher)
4. ë¡œê·¸ ê¸°ë°˜ ì„±ëŠ¥ ë¶„ì„ ë° ìµœì í™”

---

**ë‹¤ìŒ ì„¹ì…˜ì—ì„œ ë§Œë‚˜ìš”!** ğŸš€