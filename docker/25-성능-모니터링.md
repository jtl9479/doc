# 25. 컨테이너 성능 모니터링

> **학습 목표**: Docker 컨테이너의 성능을 실시간으로 모니터링하고 Prometheus, Grafana 등 전문 도구를 활용하여 병목 지점을 찾고 최적화할 수 있습니다.

**⏱️ 예상 학습 시간**: 3-4시간
**난이도**: ⭐⭐⭐⭐☆ (4개/5개)

---

## 목차
1. [왜 필요한가](#왜-필요한가)
2. [실생활 비유](#실생활-비유로-이해하기)
3. [docker stats 활용](#docker-stats-활용)
4. [cAdvisor 설치 및 사용](#cadvisor-설치-및-사용)
5. [Prometheus + Grafana 연동](#prometheus-grafana-연동)
6. [성능 메트릭 분석](#성능-메트릭-분석)
7. [병목 지점 찾기](#병목-지점-찾기)
8. [알림 설정](#알림-설정)
9. [실전 예제: LK-Trade 모니터링](#실전-예제-lk-trade-모니터링)
10. [주니어 개발자 시나리오](#주니어-개발자-시나리오)
11. [FAQ](#faq)
12. [면접 질문](#면접-질문)
13. [트러블슈팅](#트러블슈팅)

---

## 💡 왜 필요한가

### 실무 배경

**"프로덕션 서버가 느려졌는데, 어디가 문제인지 모르겠어요!"**

#### ❌ 성능 모니터링이 없으면 발생하는 문제

```
문제 1: 장애 발생 후에야 인지
- 증상: 사용자가 "느려요" 신고
- 대응: 원인 파악에 수 시간 소요
- 영향: 서비스 다운타임 누적
- 비용: 시간당 500만원 매출 손실

문제 2: 근본 원인 찾기 어려움
- 증상: CPU 100%인데 어떤 컨테이너인지 모름
- 대응: 모든 컨테이너를 하나씩 확인
- 영향: 평균 해결 시간 6시간
- 비용: 개발팀 야근, 긴급 회의 소집

문제 3: 확장 시점 놓침
- 증상: "메모리가 90%인데 몇 시간째인가요?"
- 대응: 이미 늦음, 서비스 먹통
- 영향: 대규모 장애로 확산
- 비용: 고객 이탈률 30% 증가
```

#### ✅ 체계적 모니터링을 구축하면

```
해결책 1: 실시간 문제 감지
- 방법: Prometheus + Grafana 대시보드
- 효과: CPU/메모리 80% 도달 시 즉시 알림
- 절감: 장애 예방율 95%, 다운타임 제로

해결책 2: 5분 내 원인 파악
- 방법: 컨테이너별 메트릭 추적
- 효과: 문제 컨테이너 즉시 식별
- 절감: 평균 해결 시간 6시간 → 15분

해결책 3: 예측 가능한 확장
- 방법: 히스토리 데이터 기반 트렌드 분석
- 효과: 리소스 부족 7일 전 경고
- 절감: 인프라 비용 최적화 30%
```

### 수치로 보는 효과

| 지표 | Before | After | 개선율 |
|------|--------|-------|--------|
| 장애 발견 시간 | 평균 2시간 후 | 실시간 (1분 이내) | **99%↓** |
| 원인 파악 시간 | 평균 6시간 | 평균 15분 | **96%↓** |
| 서비스 다운타임 | 월 10시간 | 월 0.5시간 | **95%↓** |
| 야간 긴급 콜 | 월 8회 | 월 1회 | **88%↓** |
| 인프라 비용 절감 | - | 월 300만원 | **30%↓** |

---

## 🔍 실생활 비유로 이해하기

### 비유 1: 자동차 계기판 (향상된 버전)

```
계기판 없는 자동차로 고속도로 주행:
┌─────────────────────────────────────────┐
│ ❌ 문제 상황                             │
├─────────────────────────────────────────┤
│ - 속도계 없음 → 과속 단속 딱 걸림       │
│ - 연료계 없음 → 고속도로 한복판에서 멈춤│
│ - 엔진 온도계 없음 → 과열로 엔진 망가짐 │
│ - 브레이크등 없음 → 뒤차가 추돌        │
│                                         │
│ 결과: 큰 사고 발생 💥                   │
└─────────────────────────────────────────┘

계기판 있는 자동차:
┌─────────────────────────────────────────┐
│ ✅ 안전한 주행                           │
├─────────────────────────────────────────┤
│ - 속도계: 120km/h (제한 속도 준수)      │
│ - 연료계: 30% (다음 휴게소에서 주유)    │
│ - 엔진 온도: 정상 범위                  │
│ - 경고등: 모두 꺼짐                     │
│                                         │
│ + 내비게이션: 앞으로 10km 교통 체증     │
│   → 미리 우회 경로 선택                 │
│                                         │
│ 결과: 안전하고 효율적인 주행 ✅         │
└─────────────────────────────────────────┘
```

**Docker 환경 대응**:
```
모니터링 없음 = 계기판 없는 차:
┌─────────────────────────────────────────┐
│ - CPU 사용률? 모름                      │
│ - 메모리 사용량? 모름                   │
│ - 디스크 I/O? 모름                      │
│ - 네트워크 트래픽? 모름                 │
│                                         │
│ → 서비스 다운 후에야 인지 ❌            │
│ → 원인 파악에 6시간 소요                │
└─────────────────────────────────────────┘

모니터링 있음 = 첨단 계기판:
┌─────────────────────────────────────────┐
│ - CPU 95% → ⚠️ 알림 → 스케일 아웃     │
│ - 메모리 90% → ⚠️ 알림 → 증설 준비    │
│ - 디스크 I/O 높음 → 쿼리 최적화        │
│ - 네트워크 지연 → 병목 지점 즉시 파악  │
│                                         │
│ + 예측 분석: 3일 후 메모리 부족 예상    │
│   → 미리 리소스 증설                    │
│                                         │
│ → 문제 발생 전 예방 ✅                 │
└─────────────────────────────────────────┘
```

---

### 비유 2: 병원 환자 모니터링 시스템

```
중환자실 환자 모니터링:

모니터 없는 병실 (1960년대):
┌─────────────────────────────────────────┐
│ 간호사가 1시간마다 손목으로 맥박 체크   │
│ - 심박수 체크: 매 1시간마다             │
│ - 혈압 측정: 매 4시간마다               │
│ - 체온 측정: 매 6시간마다               │
│                                         │
│ ❌ 문제:                                │
│ - 급성 심정지 → 30분 후 발견            │
│ - 이미 손쓸 수 없는 상태                │
│ - 사망률 높음                           │
└─────────────────────────────────────────┘

현대 중환자실 (실시간 모니터링):
┌─────────────────────────────────────────┐
│ 실시간 생체 신호 모니터링               │
│ ┌─────────────────────────────────────┐ │
│ │ 심박수: 72 bpm  (정상)              │ │
│ │ 혈압: 120/80 mmHg  (정상)           │ │
│ │ 산소포화도: 98%  (정상)             │ │
│ │ 체온: 36.8°C  (정상)                │ │
│ └─────────────────────────────────────┘ │
│                                         │
│ ⚠️ 심박수 150 초과 → 즉시 알람 울림!   │
│ → 의료진 5초 내 도착                    │
│ → 즉각 응급 처치                        │
│                                         │
│ ✅ 결과: 생존율 95% 향상                │
└─────────────────────────────────────────┘
```

**Docker 모니터링 대응**:
```
┌─────────────────────────────────────────┐
│ Grafana 대시보드 (실시간 모니터링)      │
│ ┌─────────────────────────────────────┐ │
│ │ user-service                        │ │
│ │ - CPU: 45% (정상)                   │ │
│ │ - Memory: 680MB / 1GB (정상)        │ │
│ │ - Latency: 120ms (정상)             │ │
│ │ - Error Rate: 0.1% (정상)           │ │
│ └─────────────────────────────────────┘ │
│                                         │
│ ⚠️ account-service CPU 90% 초과!       │
│ ┌─────────────────────────────────────┐ │
│ │ 🚨 Slack 알림 발송                  │ │
│ │ 📧 Email 알림 발송                  │ │
│ │ 📱 SMS 알림 발송 (Critical)         │ │
│ └─────────────────────────────────────┘ │
│                                         │
│ → 개발자 1분 내 확인                    │
│ → 5분 내 원인 파악 (쿼리 최적화 필요)   │
│ → 10분 내 스케일 아웃 적용              │
│                                         │
│ ✅ 결과: 서비스 다운 방지               │
└─────────────────────────────────────────┘
```

---

### 비유 3: 공장 생산 라인 대시보드

```
모니터링 없는 공장 (1950년대):
┌─────────────────────────────────────────┐
│ 작업 현황                               │
│                                         │
│ 라인 1: ??? (모름)                      │
│ 라인 2: ??? (모름)                      │
│ 라인 3: ??? (모름)                      │
│                                         │
│ 문제 발생:                              │
│ - 라인 2가 3시간 전 멈췄는데 모름       │
│ - 불량품 1000개 생산 후 발견            │
│ - 원인: 기계 과열 (온도계 없어서 몰랐음)│
│                                         │
│ ❌ 손실: 1000만원 + 라인 정지 비용      │
└─────────────────────────────────────────┘

스마트 팩토리 (실시간 대시보드):
┌─────────────────────────────────────────┐
│ 전체 생산 라인 모니터링                 │
│ ┌─────────────────────────────────────┐ │
│ │ 라인 1: ✅ 정상 (시간당 500개 생산) │ │
│ │   - 온도: 45°C (정상)               │ │
│ │   - 진동: 0.2mm (정상)              │ │
│ │   - 불량률: 0.5% (정상)             │ │
│ │                                     │ │
│ │ 라인 2: ⚠️ 경고 (온도 상승)        │ │
│ │   - 온도: 78°C (경고!) → 알림!      │ │
│ │   - 진동: 0.5mm (주의)              │ │
│ │   - 불량률: 2% (증가 추세)          │ │
│ │   → 자동으로 냉각 시스템 가동       │ │
│ │   → 담당자에게 알림 전송            │ │
│ │                                     │ │
│ │ 라인 3: ✅ 정상 (시간당 450개 생산) │ │
│ └─────────────────────────────────────┘ │
│                                         │
│ ✅ 결과: 불량품 0개, 다운타임 제로      │
└─────────────────────────────────────────┘
```

**Docker 마이크로서비스 대응**:
```
┌─────────────────────────────────────────┐
│ LK-Trade 전체 시스템 대시보드           │
│ ┌─────────────────────────────────────┐ │
│ │ user-service: ✅ 정상               │ │
│ │   - CPU: 45% | Memory: 680MB        │ │
│ │   - Latency: 120ms | QPS: 1,200     │ │
│ │   - Error: 0.1%                     │ │
│ │                                     │ │
│ │ account-service: ⚠️ 경고            │ │
│ │   - CPU: 92% ← 임계치 초과!         │ │
│ │   - Memory: 1.8GB / 2GB             │ │
│ │   - Latency: 850ms ← 느림!          │ │
│ │   - Error: 3% ← 증가 중!            │ │
│ │   → 즉시 Slack 알림                 │ │
│ │   → 자동 스케일 아웃 시작 (2→3 pod) │ │
│ │                                     │ │
│ │ trade-service: ✅ 정상              │ │
│ │   - CPU: 38% | Memory: 920MB        │ │
│ │   - Latency: 95ms | QPS: 800        │ │
│ └─────────────────────────────────────┘ │
│                                         │
│ 📊 예측 분석:                           │
│ - DB 연결 풀: 2시간 후 고갈 예상        │
│   → 미리 연결 풀 크기 증가              │
│                                         │
│ ✅ 결과: 장애 예방, SLA 99.9% 달성      │
└─────────────────────────────────────────┘
```

**핵심 메시지**:
> "모니터링은 선택이 아닌 필수!"
> 중환자실 환자에게 생체 신호 모니터가 필수이듯,
> 프로덕션 시스템에도 성능 모니터링이 필수입니다.

---

## 성능 모니터링의 중요성

### 모니터링해야 할 주요 메트릭

```
┌─────────────────────┬──────────────────────────────────┐
│   메트릭 종류       │          의미                    │
├─────────────────────┼──────────────────────────────────┤
│ CPU 사용률          │ 프로세서 부하 수준               │
│                     │ (높으면 스케일 아웃 필요)        │
├─────────────────────┼──────────────────────────────────┤
│ 메모리 사용량       │ RAM 사용 정도                    │
│                     │ (높으면 메모리 증설 또는 누수)   │
├─────────────────────┼──────────────────────────────────┤
│ 네트워크 I/O        │ 송수신 데이터량                  │
│                     │ (대역폭 병목 확인)               │
├─────────────────────┼──────────────────────────────────┤
│ 디스크 I/O          │ 읽기/쓰기 속도                   │
│                     │ (스토리지 병목 확인)             │
├─────────────────────┼──────────────────────────────────┤
│ 응답 시간           │ 요청 처리 시간                   │
│                     │ (사용자 경험 지표)               │
├─────────────────────┼──────────────────────────────────┤
│ 에러율              │ 실패한 요청 비율                 │
│                     │ (서비스 안정성 지표)             │
└─────────────────────┴──────────────────────────────────┘
```

---

## docker stats 활용

### 기본 사용법

```bash
# 실시간 모니터링 (계속 갱신)
docker stats

# 1회만 출력
docker stats --no-stream

# 특정 컨테이너만
docker stats user-service account-service

# 모든 컨테이너 (중지된 것 포함)
docker stats --all
```

### 출력 형식

```
CONTAINER ID   NAME           CPU %   MEM USAGE / LIMIT   MEM %   NET I/O         BLOCK I/O
a1b2c3d4e5f6   user-service   2.50%   450MiB / 1GiB       43.95%  1.2kB / 648B    0B / 0B
```

**각 열의 의미**:
- **CPU %**: CPU 사용률 (멀티코어 환경에서는 100% 이상 가능)
- **MEM USAGE / LIMIT**: 현재 메모리 / 제한
- **MEM %**: 메모리 사용 비율
- **NET I/O**: 네트워크 송수신량 (전체 누적)
- **BLOCK I/O**: 디스크 읽기/쓰기 (전체 누적)

### 커스텀 포맷

```bash
# CPU와 메모리만 출력
docker stats --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}"

# JSON 형식
docker stats --format "{{json .}}" --no-stream

# CSV 형식
docker stats --no-stream --format "{{.Name}},{{.CPUPerc}},{{.MemUsage}}"
```

### 모니터링 스크립트

```bash
#!/bin/bash
# scripts/stats-monitor.sh

# 실시간 모니터링 + 로그 저장

LOG_DIR="./logs/stats"
LOG_FILE="$LOG_DIR/stats_$(date +%Y%m%d).csv"

mkdir -p $LOG_DIR

# 헤더 작성 (처음 실행 시)
if [ ! -f "$LOG_FILE" ]; then
    echo "Timestamp,Container,CPU,Memory,MemoryPercent,NetIO,BlockIO" > $LOG_FILE
fi

# 무한 루프 모니터링
while true; do
    TIMESTAMP=$(date +"%Y-%m-%d %H:%M:%S")

    docker stats --no-stream --format "{{.Name}},{{.CPUPerc}},{{.MemUsage}},{{.MemPerc}},{{.NetIO}},{{.BlockIO}}" | while read line; do
        echo "$TIMESTAMP,$line" >> $LOG_FILE
    done

    sleep 60  # 1분마다 수집
done
```

### 고급 분석 스크립트

```bash
#!/bin/bash
# scripts/stats-analyzer.sh

LOG_FILE=$1

if [ -z "$LOG_FILE" ]; then
    echo "Usage: $0 <log-file>"
    exit 1
fi

echo "📊 통계 분석: $LOG_FILE"
echo ""

# 컨테이너별 평균 CPU 사용률
echo "=== 평균 CPU 사용률 ==="
awk -F',' 'NR>1 {cpu[$2]+=$3; count[$2]++} END {for(c in cpu) printf "%s: %.2f%%\n", c, cpu[c]/count[c]}' $LOG_FILE | sort -t: -k2 -rn

echo ""

# 컨테이너별 최대 메모리 사용량
echo "=== 최대 메모리 사용량 ==="
awk -F',' 'NR>1 {if($4 > max[$2]) max[$2]=$4} END {for(c in max) print c": "max[c]}' $LOG_FILE | sort -t: -k2 -rn

echo ""

# CPU 사용률 90% 이상 경고
echo "=== CPU 경고 (90% 이상) ==="
awk -F',' 'NR>1 {gsub("%","",$3); if($3+0 > 90) print $1, $2, $3"%"}' $LOG_FILE
```

---

## cAdvisor 설치 및 사용

### cAdvisor란?

Google이 개발한 컨테이너 모니터링 도구로, 더 상세한 메트릭을 제공합니다.

```
docker stats vs cAdvisor:

docker stats:
- 기본 메트릭 (CPU, 메모리, 네트워크)
- CLI 기반
- 히스토리 없음

cAdvisor:
- 상세 메트릭 (파일시스템, 네트워크 인터페이스별 등)
- Web UI 제공
- 짧은 히스토리 제공 (최근 1분)
- Prometheus 연동 가능
```

### cAdvisor 설치

```yaml
# docker-compose.monitoring.yml

version: '3.8'

services:
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    command:
      - '--housekeeping_interval=10s'
      - '--docker_only=true'
      - '--disable_metrics=disk,network,tcp,udp,percpu,sched,process'
```

**Windows (Docker Desktop)**:
```yaml
services:
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    ports:
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/:/var/lib/docker:ro
```

### cAdvisor 실행

```bash
# 실행
docker-compose -f docker-compose.monitoring.yml up -d cadvisor

# 확인
curl http://localhost:8080/containers/
```

### cAdvisor Web UI

브라우저에서 접속: `http://localhost:8080`

**주요 기능**:
- **Docker Containers**: 모든 컨테이너 목록 및 상세 정보
- **Metrics**: CPU, 메모리, 네트워크, 파일시스템 그래프
- **Subcontainers**: 컨테이너 계층 구조

### cAdvisor API

```bash
# 전체 컨테이너 메트릭
curl http://localhost:8080/api/v2.0/stats?count=1

# 특정 컨테이너
curl http://localhost:8080/api/v2.0/docker/<container_id>

# Prometheus 형식 메트릭
curl http://localhost:8080/metrics
```

---

## Prometheus + Grafana 연동

### 아키텍처

```
┌──────────────────────────────────────────────────┐
│                  Grafana (시각화)                 │
│            http://localhost:3000                 │
└────────────────┬─────────────────────────────────┘
                 │ 쿼리
                 ↓
┌──────────────────────────────────────────────────┐
│              Prometheus (메트릭 저장)             │
│            http://localhost:9090                 │
└────────────────┬─────────────────────────────────┘
                 │ 스크랩 (수집)
      ┌──────────┴──────────┐
      ↓                     ↓
┌─────────────┐      ┌─────────────┐
│  cAdvisor   │      │   Node      │
│  (컨테이너)  │      │  Exporter   │
│             │      │  (호스트)    │
└─────────────┘      └─────────────┘
```

### Prometheus 설정

```yaml
# docker-compose.monitoring.yml

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'

volumes:
  prometheus-data:
```

```yaml
# prometheus/prometheus.yml

global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  # cAdvisor (컨테이너 메트릭)
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']

  # Node Exporter (호스트 메트릭)
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # Spring Boot Actuator (애플리케이션 메트릭)
  - job_name: 'user-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['user-service:8080']

  - job_name: 'account-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['account-service:8080']

  - job_name: 'trade-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['trade-service:8080']
```

### Grafana 설정

```yaml
# docker-compose.monitoring.yml

services:
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus

volumes:
  grafana-data:
```

### Grafana 데이터 소스 자동 설정

```yaml
# grafana/provisioning/datasources/prometheus.yml

apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: false
```

### 전체 모니터링 스택

```yaml
# docker-compose.monitoring.yml (완전판)

version: '3.8'

services:
  # cAdvisor (컨테이너 메트릭)
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    privileged: true
    networks:
      - monitoring

  # Node Exporter (호스트 메트릭)
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring

  # Prometheus (메트릭 수집 및 저장)
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    networks:
      - monitoring
    depends_on:
      - cadvisor
      - node-exporter

  # Grafana (시각화)
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - monitoring
    depends_on:
      - prometheus

  # Alertmanager (알림)
  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    restart: unless-stopped
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager-data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    networks:
      - monitoring

networks:
  monitoring:
    driver: bridge

volumes:
  prometheus-data:
  grafana-data:
  alertmanager-data:
```

---

## 성능 메트릭 분석

### 주요 PromQL 쿼리

#### CPU 메트릭

```promql
# 컨테이너별 CPU 사용률 (%)
rate(container_cpu_usage_seconds_total[5m]) * 100

# 5분 평균 CPU 사용률
avg(rate(container_cpu_usage_seconds_total[5m])) by (name) * 100

# CPU 사용률 상위 5개 컨테이너
topk(5, rate(container_cpu_usage_seconds_total[5m])) * 100
```

#### 메모리 메트릭

```promql
# 컨테이너별 메모리 사용량 (MB)
container_memory_usage_bytes / 1024 / 1024

# 메모리 사용률 (%)
(container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100

# 메모리 사용률 80% 이상
(container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 80
```

#### 네트워크 메트릭

```promql
# 네트워크 수신 속도 (bytes/sec)
rate(container_network_receive_bytes_total[5m])

# 네트워크 송신 속도 (bytes/sec)
rate(container_network_transmit_bytes_total[5m])

# 총 네트워크 I/O
rate(container_network_receive_bytes_total[5m]) + rate(container_network_transmit_bytes_total[5m])
```

#### 디스크 I/O 메트릭

```promql
# 디스크 읽기 속도 (bytes/sec)
rate(container_fs_reads_bytes_total[5m])

# 디스크 쓰기 속도 (bytes/sec)
rate(container_fs_writes_bytes_total[5m])
```

### Grafana 대시보드 JSON

```json
{
  "dashboard": {
    "title": "LK-Trade Docker 모니터링",
    "panels": [
      {
        "title": "CPU 사용률",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_cpu_usage_seconds_total{name=~\".*-service\"}[5m]) * 100",
            "legendFormat": "{{name}}"
          }
        ],
        "yaxes": [
          {
            "format": "percent",
            "max": 100
          }
        ]
      },
      {
        "title": "메모리 사용량",
        "type": "graph",
        "targets": [
          {
            "expr": "container_memory_usage_bytes{name=~\".*-service\"} / 1024 / 1024",
            "legendFormat": "{{name}}"
          }
        ],
        "yaxes": [
          {
            "format": "megabytes"
          }
        ]
      },
      {
        "title": "네트워크 I/O",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_network_receive_bytes_total{name=~\".*-service\"}[5m])",
            "legendFormat": "{{name}} RX"
          },
          {
            "expr": "rate(container_network_transmit_bytes_total{name=~\".*-service\"}[5m])",
            "legendFormat": "{{name}} TX"
          }
        ],
        "yaxes": [
          {
            "format": "Bps"
          }
        ]
      },
      {
        "title": "컨테이너 상태",
        "type": "stat",
        "targets": [
          {
            "expr": "count(container_last_seen{name=~\".*-service\"})"
          }
        ]
      }
    ]
  }
}
```

---

## 병목 지점 찾기

### 1. CPU 병목

**증상**:
- API 응답 시간 증가
- docker stats에서 CPU 90% 이상

**진단**:
```bash
# CPU 사용률 높은 컨테이너 찾기
docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}" | sort -k2 -rn | head -5

# 컨테이너 내부 프로세스 확인
docker exec container_id top -bn1

# JVM 스레드 덤프
docker exec container_id jstack 1 > thread-dump.txt
```

**해결**:
```yaml
# CPU 증가
services:
  user-service:
    cpus: 2.0  # 1.0 → 2.0

# 또는 스케일 아웃
docker-compose up -d --scale user-service=3
```

### 2. 메모리 병목

**증상**:
- OOM Killed (Exit Code 137)
- 스왑 사용 증가

**진단**:
```bash
# 메모리 사용률 확인
docker stats --no-stream --format "table {{.Name}}\t{{.MemUsage}}\t{{.MemPerc}}"

# JVM 힙 덤프
docker exec container_id jmap -dump:format=b,file=/tmp/heap.hprof 1
docker cp container_id:/tmp/heap.hprof ./heap.hprof
```

**해결**:
```yaml
# 메모리 증가
services:
  user-service:
    mem_limit: 2g  # 1g → 2g
    environment:
      - JAVA_OPTS=-XX:MaxRAMPercentage=75.0
```

### 3. 네트워크 병목

**증상**:
- 높은 네트워크 지연
- 패킷 손실

**진단**:
```bash
# 네트워크 I/O 확인
docker stats --no-stream --format "table {{.Name}}\t{{.NetIO}}"

# 네트워크 지연 테스트
docker exec container_a ping -c 10 container_b

# 대역폭 테스트
docker exec container_a iperf3 -c container_b
```

**해결**:
- 네트워크 드라이버 변경 (bridge → host)
- 네트워크 최적화 설정

### 4. 디스크 I/O 병목

**증상**:
- 느린 데이터베이스 쿼리
- 파일 읽기/쓰기 지연

**진단**:
```bash
# 디스크 I/O 확인
docker stats --no-stream --format "table {{.Name}}\t{{.BlockIO}}"

# 디스크 사용량
docker exec container_id df -h

# I/O 대기 시간
docker exec container_id iostat -x 1 10
```

**해결**:
```yaml
# SSD 사용, I/O 제한 해제
services:
  postgres:
    volumes:
      - postgres-data:/var/lib/postgresql/data  # SSD 볼륨 사용
```

---

## 알림 설정

### Prometheus Alert 규칙

```yaml
# prometheus/alerts.yml

groups:
  - name: container_alerts
    interval: 30s
    rules:
      # CPU 사용률 80% 이상
      - alert: HighCPUUsage
        expr: rate(container_cpu_usage_seconds_total[5m]) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "컨테이너 CPU 사용률 높음"
          description: "{{ $labels.name }} CPU 사용률이 {{ $value }}% 입니다."

      # 메모리 사용률 90% 이상
      - alert: HighMemoryUsage
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "컨테이너 메모리 사용률 높음"
          description: "{{ $labels.name }} 메모리 사용률이 {{ $value }}% 입니다."

      # 컨테이너 다운
      - alert: ContainerDown
        expr: up{job="cadvisor"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "컨테이너 다운"
          description: "{{ $labels.instance }} 컨테이너가 다운되었습니다."

      # 디스크 사용률 85% 이상
      - alert: HighDiskUsage
        expr: (container_fs_usage_bytes / container_fs_limit_bytes) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "디스크 사용률 높음"
          description: "{{ $labels.name }} 디스크 사용률이 {{ $value }}% 입니다."
```

### Alertmanager 설정

```yaml
# alertmanager/alertmanager.yml

global:
  resolve_timeout: 5m

route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'slack'

receivers:
  # Slack 알림
  - name: 'slack'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: true

  # 이메일 알림
  - name: 'email'
    email_configs:
      - to: 'admin@lktrade.com'
        from: 'alertmanager@lktrade.com'
        smarthost: 'smtp.gmail.com:587'
        auth_username: 'alertmanager@lktrade.com'
        auth_password: 'password'
        headers:
          Subject: '[LK-Trade] {{ .GroupLabels.alertname }}'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname']
```

---

## 실전 예제: LK-Trade 모니터링

### 모니터링 시작

```bash
#!/bin/bash
# scripts/start-monitoring.sh

echo "📊 LK-Trade 모니터링 스택 시작..."

# 1. 모니터링 스택 시작
docker-compose -f docker-compose.monitoring.yml up -d

# 2. 서비스 준비 대기
echo "⏳ 서비스 준비 중..."
sleep 15

# 3. 헬스체크
echo "🏥 헬스체크..."
curl -f http://localhost:8080/containers/ > /dev/null 2>&1 && echo "  ✅ cAdvisor" || echo "  ❌ cAdvisor"
curl -f http://localhost:9090/-/healthy > /dev/null 2>&1 && echo "  ✅ Prometheus" || echo "  ❌ Prometheus"
curl -f http://localhost:3000/api/health > /dev/null 2>&1 && echo "  ✅ Grafana" || echo "  ❌ Grafana"

echo ""
echo "✅ 모니터링 스택 시작 완료!"
echo ""
echo "📋 접속 정보:"
echo "  - cAdvisor:    http://localhost:8080"
echo "  - Prometheus:  http://localhost:9090"
echo "  - Grafana:     http://localhost:3000 (admin/admin)"
echo "  - Alertmanager: http://localhost:9093"
```

### Makefile 통합

```makefile
# Makefile

.PHONY: monitoring monitoring-stop monitoring-logs

# 모니터링 시작
monitoring:
	@echo "📊 모니터링 스택 시작..."
	@docker-compose -f docker-compose.monitoring.yml up -d
	@sleep 10
	@echo "✅ 모니터링 준비 완료"
	@echo ""
	@echo "접속 URL:"
	@echo "  Grafana: http://localhost:3000"
	@echo "  Prometheus: http://localhost:9090"

# 모니터링 중지
monitoring-stop:
	@docker-compose -f docker-compose.monitoring.yml down

# 모니터링 로그
monitoring-logs:
	@docker-compose -f docker-compose.monitoring.yml logs -f
```

---

## 주니어 개발자 시나리오

### 시나리오 1: 첫 Prometheus + Grafana 설정

**상황**:
```
팀장: "우리 서비스 모니터링 시스템 좀 구축해봐요. Prometheus + Grafana 써서."
주니어 A (당황): "네... 근데 어떻게 시작하죠?"
```

**단계별 해결**:
```bash
# Step 1: docker-compose.monitoring.yml 작성
$ cat > docker-compose.monitoring.yml <<EOF
version: '3.8'

services:
  # cAdvisor: 컨테이너 메트릭 수집
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    ports:
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      - monitoring

  # Prometheus: 메트릭 저장
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - monitoring
    depends_on:
      - cadvisor

  # Grafana: 시각화
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-data:/var/lib/grafana
    networks:
      - monitoring
    depends_on:
      - prometheus

networks:
  monitoring:

volumes:
  prometheus-data:
  grafana-data:
EOF

# Step 2: Prometheus 설정 파일
$ mkdir prometheus
$ cat > prometheus/prometheus.yml <<EOF
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']
EOF

# Step 3: 모니터링 스택 시작
$ docker-compose -f docker-compose.monitoring.yml up -d

Creating network "monitoring_monitoring" ... done
Creating volume "monitoring_prometheus-data" ... done
Creating volume "monitoring_grafana-data" ... done
Creating monitoring_cadvisor_1 ... done
Creating monitoring_prometheus_1 ... done
Creating monitoring_grafana_1 ... done

# Step 4: 서비스 준비 대기
$ sleep 15

# Step 5: 접속 확인
$ curl http://localhost:9090/-/healthy
Prometheus is Healthy.

$ curl http://localhost:3000/api/health
{"database":"ok","version":"9.3.0"}

✅ 성공!
```

**Step 6: Grafana에서 대시보드 설정**
```
1. http://localhost:3000 접속
2. 로그인: admin / admin
3. Configuration > Data Sources > Add data source
4. Prometheus 선택
5. URL: http://prometheus:9090
6. Save & Test

7. Create > Dashboard > Add new panel
8. 쿼리 입력:
   rate(container_cpu_usage_seconds_total[5m]) * 100

9. 저장!
```

**배운 점**:
- Prometheus가 메트릭 저장소, Grafana가 시각화 도구
- cAdvisor는 컨테이너 메트릭 수집기
- docker-compose로 한 번에 구축 가능
- 3000, 8080, 9090 포트만 기억하면 됨

---

### 시나리오 2: CPU 100% 알림에 첫 대응

**상황**:
```
🚨 Slack 알림:
"[CRITICAL] user-service CPU 사용률 95% 초과!"

주니어 B (새벽 3시): "뭐지? 어떻게 하지?"
```

**단계별 대응**:
```bash
# Step 1: 상황 파악 (Grafana 대시보드 확인)
$ open http://localhost:3000
# user-service CPU 그래프 확인: 98%!

# Step 2: 실시간 리소스 확인
$ docker stats user-service --no-stream
CONTAINER      CPU %   MEM USAGE / LIMIT
user-service   98.5%   680MiB / 1GiB

# CPU 거의 100%!

# Step 3: 로그 확인
$ docker logs user-service --tail 100
[ERROR] Slow query detected: 5000ms
[ERROR] Slow query detected: 4800ms
[ERROR] Slow query detected: 5200ms
...

# 반복적인 느린 쿼리 발견!

# Step 4: 컨테이너 내부 확인
$ docker exec user-service ps aux
USER  PID  %CPU  %MEM  COMMAND
root    1  98.0  11.2  java -jar app.jar

# Java 프로세스가 CPU 100% 사용 중

# Step 5: 스레드 덤프 (원인 파악)
$ docker exec user-service jstack 1 > thread-dump.txt
$ grep -A 10 "RUNNABLE" thread-dump.txt

# 발견: DB 쿼리를 반복적으로 실행하는 스레드

# Step 6: 임시 대응 (스케일 아웃)
$ docker-compose up -d --scale user-service=3
Creating user-service_2 ... done
Creating user-service_3 ... done

# CPU 분산됨: 98% → 각각 30%

✅ 임시 해결!

# Step 7: 근본 원인 해결 (다음날 오전)
# - 쿼리 최적화 (인덱스 추가)
# - 캐싱 추가 (Redis)
# - 재배포

✅ 근본 해결!
```

**배운 점**:
- 알림 받으면 먼저 Grafana 대시보드 확인
- `docker stats`로 실시간 리소스 확인
- 로그에서 단서 찾기
- 임시 대응: 스케일 아웃, 근본 해결: 코드 수정
- 새벽에는 임시 대응, 오전에 근본 해결

---

### 시나리오 3: 메모리 누수 발견 및 대응

**상황**:
```
팀장: "account-service 메모리가 계속 증가하는데... 메모리 릭 같은데?"
주니어 C: "어떻게 확인하죠?"
```

**단계별 진단**:
```bash
# Step 1: Grafana에서 메모리 추이 확인
# 그래프: 지난 24시간 동안 메모리가 500MB → 1.8GB로 증가
# 추세: 계속 증가 중 (리셋 없음)

# Step 2: 실시간 모니터링
$ docker stats account-service
CONTAINER         MEM USAGE / LIMIT
account-service   1.85GiB / 2GiB  (92.5%)

# 30분 후 다시 확인
$ docker stats account-service --no-stream
CONTAINER         MEM USAGE / LIMIT
account-service   1.92GiB / 2GiB  (96%)

# 계속 증가 중! 메모리 릭 확실!

# Step 3: 힙 덤프 생성 (Java)
$ docker exec account-service jmap -dump:format=b,file=/tmp/heap.hprof 1
Heap dump file created

# Step 4: 힙 덤프 복사
$ docker cp account-service:/tmp/heap.hprof ./heap.hprof

# Step 5: Eclipse MAT로 분석
$ java -jar mat.jar heap.hprof

# 분석 결과:
# - ArrayList 객체가 500MB 차지
# - UserSessionCache가 무한정 증가
# - 원인: 세션 정리 로직 누락!

# Step 6: 임시 대응 (재시작으로 메모리 해제)
$ docker-compose restart account-service

# 메모리 1.8GB → 500MB로 감소

# Step 7: 근본 해결 (코드 수정)
```java
// ❌ Before: 세션 무한정 쌓임
public class UserSessionCache {
    private Map<String, Session> sessions = new HashMap<>();

    public void addSession(String id, Session session) {
        sessions.put(id, session);  // 삭제 로직 없음!
    }
}

// ✅ After: TTL + 최대 크기 제한
public class UserSessionCache {
    private LoadingCache<String, Session> sessions = CacheBuilder.newBuilder()
        .maximumSize(10000)  // 최대 10,000개
        .expireAfterWrite(30, TimeUnit.MINUTES)  // 30분 후 자동 삭제
        .build();
}
```

```bash
# Step 8: 재배포 및 모니터링
$ docker-compose up -d --build account-service

# 24시간 후 확인: 메모리 안정적으로 500~600MB 유지

✅ 근본 해결!
```

**배운 점**:
- 메모리가 계속 증가하면 메모리 릭 의심
- 힙 덤프로 메모리 사용 객체 확인
- 임시: 재시작, 근본: 코드 수정
- 캐시는 반드시 크기 제한 + TTL 설정

---

### 시나리오 4: Grafana 대시보드 커스터마이징

**상황**:
```
시니어: "대시보드에 우리가 필요한 메트릭만 보이게 정리해봐요."
주니어 D: "어떤 걸 보여줘야 하죠?"
```

**단계별 설정**:
```bash
# Step 1: 필요한 메트릭 목록 작성
필수 메트릭:
1. CPU 사용률 (%)
2. 메모리 사용량 (MB)
3. 네트워크 I/O (bytes/s)
4. API 응답 시간 (ms)
5. 에러율 (%)

# Step 2: Grafana 대시보드 생성
# http://localhost:3000 > Create > Dashboard

# Panel 1: CPU 사용률
Query: rate(container_cpu_usage_seconds_total{name=~".*-service"}[5m]) * 100
Title: "컨테이너별 CPU 사용률 (%)"
Legend: {{name}}
Y-axis: 0-100%
Threshold:
  - 80% Warning (Yellow)
  - 90% Critical (Red)

# Panel 2: 메모리 사용량
Query: container_memory_usage_bytes{name=~".*-service"} / 1024 / 1024
Title: "컨테이너별 메모리 사용량 (MB)"
Legend: {{name}}
Y-axis: MB
Threshold:
  - 800MB Warning
  - 900MB Critical

# Panel 3: 네트워크 I/O
Query RX: rate(container_network_receive_bytes_total{name=~".*-service"}[5m])
Query TX: rate(container_network_transmit_bytes_total{name=~".*-service"}[5m])
Title: "네트워크 송수신"
Legend: {{name}} RX / TX
Y-axis: bytes/s

# Panel 4: 컨테이너 상태 (Stat 패널)
Query: count(container_last_seen{name=~".*-service"})
Title: "실행 중인 컨테이너 수"
Display: Big number
Color: Green

# Step 3: 변수 추가 (동적 필터링)
Settings > Variables > Add variable
Name: service
Type: Query
Query: label_values(container_cpu_usage_seconds_total, name)

# 이제 드롭다운으로 서비스 선택 가능!

# Step 4: 알림 규칙 추가
Panel > Alert > Create Alert

Rule:
WHEN avg() OF query(A, 5m, now) IS ABOVE 80
FOR 5m
Send to: Slack

Message: "{{name}} CPU 사용률 {{value}}% 초과!"

# Step 5: 대시보드 저장
Title: "LK-Trade Production Monitoring"
Folder: Production
Save

✅ 완성!
```

**프로 팁**:
```bash
# 대시보드 JSON 내보내기 (버전 관리)
$ curl -u admin:admin http://localhost:3000/api/dashboards/uid/abc123 > dashboard.json

# Git 저장
$ git add dashboard.json
$ git commit -m "Add production monitoring dashboard"

# 다른 환경에 적용
$ curl -X POST -H "Content-Type: application/json" \
    -d @dashboard.json \
    http://grafana-staging:3000/api/dashboards/db
```

**배운 점**:
- 대시보드는 팀의 니즈에 맞게 커스터마이징
- Threshold로 시각적 경고 표시
- 변수로 동적 필터링 가능
- JSON 내보내기로 버전 관리
- 알림 규칙은 패널별로 설정 가능

---

## FAQ

<details>
<summary><strong>Q1: Prometheus vs ELK Stack, 어떤 걸 선택해야 하나요?</strong></summary>

**A**: **용도에 따라 다릅니다!** 둘 다 쓰는 것도 좋은 선택입니다.

**상세 비교**:

| 항목 | Prometheus + Grafana | ELK Stack |
|------|----------------------|-----------|
| **주 용도** | 메트릭 모니터링 (숫자) | 로그 수집 및 분석 (텍스트) |
| **데이터 형식** | Time-series (시계열) | JSON 로그 |
| **쿼리 언어** | PromQL | Lucene query / KQL |
| **시각화** | Grafana | Kibana |
| **장점** | 가볍고 빠름, 메트릭 특화 | 강력한 로그 검색, 풀텍스트 분석 |
| **단점** | 로그 분석 약함 | 무거움, 리소스 많이 사용 |
| **설치 난이도** | 쉬움 ⭐⭐☆☆☆ | 어려움 ⭐⭐⭐⭐☆ |
| **리소스 사용** | 적음 (1GB 이하) | 많음 (4GB 이상) |

**사용 사례별 권장**:

**케이스 1: 작은 프로젝트 (5개 이하 서비스)**
```
✅ Prometheus + Grafana
- 이유: 가볍고 설치 쉬움
- 설정: docker-compose up 한 번이면 끝
```

**케이스 2: 대규모 프로젝트 (10개 이상 서비스)**
```
✅ Prometheus + Grafana (메트릭)
✅ ELK Stack (로그)
- 이유: 각자 장점이 명확
- Prometheus: CPU/메모리/네트워크 모니터링
- ELK: 에러 로그 분석, 검색
```

**케이스 3: AWS/GCP 사용 중**
```
✅ 클라우드 네이티브 도구
- AWS: CloudWatch
- GCP: Cloud Monitoring
- 이유: 통합 관리, 추가 인프라 불필요
```

**실전 권장 조합**:
```yaml
# docker-compose.monitoring.yml

# 메트릭 모니터링 (가벼움)
services:
  prometheus:
    image: prom/prometheus:latest
  grafana:
    image: grafana/grafana:latest

# 로그 수집 (필요시 추가)
  elasticsearch:
    image: elasticsearch:8.11.0
  kibana:
    image: kibana:8.11.0
  filebeat:
    image: elastic/filebeat:8.11.0
```

**결론**:
> "작게 시작: Prometheus + Grafana"
> "커지면 추가: ELK Stack"
> "돈 있으면: 클라우드 서비스"

</details>

<details>
<summary><strong>Q2: 알림 임계값을 어떻게 설정해야 하나요? (CPU 80%? 90%?)</strong></summary>

**A**: **서비스 특성에 따라 다르지만, 일반적으로 3단계로 설정합니다.**

**상세 설명**:

**알림 임계값 설정 원칙**:

```
┌─────────────────────────────────────────┐
│ 3단계 알림 시스템                       │
├─────────────────────────────────────────┤
│ 1. Warning (경고)                       │
│    - CPU: 70-80%                        │
│    - Memory: 70-80%                     │
│    - 조치: 모니터링 강화, 로그 확인     │
│    - 알림: Slack 메시지                 │
│                                         │
│ 2. Critical (긴급)                      │
│    - CPU: 90%+                          │
│    - Memory: 90%+                       │
│    - 조치: 즉시 대응, 스케일 아웃       │
│    - 알림: Slack + Email                │
│                                         │
│ 3. Emergency (비상)                     │
│    - CPU: 95%+                          │
│    - Memory: 95%+ (OOM 임박)            │
│    - 조치: 긴급 대응, 자동 스케일 아웃  │
│    - 알림: Slack + Email + SMS + 전화   │
└─────────────────────────────────────────┘
```

**Prometheus Alert 규칙 예시**:
```yaml
# prometheus/alerts.yml

groups:
  - name: container_alerts
    rules:
      # Warning: CPU 80% (5분 지속)
      - alert: HighCPUWarning
        expr: rate(container_cpu_usage_seconds_total[5m]) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "CPU 사용률 높음 (경고)"
          description: "{{ $labels.name }} CPU {{ $value }}%"

      # Critical: CPU 90% (3분 지속)
      - alert: HighCPUCritical
        expr: rate(container_cpu_usage_seconds_total[5m]) * 100 > 90
        for: 3m
        labels:
          severity: critical
        annotations:
          summary: "CPU 사용률 위험 (긴급)"
          description: "{{ $labels.name }} CPU {{ $value }}% - 즉시 대응 필요!"

      # Warning: Memory 80%
      - alert: HighMemoryWarning
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "메모리 사용률 높음 (경고)"
          description: "{{ $labels.name }} Memory {{ $value }}%"

      # Critical: Memory 90% (OOM 임박!)
      - alert: HighMemoryCritical
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 90
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "메모리 사용률 위험 (OOM 임박!)"
          description: "{{ $labels.name }} Memory {{ $value }}% - 즉시 대응!"
```

**서비스 유형별 임계값**:

| 서비스 유형 | CPU Warning | CPU Critical | Memory Warning | Memory Critical |
|-------------|-------------|--------------|----------------|-----------------|
| **API 서버** | 70% | 85% | 80% | 90% |
| **데이터베이스** | 60% | 80% | 70% | 85% |
| **캐시 (Redis)** | 80% | 95% | 80% | 95% |
| **배치 작업** | 90% | 95% | 85% | 90% |
| **프론트엔드** | 75% | 90% | 75% | 90% |

**for 기간 설정** (얼마나 지속되어야 알림?):
```yaml
# 짧은 스파이크 무시, 지속적인 문제만 알림

# ❌ for: 10s (너무 짧음)
# → 일시적 스파이크에도 알림 남발

# ✅ for: 5m (적절)
# → 5분 이상 지속되면 진짜 문제

# ⚠️ for: 30m (너무 김)
# → 이미 장애 발생 후
```

**실전 권장 설정**:
```yaml
# Alertmanager 라우팅
route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 5m
  repeat_interval: 4h  # 4시간마다 재알림

  routes:
    # Warning: Slack만
    - match:
        severity: warning
      receiver: 'slack'
      repeat_interval: 12h

    # Critical: Slack + Email
    - match:
        severity: critical
      receiver: 'slack-and-email'
      repeat_interval: 2h

    # Emergency: 모든 채널 + 전화
    - match:
        severity: emergency
      receiver: 'all-channels'
      repeat_interval: 30m
```

**결론**:
> "80%에서 Warning, 90%에서 Critical"
> "5분 이상 지속되면 알림"
> "서비스 특성 고려해서 조정"

</details>

<details>
<summary><strong>Q3: Prometheus 데이터 보존 기간을 어떻게 설정하나요?</strong></summary>

**A**: **retention.time 설정으로 보존 기간을 조절**합니다. 일반적으로 15일~30일이 적절합니다.

**상세 설명**:

**기본 설정**:
```yaml
# docker-compose.monitoring.yml

services:
  prometheus:
    image: prom/prometheus:latest
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'  # 30일 보관
      - '--storage.tsdb.retention.size=10GB'  # 최대 10GB
```

**보존 기간별 디스크 사용량** (메트릭 100개, 15초 간격 기준):

| 보존 기간 | 예상 디스크 사용량 | 추천 대상 |
|-----------|-------------------|----------|
| **7일** | ~2GB | 개발 환경 |
| **15일** | ~4GB | 소규모 프로덕션 |
| **30일** | ~8GB | 중규모 프로덕션 (추천) |
| **90일** | ~24GB | 대규모 프로덕션 |
| **1년** | ~96GB | 장기 추세 분석 필요 시 |

**환경별 권장 설정**:

**1. 개발 환경**:
```yaml
prometheus:
  command:
    - '--storage.tsdb.retention.time=7d'  # 7일이면 충분
    - '--storage.tsdb.retention.size=2GB'
```

**2. 스테이징 환경**:
```yaml
prometheus:
  command:
    - '--storage.tsdb.retention.time=15d'  # 15일
    - '--storage.tsdb.retention.size=5GB'
```

**3. 프로덕션 환경**:
```yaml
prometheus:
  command:
    - '--storage.tsdb.retention.time=30d'  # 30일 (추천)
    - '--storage.tsdb.retention.size=10GB'
```

**4. 장기 보관 필요 시** (Thanos 사용):
```yaml
# prometheus + thanos 조합
# Prometheus: 최근 30일 (빠른 쿼리)
# Thanos: 1년+ (S3 저장)

services:
  prometheus:
    command:
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.min-block-duration=2h'
      - '--storage.tsdb.max-block-duration=2h'

  thanos-sidecar:
    image: thanosio/thanos:latest
    command:
      - 'sidecar'
      - '--tsdb.path=/prometheus'
      - '--objstore.config-file=/etc/thanos/bucket.yml'

  # Thanos로 S3에 장기 저장
```

**디스크 사용량 모니터링**:
```bash
# 현재 Prometheus 데이터 크기 확인
$ docker exec prometheus du -sh /prometheus
8.2G    /prometheus

# 상세 확인
$ docker exec prometheus ls -lh /prometheus
```

**자동 정리 확인**:
```bash
# Prometheus 로그에서 정리 확인
$ docker logs prometheus | grep "Deleting"
level=info msg="Deleting obsolete block" mint=1234567890000 maxt=1234567899999
```

**비용 절감 팁**:
```yaml
# 1. scrape_interval 늘리기 (정밀도 ↓, 디스크 ↓)
global:
  scrape_interval: 30s  # 15s → 30s

# 2. 불필요한 메트릭 제외
scrape_configs:
  - job_name: 'cadvisor'
    metric_relabel_configs:
      # 불필요한 메트릭 드롭
      - source_labels: [__name__]
        regex: 'container_fs_.*'  # 파일시스템 메트릭 제외
        action: drop
```

**결론**:
> "개발: 7일, 프로덕션: 30일"
> "장기 보관 필요 시: Thanos 사용"
> "디스크 크기는 예상의 1.5배로 설정"

</details>

<details>
<summary><strong>Q4: 모니터링 시스템 자체 비용을 어떻게 최적화하나요?</strong></summary>

**A**: **가벼운 설정 + 불필요한 메트릭 제거 + 샘플링**으로 30-50% 비용 절감 가능합니다.

**상세 설명**:

**비용 구성 요소**:
```
모니터링 시스템 비용 =
  + Prometheus 인스턴스 (CPU, 메모리, 디스크)
  + Grafana 인스턴스 (CPU, 메모리)
  + cAdvisor (CPU, 메모리)
  + 네트워크 트래픽
  + 스토리지 (시계열 데이터)
```

**최적화 전략**:

**1. 메트릭 수집 간격 조정** (가장 효과적):
```yaml
# Before: 15초마다 수집
global:
  scrape_interval: 15s
# 디스크 사용량: 10GB/월

# After: 30초마다 수집
global:
  scrape_interval: 30s
# 디스크 사용량: 5GB/월 (50% 절감)

# 트레이드오프: 정밀도 약간 감소
# - Before: 1분에 4개 데이터 포인트
# - After: 1분에 2개 데이터 포인트
# → 대부분의 경우 충분함!
```

**2. 불필요한 메트릭 제거**:
```yaml
scrape_configs:
  - job_name: 'cadvisor'
    metric_relabel_configs:
      # 사용하지 않는 메트릭 드롭
      - source_labels: [__name__]
        regex: 'container_(file_descriptors|tasks_state|memory_failures_total).*'
        action: drop

      # 특정 컨테이너만 수집 (불필요한 시스템 컨테이너 제외)
      - source_labels: [name]
        regex: '^/system.*'
        action: drop

# 효과: 메트릭 수 70% 감소 → 저장 공간 70% 절감
```

**3. cAdvisor 설정 최적화**:
```yaml
services:
  cadvisor:
    command:
      - '--housekeeping_interval=30s'  # 10s → 30s
      - '--docker_only=true'  # Docker 컨테이너만
      - '--disable_metrics=disk,network,tcp,udp,percpu,sched,process'  # 불필요한 메트릭 비활성화

# 효과: CPU 사용량 50% 감소
```

**4. 경량 이미지 사용**:
```yaml
services:
  prometheus:
    image: prom/prometheus:latest  # ~200MB

  grafana:
    image: grafana/grafana:latest-ubuntu  # ~350MB
    # Alpine 버전은 일부 플러그인 호환 문제 있음

  # 대신 리소스 제한 설정
  prometheus:
    deploy:
      resources:
        limits:
          memory: 1G  # 충분
          cpus: '0.5'
```

**5. 보존 기간 단축**:
```yaml
prometheus:
  command:
    - '--storage.tsdb.retention.time=15d'  # 30d → 15d
    - '--storage.tsdb.retention.size=5GB'  # 10GB → 5GB

# 효과: 디스크 비용 50% 절감
```

**비용 비교** (소규모 프로덕션 기준):

| 항목 | Before (최적화 전) | After (최적화 후) | 절감율 |
|------|-------------------|------------------|--------|
| Prometheus 메모리 | 2GB | 1GB | 50% |
| Prometheus 디스크 | 20GB | 8GB | 60% |
| cAdvisor CPU | 0.5 core | 0.2 core | 60% |
| 월 클라우드 비용 | $80 | $35 | **56%** |

**최소 설정 예시** (작은 프로젝트):
```yaml
# docker-compose.monitoring.yml (minimal)

version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'  # 7일만
      - '--storage.tsdb.retention.size=2GB'  # 2GB 제한
    deploy:
      resources:
        limits:
          memory: 512M  # 512MB로 제한
          cpus: '0.3'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=  # 플러그인 설치 안 함
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.2'

volumes:
  prometheus-data:
```

**결론**:
> "수집 간격 30초로 설정: 50% 절감"
> "불필요한 메트릭 제거: 추가 30% 절감"
> "보존 기간 15일로 설정: 추가 20% 절감"
> "총 비용 절감: 약 60%"

</details>

<details>
<summary><strong>Q5: 클라우드 환경 (AWS/GCP)에서는 어떻게 모니터링하나요?</strong></summary>

**A**: **자체 구축 vs 클라우드 네이티브 도구를 상황에 맞게 선택**합니다.

**상세 설명**:

**선택지 비교**:

| 항목 | Prometheus + Grafana (자체 구축) | AWS CloudWatch | GCP Cloud Monitoring |
|------|----------------------------------|----------------|---------------------|
| **비용** | 인스턴스 비용만 | 메트릭당 과금 | 메트릭당 과금 |
| **설치** | 직접 설치 필요 | 즉시 사용 | 즉시 사용 |
| **커스터마이징** | 자유로움 | 제한적 | 제한적 |
| **통합** | 수동 설정 | AWS 서비스 자동 통합 | GCP 서비스 자동 통합 |
| **학습 곡선** | 높음 | 낮음 | 낮음 |

**시나리오별 권장**:

**시나리오 1: AWS ECS/Fargate에서 Docker 실행**
```yaml
# ✅ 권장: CloudWatch Container Insights

# ECS Task Definition
{
  "family": "user-service",
  "containerDefinitions": [{
    "name": "user-service",
    "image": "user-service:latest",
    "logConfiguration": {
      "logDriver": "awslogs",  # CloudWatch Logs로 자동 전송
      "options": {
        "awslogs-group": "/ecs/user-service",
        "awslogs-region": "ap-northeast-2",
        "awslogs-stream-prefix": "ecs"
      }
    }
  }]
}

# Container Insights 활성화
$ aws ecs update-cluster-settings \
    --cluster lk-trade \
    --settings name=containerInsights,value=enabled

# 비용: 메트릭 $0.30/GB (첫 10GB 무료)
```

**시나리오 2: AWS EC2에서 직접 Docker 실행**
```yaml
# ✅ 권장: Prometheus + Grafana (자체 구축)

# 이유:
# - CloudWatch는 커스텀 메트릭 비용 높음
# - EC2에서는 자체 구축이 더 저렴

# docker-compose.monitoring.yml
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - prometheus-data:/prometheus

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"

  cloudwatch-exporter:  # CloudWatch 메트릭도 가져오기
    image: prom/cloudwatch-exporter:latest
    volumes:
      - ./cloudwatch.yml:/config/config.yml:ro

# 비용: EC2 인스턴스 비용만 (월 $10~30)
```

**시나리오 3: GKE (Google Kubernetes Engine)**
```yaml
# ✅ 권장: Cloud Monitoring (Stackdriver)

# GKE에서는 기본으로 활성화됨
# 추가 설정 불필요!

# Grafana로 Cloud Monitoring 연동
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
data:
  datasource.yaml: |
    apiVersion: 1
    datasources:
      - name: Google Cloud Monitoring
        type: stackdriver
        access: proxy
        jsonData:
          authenticationType: gce

# 비용: 메트릭 150MB/월 무료, 초과분 $0.258/MB
```

**하이브리드 접근** (Best Practice):
```yaml
# 클라우드 + 자체 구축 조합

# 1. 클라우드 네이티브 도구: 인프라 메트릭
#    - AWS: CloudWatch로 EC2, RDS, ELB 모니터링
#    - GCP: Cloud Monitoring으로 GCE, CloudSQL 모니터링

# 2. Prometheus + Grafana: 애플리케이션 메트릭
#    - 커스텀 비즈니스 메트릭
#    - 상세한 컨테이너 메트릭

# docker-compose.monitoring.yml
services:
  prometheus:
    image: prom/prometheus:latest
    # 애플리케이션 메트릭 수집

  grafana:
    image: grafana/grafana:latest
    # 클라우드 메트릭 + Prometheus 메트릭 통합 대시보드

  cloudwatch-exporter:  # AWS
    image: prom/cloudwatch-exporter:latest

  stackdriver-exporter:  # GCP
    image: prom/stackdriver-exporter:latest
```

**비용 최적화 팁**:

**AWS CloudWatch**:
```bash
# 1. 메트릭 해상도 낮추기
#    - 기본: 1분 간격 (상세 모니터링)
#    - 최적화: 5분 간격 (기본 모니터링)
#    - 절감: 70% 비용 감소

# 2. 로그 보존 기간 단축
$ aws logs put-retention-policy \
    --log-group-name /ecs/user-service \
    --retention-in-days 7  # 무제한 → 7일

# 3. 로그 샘플링
#    - 모든 요청 로깅 → 10% 샘플링
#    - 에러는 100% 로깅
```

**결론**:
> "소규모 (<10 서비스): CloudWatch/Cloud Monitoring"
> "중규모 (10-50 서비스): Prometheus + 클라우드 통합"
> "대규모 (50+ 서비스): Prometheus + Thanos + 클라우드"

</details>

---

## 면접 질문

### 주니어 레벨

**Q1: docker stats 명령어로 확인할 수 있는 주요 메트릭 5가지는 무엇인가요?**

**A**: CPU 사용률, 메모리 사용량, 네트워크 I/O, 디스크 I/O, PID 수입니다.

**상세 답변**:
```bash
$ docker stats
CONTAINER ID   NAME   CPU %   MEM USAGE / LIMIT   MEM %   NET I/O       BLOCK I/O   PIDS
```

**1. CPU % (CPU 사용률)**
- 의미: 컨테이너가 사용 중인 CPU 비율
- 예시: 45% = CPU의 45% 사용 중
- 주의: 멀티코어 환경에서는 100% 이상 가능 (2코어면 200%까지)

**2. MEM USAGE / LIMIT (메모리 사용량)**
- 의미: 현재 사용 메모리 / 제한 메모리
- 예시: 680MiB / 1GiB
- 주의: 제한 없으면 호스트 전체 메모리 표시

**3. MEM % (메모리 사용률)**
- 의미: 제한 대비 사용 비율
- 예시: 66.4%
- 경고: 90% 이상이면 OOM Killer 위험

**4. NET I/O (네트워크 I/O)**
- 의미: 네트워크 송수신 총량 (누적)
- 예시: 1.2kB / 648B (수신 / 송신)
- 단위: 전체 누적량 (초당 아님!)

**5. BLOCK I/O (디스크 I/O)**
- 의미: 디스크 읽기/쓰기 총량 (누적)
- 예시: 10MB / 5MB (읽기 / 쓰기)

**실전 사용**:
```bash
# CPU 사용률 높은 컨테이너 찾기
$ docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}" | sort -k2 -rn

# 메모리 사용량 많은 컨테이너
$ docker stats --no-stream --format "table {{.Name}}\t{{.MemUsage}}" | sort -k2 -rn

# 특정 컨테이너만 모니터링
$ docker stats user-service account-service
```

---

**Q2: Prometheus, Grafana, cAdvisor의 역할을 각각 설명하세요.**

**A**:
- **Prometheus**: 메트릭 수집 및 저장 (DB)
- **Grafana**: 시각화 대시보드 (UI)
- **cAdvisor**: 컨테이너 메트릭 수집기 (Agent)

**상세 답변**:

```
┌────────────────────────────────────────────┐
│          모니터링 스택 아키텍처             │
├────────────────────────────────────────────┤
│                                            │
│  📊 Grafana (Port 3000)                    │
│  ┌──────────────────────────────────────┐  │
│  │ 역할: 시각화, 대시보드                │  │
│  │ 기능:                                 │  │
│  │ - 그래프, 차트 생성                   │  │
│  │ - 알림 설정 및 전송                   │  │
│  │ - 다양한 데이터 소스 통합             │  │
│  └────────────┬─────────────────────────┘  │
│               │ 쿼리 (PromQL)              │
│               ↓                            │
│  🗄️ Prometheus (Port 9090)                │
│  ┌──────────────────────────────────────┐  │
│  │ 역할: 메트릭 저장소 (TSDB)            │  │
│  │ 기능:                                 │  │
│  │ - 시계열 데이터 저장                  │  │
│  │ - PromQL 쿼리 처리                    │  │
│  │ - 알림 규칙 평가                      │  │
│  │ - 데이터 스크랩 (Pull 방식)           │  │
│  └────────────┬─────────────────────────┘  │
│               │ HTTP /metrics 엔드포인트   │
│               ↓                            │
│  📡 cAdvisor (Port 8080)                   │
│  ┌──────────────────────────────────────┐  │
│  │ 역할: 컨테이너 메트릭 수집기          │  │
│  │ 기능:                                 │  │
│  │ - Docker 컨테이너 메트릭 수집         │  │
│  │ - CPU, 메모리, 네트워크, 디스크 모니터│  │
│  │ - Prometheus 형식으로 노출            │  │
│  └────────────┬─────────────────────────┘  │
│               │ Docker API                 │
│               ↓                            │
│  🐳 Docker Containers                      │
│  ┌──────────────────────────────────────┐  │
│  │ user-service                          │  │
│  │ account-service                       │  │
│  │ trade-service                         │  │
│  └──────────────────────────────────────┘  │
└────────────────────────────────────────────┘
```

**각각의 역할 상세**:

**1. cAdvisor (Container Advisor)**:
```
"감시 카메라" 역할

- 컨테이너를 실시간으로 감시
- CPU, 메모리, 네트워크, 디스크 I/O 수집
- Docker API 사용하여 정보 수집
- http://localhost:8080/metrics 로 노출

예시 메트릭:
container_cpu_usage_seconds_total
container_memory_usage_bytes
container_network_receive_bytes_total
```

**2. Prometheus**:
```
"데이터베이스" 역할

- cAdvisor에서 주기적으로 데이터 가져오기 (Pull)
- 시계열 데이터베이스에 저장
- PromQL 쿼리 언어로 데이터 조회
- 알림 규칙 평가

예시 쿼리:
rate(container_cpu_usage_seconds_total[5m]) * 100
```

**3. Grafana**:
```
"대시보드" 역할

- Prometheus에서 데이터 조회
- 그래프, 차트로 시각화
- 알림 전송 (Slack, Email 등)
- 사용자 친화적인 UI 제공

예시 기능:
- CPU 사용률 그래프
- 메모리 사용량 차트
- 임계값 초과 시 Slack 알림
```

**비유로 이해하기**:
```
cAdvisor = CCTV 카메라
  → 현장을 촬영

Prometheus = DVR (녹화기)
  → 영상을 저장하고 관리

Grafana = 모니터링 센터
  → 영상을 보고 분석
```

---

### 중급 레벨

**Q3: Prometheus의 Pull 방식과 Push 방식의 차이점은 무엇이고, 각각 언제 사용하나요?**

**A**: Prometheus는 기본적으로 **Pull 방식**을 사용하며, 단기 배치 작업에는 **Pushgateway를 통한 Push 방식**을 사용합니다.

**상세 답변**:

**Pull 방식 (Prometheus 기본)**:
```
┌─────────────────────────────────────────┐
│ Prometheus가 주기적으로 데이터 요청     │
├─────────────────────────────────────────┤
│                                         │
│  Prometheus                             │
│  ┌─────────────┐                        │
│  │             │                        │
│  │  매 15초마다                          │
│  │  HTTP GET   │                        │
│  │  /metrics   │                        │
│  │             │                        │
│  └──────┬──────┘                        │
│         │ GET http://cadvisor:8080/metrics
│         ↓                                │
│  ┌──────────────┐                       │
│  │  cAdvisor    │                       │
│  │  (Exporter)  │                       │
│  └──────────────┘                       │
└─────────────────────────────────────────┘

장점:
✅ 서비스 디스커버리 쉬움
✅ 타겟 헬스 확인 가능
✅ 설정이 간단
✅ 네트워크 실패 시 자동 재시도

단점:
❌ 방화벽 뚫어야 함
❌ 단기 실행 작업 모니터링 어려움
```

**Push 방식 (Pushgateway 사용)**:
```
┌─────────────────────────────────────────┐
│ 작업이 완료되면 Pushgateway로 전송      │
├─────────────────────────────────────────┤
│                                         │
│  배치 작업                               │
│  ┌─────────────┐                        │
│  │ Backup Job  │                        │
│  │ (30분 실행) │                        │
│  │             │                        │
│  │ 완료 시:     │                        │
│  │ POST 메트릭 │                        │
│  └──────┬──────┘                        │
│         │ POST metrics                  │
│         ↓                                │
│  ┌──────────────────┐                   │
│  │   Pushgateway    │                   │
│  │ (임시 저장소)     │                   │
│  └────────┬─────────┘                   │
│           │ ← GET (Prometheus가 Pull)   │
│           ↓                              │
│  ┌──────────────┐                       │
│  │  Prometheus  │                       │
│  └──────────────┘                       │
└─────────────────────────────────────────┘

장점:
✅ 단기 실행 작업 모니터링 가능
✅ 네트워크 제한 없음

단점:
❌ SPOF (Pushgateway 장애 시 데이터 손실)
❌ 설정 복잡
❌ 타임스탬프 문제 가능
```

**사용 사례**:

**Pull 방식 사용**:
```yaml
# 1. 장기 실행 서비스 (API 서버, DB 등)
scrape_configs:
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8080']

# 언제: 항상 실행 중인 서비스
```

**Push 방식 사용**:
```yaml
# 2. 배치 작업, 크론 작업
# pushgateway 설치
services:
  pushgateway:
    image: prom/pushgateway:latest
    ports:
      - "9091:9091"

# 배치 스크립트
#!/bin/bash
# backup.sh

echo "backup_duration_seconds $(date +%s)" | \
    curl --data-binary @- http://pushgateway:9091/metrics/job/backup

# 언제: 단기 실행 작업 (크론, 배치)
```

**혼합 사용 예시** (실전):
```yaml
# prometheus.yml

scrape_configs:
  # Pull: 항상 실행 중인 서비스
  - job_name: 'services'
    static_configs:
      - targets:
        - 'user-service:8080'
        - 'account-service:8080'
        - 'trade-service:8080'

  # Pull: Pushgateway (배치 작업 메트릭)
  - job_name: 'pushgateway'
    honor_labels: true  # 중요!
    static_configs:
      - targets: ['pushgateway:9091']
```

**결론**:
> "기본은 Pull 방식"
> "배치 작업만 Push 방식 (Pushgateway)"
> "99%는 Pull로 해결 가능"

---

**Q4: PromQL 쿼리를 작성하세요: "지난 5분간 CPU 사용률이 80% 이상인 컨테이너를 찾아라"**

**A**:
```promql
rate(container_cpu_usage_seconds_total[5m]) * 100 > 80
```

**상세 설명**:

**쿼리 분해**:
```promql
1. container_cpu_usage_seconds_total
   → CPU 사용 시간 (누적, 단위: 초)

2. [5m]
   → 지난 5분간의 데이터

3. rate(...[5m])
   → 초당 증가율 계산
   → 0.45 = 초당 0.45초 사용 (45% CPU)

4. * 100
   → 퍼센트로 변환
   → 0.45 * 100 = 45%

5. > 80
   → 80% 초과인 것만 필터링
```

**단계별 실행**:
```bash
# Prometheus UI (http://localhost:9090)에서 실행

# Step 1: 기본 메트릭 확인
container_cpu_usage_seconds_total

# 결과:
# container_cpu_usage_seconds_total{name="user-service"} 12345.67
# → 컨테이너 시작 후 총 12345.67초 동안 CPU 사용

# Step 2: rate() 적용 (초당 변화율)
rate(container_cpu_usage_seconds_total[5m])

# 결과:
# {name="user-service"} 0.85
# → 초당 0.85초 사용 = 85% CPU

# Step 3: 퍼센트로 변환
rate(container_cpu_usage_seconds_total[5m]) * 100

# 결과:
# {name="user-service"} 85
# → 85%

# Step 4: 80% 이상만 필터링
rate(container_cpu_usage_seconds_total[5m]) * 100 > 80

# 결과:
# {name="user-service"} 85
# {name="trade-service"} 92
# → CPU 80% 이상인 컨테이너만 표시
```

**다른 유용한 PromQL 쿼리**:

**1. 메모리 사용률 80% 이상**:
```promql
(container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 80
```

**2. CPU 사용률 상위 5개 컨테이너**:
```promql
topk(5, rate(container_cpu_usage_seconds_total[5m]) * 100)
```

**3. 평균 CPU 사용률 (컨테이너별)**:
```promql
avg(rate(container_cpu_usage_seconds_total[5m]) * 100) by (name)
```

**4. 네트워크 수신 속도 (bytes/sec)**:
```promql
rate(container_network_receive_bytes_total[5m])
```

**5. 디스크 쓰기 속도 (bytes/sec)**:
```promql
rate(container_fs_writes_bytes_total[5m])
```

**Grafana 패널에 적용**:
```
Query: rate(container_cpu_usage_seconds_total{name=~".*-service"}[5m]) * 100
Legend: {{name}}
Y-axis: 0-100 (%)
Threshold:
  - 80% → Yellow
  - 90% → Red
```

---

**Q5: Grafana 대시보드 설계 시 고려해야 할 핵심 원칙 5가지는 무엇인가요?**

**A**: **가독성, 계층화, 컨텍스트, 알림, 일관성**입니다.

**상세 설명**:

**1. 가독성 (Readability)**
```
원칙: "한눈에 파악 가능하게"

❌ 나쁜 예:
┌────────────────────────────────────┐
│ 패널 20개가 빽빽하게 배치           │
│ 텍스트 작음, 색상 난잡              │
│ → 뭘 봐야 할지 모르겠음             │
└────────────────────────────────────┘

✅ 좋은 예:
┌────────────────────────────────────┐
│ [전체 시스템 상태]  ← 상단에 요약   │
│  ✅ All Systems Operational        │
│                                    │
│ [CPU 사용률] [메모리 사용률]        │
│  큰 그래프, 명확한 레이블           │
│                                    │
│ [상세 메트릭] ← 하단에 상세 정보    │
└────────────────────────────────────┘

팁:
- 패널당 1가지 메트릭만
- 큰 폰트 사용 (최소 14pt)
- 색상은 3가지 이내 (정상: 초록, 경고: 노랑, 위험: 빨강)
```

**2. 계층화 (Hierarchy)**
```
원칙: "위에서 아래로, 전체에서 상세로"

대시보드 레이아웃:
┌────────────────────────────────────┐
│ [1단계] 전체 시스템 상태            │
│  - 모든 서비스 정상? (한 줄)        │
│  - 알림 개수                        │
├────────────────────────────────────┤
│ [2단계] 서비스별 주요 메트릭        │
│  - CPU, 메모리 (각 서비스)          │
│  - 그래프로 시각화                  │
├────────────────────────────────────┤
│ [3단계] 상세 메트릭                 │
│  - 네트워크 I/O                     │
│  - 디스크 I/O                       │
│  - 에러율, 레이턴시                 │
└────────────────────────────────────┘

사용자 경험:
1. 대시보드 열면 → 전체 상태 즉시 파악
2. 문제 있으면 → 2단계에서 어떤 서비스인지 확인
3. 원인 파악 → 3단계에서 상세 분석
```

**3. 컨텍스트 (Context)**
```
원칙: "숫자만으로는 부족, 의미를 제공하라"

❌ 나쁜 예:
CPU: 85%
→ 85%가 많은 건가? 적은 건가?

✅ 좋은 예:
CPU: 85% / 100% (Warning Threshold: 80%)
⚠️ 경고 수준!
추세: 지난 1시간 동안 20% 증가 ↑

컨텍스트 제공 방법:
1. Threshold 표시 (80% 선 긋기)
2. 추세 화살표 (↑ 증가, ↓ 감소)
3. 비교값 (전일 대비, 전주 대비)
4. 단위 명시 (%, MB, req/s)
```

**4. 알림 (Alerting)**
```
원칙: "보는 것만으로는 부족, 알림도 함께"

Grafana Alert 설정:
1. 임계값 초과 시 시각적 경고 (Red 배경)
2. Slack/Email 알림 전송
3. 알림 이력 표시

예시:
┌────────────────────────────────────┐
│ CPU 사용률                          │
│ ┌────────────────────────────────┐ │
│ │                          🔴 92%│ │ ← 빨간색 배경
│ │        ╱‾‾‾‾‾╲                 │ │
│ │   ╱‾‾‾‾      ╲                 │ │
│ │ ‾‾           ‾‾‾‾‾‾            │ │
│ │ ──────────── 80% ─────────────│ │ ← Threshold 선
│ └────────────────────────────────┘ │
│                                    │
│ 🚨 Alert: High CPU Usage           │
│ Sent to: #ops-alerts (Slack)       │
└────────────────────────────────────┘
```

**5. 일관성 (Consistency)**
```
원칙: "모든 대시보드가 같은 디자인 언어"

통일해야 할 것:
1. 색상 스킴
   - 정상: #73BF69 (초록)
   - 경고: #F2CC0C (노랑)
   - 위험: #E02F44 (빨강)

2. 패널 크기
   - 상단 요약: 전체 너비
   - 주요 메트릭: 1/2 너비
   - 상세 메트릭: 1/3 너비

3. 시간 범위
   - 기본: 최근 1시간
   - 옵션: 1h, 6h, 24h, 7d

4. Y축 범위
   - CPU/Memory: 0-100%
   - 네트워크: Auto

5. 레전드 위치
   - 그래프: 하단
   - Stat: 없음
```

**실전 예시 (LK-Trade 대시보드)**:
```json
{
  "dashboard": {
    "title": "LK-Trade Production Monitoring",
    "panels": [
      {
        "title": "🟢 System Status",
        "type": "stat",
        "gridPos": {"x": 0, "y": 0, "w": 24, "h": 3},
        "targets": [
          {
            "expr": "up{job=\"services\"} == 1",
            "legendFormat": "{{name}}"
          }
        ]
      },
      {
        "title": "CPU Usage (%)",
        "type": "graph",
        "gridPos": {"x": 0, "y": 3, "w": 12, "h": 8},
        "yaxes": [{"max": 100, "min": 0}],
        "thresholds": [
          {"value": 80, "color": "yellow"},
          {"value": 90, "color": "red"}
        ]
      },
      {
        "title": "Memory Usage (MB)",
        "type": "graph",
        "gridPos": {"x": 12, "y": 3, "w": 12, "h": 8}
      }
    ]
  }
}
```

**결론**:
> "가독성: 한눈에 파악"
> "계층화: 전체 → 상세"
> "컨텍스트: 의미 제공"
> "알림: 능동적 대응"
> "일관성: 통일된 경험"

---

## 트러블슈팅

### 문제 1: cAdvisor가 메트릭을 수집하지 않음

**증상**:
```
cAdvisor Web UI에서 컨테이너 목록이 비어있음
```

**해결**:
```yaml
# docker-compose.monitoring.yml
services:
  cadvisor:
    privileged: true  # 권한 추가
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Docker 소켓 마운트
```

### 문제 2: Prometheus가 타겟을 스크랩하지 못함

**진단**:
```bash
# Prometheus 타겟 상태 확인
curl http://localhost:9090/api/v1/targets | jq
```

**해결**:
```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']  # 컨테이너 이름 사용
```

### 문제 3: Grafana 대시보드에 데이터가 없음

**진단**:
1. Prometheus에서 데이터 확인: `http://localhost:9090/graph`
2. 쿼리 테스트: `up`

**해결**:
- 데이터 소스 연결 확인
- PromQL 쿼리 수정

---

## 다음 단계

### 26. 로그 관리
- 로그 드라이버 종류
- 중앙화된 로그 수집
- ELK 스택

### 학습 자료

**모니터링**:
- [Prometheus 공식 문서](https://prometheus.io/docs/introduction/overview/)
- [Grafana 공식 문서](https://grafana.com/docs/)
- [cAdvisor GitHub](https://github.com/google/cadvisor)

---

**축하합니다! 🎉** Docker 성능 모니터링을 마스터했습니다!