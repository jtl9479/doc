# ì„¹ì…˜ 26: ë¡œê·¸ ê´€ë¦¬

## ë¹„ìœ ë¡œ ì‹œì‘í•˜ê¸°

ë¡œê·¸ ê´€ë¦¬ëŠ” **ë¸”ë™ë°•ìŠ¤ ë…¹í™”**ì™€ ê°™ìŠµë‹ˆë‹¤.

```
ìë™ì°¨ ë¸”ë™ë°•ìŠ¤                      Docker ë¡œê·¸ ê´€ë¦¬
================                      ==================
ğŸ“¹ ì „ë°© ì¹´ë©”ë¼                   â†’    stdout/stderr ë¡œê·¸
ğŸ“¹ í›„ë°© ì¹´ë©”ë¼                   â†’    ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸
ğŸ’¾ SD ì¹´ë“œ ì €ì¥                  â†’    ë¡œê·¸ ë“œë¼ì´ë²„
ğŸ”„ ìš©ëŸ‰ ê½‰ ì°¨ë©´ ë®ì–´ì“°ê¸°         â†’    ë¡œê·¸ ë¡œí…Œì´ì…˜
ğŸ“‚ ì‚¬ê³  ì‹œ ì˜ìƒ ë¶„ì„             â†’    ELKë¡œ ë¡œê·¸ ë¶„ì„
ğŸš¨ ì¶©ê²© ê°ì§€ ì‹œ ìë™ ì €ì¥        â†’    ì—ëŸ¬ ë¡œê·¸ ìë™ ìˆ˜ì§‘
```

ë¸”ë™ë°•ìŠ¤ê°€ ì—†ìœ¼ë©´ ì‚¬ê³  ì›ì¸ì„ ì•Œ ìˆ˜ ì—†ë“¯ì´, ë¡œê·¸ ê´€ë¦¬ê°€ ì—†ìœ¼ë©´ ì‹œìŠ¤í…œ ì¥ì•  ì›ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

---

## ì™œ ë¡œê·¸ ê´€ë¦¬ê°€ ì¤‘ìš”í•œê°€?

### 1. ë¡œê·¸ ê´€ë¦¬ì˜ í•„ìš”ì„±

```
ë¬¸ì œ ë°œìƒ ì‹œë‚˜ë¦¬ì˜¤
==================

âŒ ë¡œê·¸ ê´€ë¦¬ ì—†ì„ ë•Œ:
------------------
ì‚¬ìš©ì: "ì£¼ë¬¸ì´ ì•ˆ ë¼ìš”!"
ê°œë°œì: "ì–¸ì œìš”? ì–´ë–¤ ì—ëŸ¬ì˜€ë‚˜ìš”?"
ì‚¬ìš©ì: "ì•„ê¹Œìš”... ì˜ ëª¨ë¥´ê² ì–´ìš”..."
ê°œë°œì: "ë¡œê·¸ê°€ ì—†ì–´ì„œ í™•ì¸ ë¶ˆê°€ëŠ¥..."
    â†“
ì›ì¸ íŒŒì•… ë¶ˆê°€ ğŸ˜±


âœ… ë¡œê·¸ ê´€ë¦¬ ìˆì„ ë•Œ:
------------------
ì‚¬ìš©ì: "ì£¼ë¬¸ì´ ì•ˆ ë¼ìš”!"
ê°œë°œì: "í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
    â†“
1. Kibanaì—ì„œ ì‚¬ìš©ì IDë¡œ ê²€ìƒ‰
2. 13:24:15ì— "Insufficient balance" ì—ëŸ¬ ë°œê²¬
3. ê³„ì¢Œ ì”ì•¡ ë¶€ì¡±ì´ ì›ì¸ì„ì„ ì¦‰ì‹œ íŒŒì•…
4. ì‚¬ìš©ìì—ê²Œ "ì”ì•¡ ë¶€ì¡±ì…ë‹ˆë‹¤" ì•ˆë‚´
    â†“
5ë¶„ ë§Œì— ë¬¸ì œ í•´ê²°! ğŸ˜Š
```

### 2. ë¡œê·¸ ê´€ë¦¬ê°€ í•´ê²°í•˜ëŠ” ë¬¸ì œ

| ë¬¸ì œ | ë¡œê·¸ ê´€ë¦¬ ì—†ì´ | ë¡œê·¸ ê´€ë¦¬ë¡œ |
|------|--------------|-----------|
| ğŸ› ë²„ê·¸ ì¶”ì  | "ì¬í˜„ ì•ˆ ë¼ìš”..." | ì •í™•í•œ ì—ëŸ¬ ìŠ¤íƒ í™•ì¸ |
| âš¡ ì„±ëŠ¥ ì´ìŠˆ | "ëŠë¦° ê²ƒ ê°™ì•„ìš”..." | ì •í™•í•œ ì‘ë‹µ ì‹œê°„ ì¸¡ì • |
| ğŸ”’ ë³´ì•ˆ ì‚¬ê³  | "ëˆ„ê°€ í•´í‚¹í–ˆë‚˜?" | ì ‘ê·¼ ê¸°ë¡ ì „ì²´ ì¶”ì  |
| ğŸ“Š ì‚¬ìš© í†µê³„ | "ì–¼ë§ˆë‚˜ ì“°ë‚˜ìš”?" | ì •í™•í•œ ì‚¬ìš©ëŸ‰ ë¶„ì„ |
| ğŸš¨ ì¥ì•  ëŒ€ì‘ | "ì–¸ì œ ì£½ì—ˆì–´ìš”?" | ì •í™•í•œ ì¥ì•  ì‹œê°„ íŒŒì•… |

---

## Docker ë¡œê·¸ì˜ ê¸°ë³¸ ì´í•´

### 1. Docker ë¡œê·¸ ìˆ˜ì§‘ ë©”ì»¤ë‹ˆì¦˜

```
Container ë‚´ë¶€                         Docker Daemon                    ë¡œê·¸ ì €ì¥ì†Œ
==============                         ==============                   ===========

Application
    |
    | stdout (System.out)
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
    |                                  Log Driver
    | stderr (System.err)              (json-file,
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>           syslog, etc.)
                                           |
                                           | í¬ë§· ë³€í™˜
                                           | ë²„í¼ë§
                                           â†“
                                       ë¡œê·¸ íŒŒì¼
                                       (/var/lib/docker/containers/
                                        <container-id>/<container-id>-json.log)
                                           |
                                           | (ì˜µì…˜) ì›ê²© ì „ì†¡
                                           â†“
                                       Elasticsearch
                                       Fluentd
                                       Splunk
                                       ë“±ë“±...
```

### 2. ë¡œê·¸ ë“œë¼ì´ë²„ ì¢…ë¥˜

DockerëŠ” ë‹¤ì–‘í•œ ë¡œê·¸ ë“œë¼ì´ë²„ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:

| ë“œë¼ì´ë²„ | ì„¤ëª… | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|---------|------|-------------|
| **json-file** | JSON í˜•ì‹ ë¡œì»¬ íŒŒì¼ (ê¸°ë³¸ê°’) | ê°œë°œ í™˜ê²½, ì†Œê·œëª¨ ìš´ì˜ |
| **journald** | systemd ì €ë„ì— ì „ì†¡ | Linux systemd í™˜ê²½ |
| **syslog** | Syslog ì„œë²„ë¡œ ì „ì†¡ | ê¸°ì¡´ syslog ì¸í”„ë¼ í™œìš© |
| **fluentd** | Fluentdë¡œ ì „ì†¡ | ëŒ€ê·œëª¨ ë¡œê·¸ ìˆ˜ì§‘ |
| **gelf** | Graylogë¡œ ì „ì†¡ | Graylog ì‚¬ìš© ì‹œ |
| **awslogs** | AWS CloudWatchë¡œ ì „ì†¡ | AWS í™˜ê²½ |
| **gcplogs** | Google Cloud Logging | GCP í™˜ê²½ |
| **splunk** | Splunkë¡œ ì „ì†¡ | Splunk ì‚¬ìš© ê¸°ì—… |
| **none** | ë¡œê·¸ ìˆ˜ì§‘ ì•ˆ í•¨ | ë¡œê·¸ ë¶ˆí•„ìš”í•œ ì»¨í…Œì´ë„ˆ |

---

## ë¡œê·¸ ë“œë¼ì´ë²„ ì„¤ì •

### 1. json-file ë“œë¼ì´ë²„ (ê¸°ë³¸ê°’)

ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë“œë¼ì´ë²„ì…ë‹ˆë‹¤.

#### docker-compose.yml ì„¤ì •

```yaml
# docker-compose.yml
version: '3.8'

services:
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "json-file"
      options:
        max-size: "10m"        # ë¡œê·¸ íŒŒì¼ ìµœëŒ€ í¬ê¸°
        max-file: "3"          # ë¡œê·¸ íŒŒì¼ ìµœëŒ€ ê°œìˆ˜
        labels: "service=user" # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        env: "ENVIRONMENT"     # í™˜ê²½ë³€ìˆ˜ í¬í•¨
```

#### ë™ì‘ ë°©ì‹

```
ë¡œê·¸ íŒŒì¼ ë¡œí…Œì´ì…˜
==================

user-service-json.log          (10MB ë„ë‹¬)
    â†“
user-service-json.log.1        (ì´ë¦„ ë³€ê²½)
user-service-json.log          (ìƒˆ íŒŒì¼ ìƒì„±)
    â†“
user-service-json.log.2        (ì´ë¦„ ë³€ê²½)
user-service-json.log.1        (ì´ë¦„ ë³€ê²½)
user-service-json.log          (ìƒˆ íŒŒì¼ ìƒì„±)
    â†“
user-service-json.log.2        (ì‚­ì œ, max-file=3 ì´ˆê³¼)
user-service-json.log.1        (ì´ë¦„ ë³€ê²½)
user-service-json.log          (ìƒˆ íŒŒì¼ ìƒì„±)
```

#### ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜

```bash
# ì»¨í…Œì´ë„ˆ ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜ í™•ì¸
docker inspect --format='{{.LogPath}}' user-service

# ì¶œë ¥ ì˜ˆì‹œ:
# /var/lib/docker/containers/abc123.../abc123...-json.log

# ë¡œê·¸ íŒŒì¼ ì§ì ‘ ë³´ê¸° (Linux/Mac)
sudo tail -f /var/lib/docker/containers/abc123.../abc123...-json.log

# ë¡œê·¸ íŒŒì¼ ë‚´ìš© ì˜ˆì‹œ
{"log":"2025-09-30 10:15:32.123 INFO  [main] Application started\n","stream":"stdout","time":"2025-09-30T01:15:32.123456789Z"}
{"log":"2025-09-30 10:15:33.456 ERROR [http-nio-8080-exec-1] Connection refused\n","stream":"stderr","time":"2025-09-30T01:15:33.456789012Z"}
```

### 2. syslog ë“œë¼ì´ë²„

ê¸°ì¡´ syslog ì¸í”„ë¼ê°€ ìˆì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

```yaml
# docker-compose.yml
services:
  trade-service:
    image: lk-trade/trade-service:latest
    logging:
      driver: "syslog"
      options:
        syslog-address: "tcp://syslog-server:514"
        syslog-facility: "daemon"
        tag: "{{.Name}}/{{.ID}}"
```

### 3. fluentd ë“œë¼ì´ë²„ (ê¶Œì¥ - ëŒ€ê·œëª¨ í™˜ê²½)

FluentdëŠ” ê°•ë ¥í•œ ë¡œê·¸ ìˆ˜ì§‘ê¸°ì…ë‹ˆë‹¤.

```yaml
# docker-compose.yml
services:
  # Fluentd ì»¨í…Œì´ë„ˆ
  fluentd:
    image: fluent/fluentd:v1.16-1
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    volumes:
      - ./fluentd/conf:/fluentd/etc
      - ./fluentd/logs:/fluentd/log
    networks:
      - lk-trade-network

  # ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆ
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "localhost:24224"
        tag: "lk-trade.user-service"
        fluentd-async: "true"      # ë¹„ë™ê¸° ì „ì†¡
        fluentd-buffer-limit: "1m" # ë²„í¼ í¬ê¸°
    depends_on:
      - fluentd
    networks:
      - lk-trade-network
```

#### Fluentd ì„¤ì • íŒŒì¼

```ruby
# fluentd/conf/fluent.conf

# ì…ë ¥: Docker ì»¨í…Œì´ë„ˆë¡œë¶€í„° ë¡œê·¸ ìˆ˜ì‹ 
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# í•„í„°: JSON íŒŒì‹±
<filter lk-trade.**>
  @type parser
  key_name log
  <parse>
    @type json
  </parse>
</filter>

# í•„í„°: ë¡œê·¸ ë ˆë²¨ ì¶”ì¶œ
<filter lk-trade.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    level ${record["level"] || "INFO"}
  </record>
</filter>

# ì¶œë ¥ 1: Elasticsearchë¡œ ì „ì†¡
<match lk-trade.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix lk-trade
  <buffer>
    @type file
    path /fluentd/log/buffer
    flush_interval 10s
  </buffer>
</match>

# ì¶œë ¥ 2: íŒŒì¼ë¡œë„ ë°±ì—… ì €ì¥
<match lk-trade.**>
  @type copy
  <store>
    @type file
    path /fluentd/log/${tag}/%Y%m%d
    <buffer tag,time>
      timekey 1d
      timekey_wait 10m
    </buffer>
  </store>
</match>
```

---

## ELK Stackìœ¼ë¡œ ë¡œê·¸ ìˆ˜ì§‘í•˜ê¸°

ELK = **E**lasticsearch + **L**ogstash + **K**ibana

```
ì „ì²´ ì•„í‚¤í…ì²˜
=============

Docker Containers                     Filebeat                  Logstash                Elasticsearch         Kibana
=================                     ========                  ========                =============         ======

[user-service]
   stdout/stderr  â”€â”€â”€â”€â”
                      â”‚
[trade-service]       â”œâ”€â”€â”€> Filebeat â”€â”€â”€> Logstash â”€â”€â”€> Elasticsearch â”€â”€â”€> Kibana
   stdout/stderr  â”€â”€â”€â”€â”¤      (ìˆ˜ì§‘)        (ê°€ê³µ)         (ì €ì¥)           (ì‹œê°í™”)
                      â”‚
[account-service]     â”‚
   stdout/stderr  â”€â”€â”€â”€â”˜

ê° ì—­í• :
- Filebeat: ë¡œê·¸ íŒŒì¼ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì½ì–´ì„œ Logstashë¡œ ì „ì†¡
- Logstash: ë¡œê·¸ë¥¼ íŒŒì‹±í•˜ê³  í•„í„°ë§í•˜ì—¬ êµ¬ì¡°í™”
- Elasticsearch: ë¡œê·¸ë¥¼ ìƒ‰ì¸í•˜ê³  ì €ì¥
- Kibana: ë¡œê·¸ë¥¼ ê²€ìƒ‰í•˜ê³  ì‹œê°í™”
```

### 1. ELK Stack docker-compose êµ¬ì„±

```yaml
# docker-compose.elk.yml
version: '3.8'

services:
  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"  # JVM í™ í¬ê¸°
      - xpack.security.enabled=false   # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ë³´ì•ˆ ë¹„í™œì„±í™”
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - elk-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"  # Filebeat ì…ë ¥
      - "9600:9600"  # Logstash API
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
    networks:
      - elk-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  # Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - elk-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  # Filebeat
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: filebeat
    user: root  # Docker ì†Œì¼“ ì ‘ê·¼ ê¶Œí•œ í•„ìš”
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data:/usr/share/filebeat/data
    command: filebeat -e -strict.perms=false
    networks:
      - elk-network
    depends_on:
      - logstash

volumes:
  elasticsearch-data:
    driver: local
  filebeat-data:
    driver: local

networks:
  elk-network:
    driver: bridge
```

### 2. Filebeat ì„¤ì •

FilebeatëŠ” Docker ì»¨í…Œì´ë„ˆì˜ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

```yaml
# filebeat/filebeat.yml
filebeat.inputs:
  # Docker ì»¨í…Œì´ë„ˆ ë¡œê·¸ ìë™ ìˆ˜ì§‘
  - type: container
    enabled: true
    paths:
      - '/var/lib/docker/containers/*/*.log'

    # JSON ë¡œê·¸ íŒŒì‹±
    json.keys_under_root: true
    json.add_error_key: true
    json.message_key: log

    # Docker ë©”íƒ€ë°ì´í„° ì¶”ê°€
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"

      - decode_json_fields:
          fields: ["message"]
          target: ""
          overwrite_keys: true

      # ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°
      - drop_fields:
          fields: ["agent", "ecs", "host", "input"]

# Logstashë¡œ ì¶œë ¥
output.logstash:
  hosts: ["logstash:5044"]

# ë¡œê·¸ ë ˆë²¨ ì„¤ì •
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

### 3. Logstash íŒŒì´í”„ë¼ì¸ ì„¤ì •

LogstashëŠ” ë¡œê·¸ë¥¼ íŒŒì‹±í•˜ê³  ê°€ê³µí•©ë‹ˆë‹¤.

```ruby
# logstash/pipeline/logstash.conf

input {
  beats {
    port => 5044
  }
}

filter {
  # Docker ì»¨í…Œì´ë„ˆ ë¡œê·¸ í•„í„°
  if [container] {
    # ì»¨í…Œì´ë„ˆ ì´ë¦„ì—ì„œ ì„œë¹„ìŠ¤ ì´ë¦„ ì¶”ì¶œ
    grok {
      match => {
        "[container][name]" => "^/?(%{DATA:service_name})[-_]"
      }
    }

    # Spring Boot ë¡œê·¸ íŒŒì‹±
    if [service_name] =~ /user|trade|account|strategy/ {
      grok {
        match => {
          "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} +\[%{DATA:thread}\] %{DATA:logger} : %{GREEDYDATA:log_message}"
        }
      }

      # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹±
      date {
        match => ["timestamp", "ISO8601"]
        target => "@timestamp"
      }
    }

    # ì—ëŸ¬ ë¡œê·¸ íƒœê·¸ ì¶”ê°€
    if [log_level] == "ERROR" or [log_level] == "FATAL" {
      mutate {
        add_tag => ["error"]
      }
    }

    # ì„±ëŠ¥ ê´€ë ¨ ë¡œê·¸ íƒœê·¸
    if [message] =~ /took \d+ms/ or [message] =~ /response time/ {
      grok {
        match => {
          "message" => "took %{NUMBER:response_time_ms:int}ms"
        }
      }
      mutate {
        add_tag => ["performance"]
      }
    }
  }

  # ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°
  mutate {
    remove_field => ["agent", "ecs", "input", "host"]
  }
}

output {
  # Elasticsearchë¡œ ì¶œë ¥
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "lk-trade-%{+YYYY.MM.dd}"

    # í…œí”Œë¦¿ ì„¤ì •
    template_name => "lk-trade"
    template_pattern => "lk-trade-*"
  }

  # ë””ë²„ê¹…ìš© stdout (ê°œë°œ í™˜ê²½ì—ì„œë§Œ)
  stdout {
    codec => rubydebug
  }
}
```

### 4. ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ êµ¬ì¡°í™”ëœ ë¡œê·¸ ì¶œë ¥

Spring Boot ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ JSON í˜•ì‹ìœ¼ë¡œ ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ë©´ íŒŒì‹±ì´ ì‰¬ì›Œì§‘ë‹ˆë‹¤.

#### Logback ì„¤ì • (JSON ë¡œê·¸)

```xml
<!-- src/main/resources/logback-spring.xml -->
<configuration>
    <springProperty scope="context" name="serviceName" source="spring.application.name"/>

    <!-- JSON Encoder ì˜ì¡´ì„± í•„ìš”: net.logstash.logback:logstash-logback-encoder -->
    <appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>{"service":"${serviceName}"}</customFields>
            <fieldNames>
                <timestamp>timestamp</timestamp>
                <message>message</message>
                <logger>logger</logger>
                <thread>thread</thread>
                <level>level</level>
                <stackTrace>stack_trace</stackTrace>
            </fieldNames>
        </encoder>
    </appender>

    <root level="INFO">
        <appender-ref ref="JSON"/>
    </root>
</configuration>
```

#### Gradle ì˜ì¡´ì„± ì¶”ê°€

```kotlin
// build.gradle.kts
dependencies {
    // JSON ë¡œê·¸ ì¶œë ¥
    implementation("net.logstash.logback:logstash-logback-encoder:7.4")
}
```

#### ë¡œê·¸ ì¶œë ¥ ì˜ˆì‹œ

```kotlin
// UserService.kt
import org.slf4j.LoggerFactory
import org.slf4j.MDC

class UserService {
    private val logger = LoggerFactory.getLogger(UserService::class.java)

    fun createUser(request: CreateUserRequest): User {
        // MDCë¡œ ì¶”ì  ID ì¶”ê°€ (ì „ì²´ ìš”ì²­ì—ì„œ ì¶”ì  ê°€ëŠ¥)
        MDC.put("userId", request.email)
        MDC.put("requestId", UUID.randomUUID().toString())

        try {
            logger.info("Creating user: {}", request.email)

            val user = userRepository.save(User(email = request.email))

            logger.info("User created successfully: {}", user.id)
            return user

        } catch (e: Exception) {
            logger.error("Failed to create user: {}", request.email, e)
            throw e
        } finally {
            MDC.clear()
        }
    }
}
```

#### JSON ë¡œê·¸ ì¶œë ¥ ì˜ˆì‹œ

```json
{
  "timestamp": "2025-09-30T10:15:32.123+09:00",
  "level": "INFO",
  "thread": "http-nio-8080-exec-1",
  "logger": "com.lk.trade.user.service.UserService",
  "message": "Creating user: test@example.com",
  "service": "user-service",
  "userId": "test@example.com",
  "requestId": "abc-123-def-456"
}
```

---

## Kibanaì—ì„œ ë¡œê·¸ ê²€ìƒ‰ê³¼ ì‹œê°í™”

### 1. Kibana ì ‘ì† ë° Index Pattern ì„¤ì •

```bash
# Kibana ì ‘ì†
http://localhost:5601

# ìµœì´ˆ ì ‘ì† ì‹œ Index Pattern ìƒì„±
1. Management > Stack Management > Index Patterns
2. "Create index pattern" í´ë¦­
3. Index pattern name: lk-trade-*
4. Time field: @timestamp
5. "Create index pattern" í´ë¦­
```

### 2. ê¸°ë³¸ ë¡œê·¸ ê²€ìƒ‰

```
Kibana Discover í™”ë©´
====================

ê²€ìƒ‰ ì¿¼ë¦¬ ì˜ˆì‹œ:

1. íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸ ê²€ìƒ‰
   service_name: "user-service"

2. ì—ëŸ¬ ë¡œê·¸ë§Œ ê²€ìƒ‰
   log_level: "ERROR"

3. íŠ¹ì • ì‚¬ìš©ì ê´€ë ¨ ë¡œê·¸
   userId: "test@example.com"

4. íŠ¹ì • ì‹œê°„ëŒ€ ë¡œê·¸
   @timestamp: [2025-09-30T00:00:00 TO 2025-09-30T23:59:59]

5. ë³µí•© ì¡°ê±´ (AND, OR)
   service_name: "trade-service" AND log_level: "ERROR"

6. ì‘ë‹µ ì‹œê°„ì´ ëŠë¦° ìš”ì²­
   response_time_ms: >1000

7. íŠ¹ì • ë©”ì‹œì§€ í¬í•¨
   message: *"Connection refused"*
```

### 3. ì‹œê°í™” ëŒ€ì‹œë³´ë“œ êµ¬ì„±

Kibanaì—ì„œ ìœ ìš©í•œ ì‹œê°í™”:

#### ë¡œê·¸ ë ˆë²¨ë³„ ë¶„í¬ (Pie Chart)

```
Visualization Type: Pie Chart
Metrics: Count
Buckets:
  - Split slices
  - Aggregation: Terms
  - Field: log_level.keyword
  - Size: 10
```

#### ì‹œê°„ëŒ€ë³„ ì—ëŸ¬ ë°œìƒ ì¶”ì´ (Line Chart)

```
Visualization Type: Line Chart
Metrics: Count
Buckets:
  - X-Axis
  - Aggregation: Date Histogram
  - Field: @timestamp
  - Interval: Auto

Filters: log_level: "ERROR"
```

#### ì„œë¹„ìŠ¤ë³„ ë¡œê·¸ ì–‘ (Bar Chart)

```
Visualization Type: Bar Chart (Vertical)
Metrics: Count
Buckets:
  - X-Axis
  - Aggregation: Terms
  - Field: service_name.keyword
  - Order By: metric: Count
  - Order: Descending
  - Size: 10
```

#### ì‘ë‹µ ì‹œê°„ ë¶„í¬ (Histogram)

```
Visualization Type: Histogram
Metrics: Average response_time_ms
Buckets:
  - X-Axis
  - Aggregation: Histogram
  - Field: response_time_ms
  - Interval: 100
```

### 4. ëŒ€ì‹œë³´ë“œ êµ¬ì„± ì˜ˆì‹œ

```
LK-Trade ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
====================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì‹œê°„ ë²”ìœ„: Last 24 hours                  ğŸ”„ Auto-refresh  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì´ ë¡œê·¸ ìˆ˜      â”‚  ì—ëŸ¬ ìˆ˜         â”‚  í‰ê·  ì‘ë‹µ ì‹œê°„      â”‚
â”‚  1,234,567       â”‚  42 (0.003%)     â”‚  123ms               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì‹œê°„ëŒ€ë³„ ë¡œê·¸ ë°œìƒëŸ‰       â”‚  ì„œë¹„ìŠ¤ë³„ ë¡œê·¸ ë¶„í¬         â”‚
â”‚  [Line Chart]               â”‚  [Pie Chart]                â”‚
â”‚                             â”‚  - user-service: 35%        â”‚
â”‚     â•±â•²                      â”‚  - trade-service: 28%       â”‚
â”‚    â•±  â•²      â•±â•²            â”‚  - account-service: 20%     â”‚
â”‚   â•±    â•²    â•±  â•²           â”‚  - strategy-service: 17%    â”‚
â”‚  â•±      â•²  â•±    â•²          â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì—ëŸ¬ ë¡œê·¸ ì¶”ì´             â”‚  ì‘ë‹µ ì‹œê°„ ë¶„í¬             â”‚
â”‚  [Area Chart]               â”‚  [Histogram]                â”‚
â”‚                             â”‚                             â”‚
â”‚      â•±â•²                     â”‚      â”ƒ                      â”‚
â”‚     â•±  â•²â•±â•²                  â”‚      â”ƒ                      â”‚
â”‚    â•±       â•²â•±â•²              â”‚  â”ƒ   â”ƒ                      â”‚
â”‚   â•±            â•²            â”‚  â”ƒ   â”ƒ  â”ƒ                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ìµœê·¼ ì—ëŸ¬ ë¡œê·¸ (ì‹¤ì‹œê°„)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [10:15:32] user-service | ERROR | Connection refused     â”‚
â”‚  [10:14:28] trade-service | ERROR | Insufficient balance â”‚
â”‚  [10:13:45] account-service | ERROR | API rate limit     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ë¡œê·¸ ê´€ë¦¬ ëª¨ë²” ì‚¬ë¡€

### 1. ë¡œê·¸ ë ˆë²¨ ì „ëµ

```kotlin
// âŒ ë‚˜ìœ ì˜ˆ
logger.info("User: $user, Password: ${user.password}, Request: $request")
// ë¬¸ì œ: ë¯¼ê° ì •ë³´ ë…¸ì¶œ, ë„ˆë¬´ ìƒì„¸

logger.debug("Step 1")
logger.debug("Step 2")
logger.debug("Step 3")
// ë¬¸ì œ: ì˜ë¯¸ ì—†ëŠ” ë¡œê·¸

logger.error("Error occurred")
// ë¬¸ì œ: êµ¬ì²´ì ì¸ ì •ë³´ ì—†ìŒ


// âœ… ì¢‹ì€ ì˜ˆ
// INFO: ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ìš” ì´ë²¤íŠ¸
logger.info("User registered successfully",
    kv("userId", user.id),
    kv("email", user.email.maskEmail())  // ì´ë©”ì¼ ë§ˆìŠ¤í‚¹
)

// DEBUG: ë””ë²„ê¹…ì— í•„ìš”í•œ ìƒì„¸ ì •ë³´
logger.debug("Processing order",
    kv("orderId", order.id),
    kv("items", order.items.size),
    kv("totalAmount", order.totalAmount)
)

// ERROR: ì˜ˆì™¸ ìƒí™©, ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ í¬í•¨
logger.error("Failed to process payment",
    kv("orderId", order.id),
    kv("errorCode", errorCode),
    e  // Exception ê°ì²´
)
```

### 2. ë¡œê·¸ ë ˆë²¨ ê°€ì´ë“œë¼ì¸

| ë ˆë²¨ | ìš©ë„ | ì˜ˆì‹œ |
|-----|------|-----|
| **TRACE** | ë§¤ìš° ìƒì„¸í•œ ë””ë²„ê·¸ ì •ë³´ | "Entering method", "Loop iteration 5" |
| **DEBUG** | ë””ë²„ê¹…ì— í•„ìš”í•œ ì •ë³´ | "Query: SELECT * FROM users WHERE...", "Cache hit" |
| **INFO** | ì¤‘ìš” ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë²¤íŠ¸ | "User login successful", "Order created" |
| **WARN** | ì ì¬ì  ë¬¸ì œ ìƒí™© | "API rate limit 80% reached", "Retrying connection" |
| **ERROR** | ì—ëŸ¬ ë°œìƒ, ë³µêµ¬ ê°€ëŠ¥ | "Payment failed", "External API timeout" |
| **FATAL** | ì¹˜ëª…ì  ì˜¤ë¥˜, ë³µêµ¬ ë¶ˆê°€ | "Database connection lost", "Out of memory" |

### 3. êµ¬ì¡°í™”ëœ ë¡œê¹… (Structured Logging)

```kotlin
// âŒ ë¹„êµ¬ì¡°í™”ëœ ë¡œê·¸ (íŒŒì‹± ì–´ë ¤ì›€)
logger.info("User test@example.com created order #12345 with amount $99.99")

// âœ… êµ¬ì¡°í™”ëœ ë¡œê·¸ (ê²€ìƒ‰ ì‰¬ì›€)
logger.info("Order created",
    kv("userId", user.id),
    kv("userEmail", user.email),
    kv("orderId", order.id),
    kv("amount", order.amount),
    kv("currency", "USD")
)

// JSON ì¶œë ¥ ì˜ˆì‹œ:
// {
//   "message": "Order created",
//   "userId": 123,
//   "userEmail": "test@example.com",
//   "orderId": 12345,
//   "amount": 99.99,
//   "currency": "USD"
// }
```

### 4. ìƒê´€ ê´€ê³„ ì¶”ì  (Correlation ID)

ìš”ì²­ ì „ì²´ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•œ ìƒê´€ ID ì‚¬ìš©:

```kotlin
// Spring Boot Interceptor
@Component
class CorrelationIdInterceptor : HandlerInterceptor {
    companion object {
        const val CORRELATION_ID_HEADER = "X-Correlation-ID"
        const val CORRELATION_ID_MDC_KEY = "correlationId"
    }

    override fun preHandle(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any
    ): Boolean {
        // í—¤ë”ì—ì„œ Correlation ID ê°€ì ¸ì˜¤ê¸° or ìƒˆë¡œ ìƒì„±
        val correlationId = request.getHeader(CORRELATION_ID_HEADER)
            ?: UUID.randomUUID().toString()

        // MDCì— ì €ì¥ (ëª¨ë“  ë¡œê·¸ì— ìë™ í¬í•¨ë¨)
        MDC.put(CORRELATION_ID_MDC_KEY, correlationId)

        // ì‘ë‹µ í—¤ë”ì—ë„ ì¶”ê°€
        response.setHeader(CORRELATION_ID_HEADER, correlationId)

        return true
    }

    override fun afterCompletion(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any,
        ex: Exception?
    ) {
        // ìš”ì²­ ì™„ë£Œ í›„ MDC ì •ë¦¬
        MDC.clear()
    }
}

// ì‚¬ìš© ì˜ˆì‹œ
class OrderService {
    private val logger = LoggerFactory.getLogger(OrderService::class.java)

    fun createOrder(request: CreateOrderRequest): Order {
        // correlationIdëŠ” ìë™ìœ¼ë¡œ ëª¨ë“  ë¡œê·¸ì— í¬í•¨ë¨
        logger.info("Creating order for user {}", request.userId)

        // ë‹¤ë¥¸ ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹œì—ë„ Correlation ID ì „ë‹¬
        val user = userClient.getUser(request.userId)

        logger.info("Order created successfully")
        return order
    }
}

// Feign Clientì—ì„œ Correlation ID ì „ë‹¬
@Component
class CorrelationIdFeignInterceptor : RequestInterceptor {
    override fun apply(template: RequestTemplate) {
        val correlationId = MDC.get(CorrelationIdInterceptor.CORRELATION_ID_MDC_KEY)
        if (correlationId != null) {
            template.header(
                CorrelationIdInterceptor.CORRELATION_ID_HEADER,
                correlationId
            )
        }
    }
}
```

ì´ë ‡ê²Œ í•˜ë©´ Kibanaì—ì„œ `correlationId`ë¡œ ê²€ìƒ‰í•˜ì—¬ ì „ì²´ ìš”ì²­ íë¦„ì„ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```
Kibana ê²€ìƒ‰:
correlationId: "abc-123-def-456"

ê²°ê³¼:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10:15:32.123 | user-service     | Authenticating user       â”‚
â”‚ 10:15:32.234 | user-service     | User authenticated        â”‚
â”‚ 10:15:32.345 | account-service  | Fetching account balance  â”‚
â”‚ 10:15:32.456 | account-service  | Balance: $1,000           â”‚
â”‚ 10:15:32.567 | trade-service    | Creating order            â”‚
â”‚ 10:15:32.678 | trade-service    | Order created: #12345     â”‚
â”‚ 10:15:32.789 | notification     | Sending email             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. ë¯¼ê° ì •ë³´ ë³´í˜¸

```kotlin
// ì´ë©”ì¼ ë§ˆìŠ¤í‚¹
fun String.maskEmail(): String {
    val parts = this.split("@")
    if (parts.size != 2) return "***"
    val local = parts[0]
    val domain = parts[1]
    val masked = local.take(2) + "*".repeat(local.length - 2)
    return "$masked@$domain"
}

// ì „í™”ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
fun String.maskPhone(): String {
    return this.replaceRange(4, this.length - 4, "*".repeat(this.length - 8))
}

// ì¹´ë“œ ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
fun String.maskCardNumber(): String {
    return this.replaceRange(4, 12, "****-****")
}

// ì‚¬ìš© ì˜ˆì‹œ
logger.info("User registered",
    kv("email", user.email.maskEmail()),  // te**@example.com
    kv("phone", user.phone.maskPhone())   // 010-****-5678
)
```

---

## LK-Trade í”„ë¡œì íŠ¸ì— ì ìš©í•˜ê¸°

### 1. ì „ì²´ docker-compose í†µí•©

```yaml
# docker-compose.yml (ì „ì²´ í†µí•© ë²„ì „)
version: '3.8'

services:
  # ========================================
  # ELK Stack
  # ========================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: lk-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - lk-trade-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: lk-logstash
    volumes:
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5044:5044"
      - "9600:9600"
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
    networks:
      - lk-trade-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: lk-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - lk-trade-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: lk-filebeat
    user: root
    volumes:
      - ./elk/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data:/usr/share/filebeat/data
    command: filebeat -e -strict.perms=false
    networks:
      - lk-trade-network
    depends_on:
      - logstash

  # ========================================
  # Application Services (ë¡œê·¸ ì„¤ì • í¬í•¨)
  # ========================================
  user-service:
    build:
      context: ./modules/user/api
      dockerfile: Dockerfile
    container_name: lk-user-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=user"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/lk_trade
    ports:
      - "8081:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres
      - redis

  trade-service:
    build:
      context: ./modules/trade/api
      dockerfile: Dockerfile
    container_name: lk-trade-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=trade"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8082:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres
      - redis

  account-service:
    build:
      context: ./modules/account/api
      dockerfile: Dockerfile
    container_name: lk-account-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=account"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8083:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres

  strategy-service:
    build:
      context: ./modules/strategy/api
      dockerfile: Dockerfile
    container_name: lk-strategy-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=strategy"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8084:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres

  # ========================================
  # Infrastructure
  # ========================================
  postgres:
    image: postgres:16-alpine
    container_name: lk-postgres
    environment:
      - POSTGRES_DB=lk_trade
      - POSTGRES_USER=lk_admin
      - POSTGRES_PASSWORD=secure_password
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - lk-trade-network

  redis:
    image: redis:7-alpine
    container_name: lk-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - lk-trade-network

volumes:
  elasticsearch-data:
  filebeat-data:
  postgres-data:
  redis-data:

networks:
  lk-trade-network:
    driver: bridge
```

### 2. ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
C:\trade\backend1\
â”œâ”€â”€ elk/
â”‚   â”œâ”€â”€ filebeat/
â”‚   â”‚   â””â”€â”€ filebeat.yml
â”‚   â””â”€â”€ logstash/
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â””â”€â”€ logstash.yml
â”‚       â””â”€â”€ pipeline/
â”‚           â””â”€â”€ logstash.conf
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ user/api/
â”‚   â”‚   â””â”€â”€ src/main/resources/
â”‚   â”‚       â””â”€â”€ logback-spring.xml
â”‚   â”œâ”€â”€ trade/api/
â”‚   â”‚   â””â”€â”€ src/main/resources/
â”‚   â”‚       â””â”€â”€ logback-spring.xml
â”‚   â””â”€â”€ ...
â””â”€â”€ scripts/
    â”œâ”€â”€ start-elk.sh
    â””â”€â”€ stop-elk.sh
```

### 3. ì‹œì‘/ì¤‘ì§€ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/start-elk.sh

echo "ğŸš€ Starting ELK Stack..."

# Elasticsearch ì‹œì‘
docker-compose up -d elasticsearch
echo "â³ Waiting for Elasticsearch to be healthy..."
until docker exec lk-elasticsearch curl -s http://localhost:9200 > /dev/null; do
    sleep 5
done
echo "âœ… Elasticsearch is ready"

# Logstash ì‹œì‘
docker-compose up -d logstash
echo "â³ Waiting for Logstash..."
sleep 30
echo "âœ… Logstash is ready"

# Kibana ì‹œì‘
docker-compose up -d kibana
echo "â³ Waiting for Kibana..."
sleep 30
echo "âœ… Kibana is ready"

# Filebeat ì‹œì‘
docker-compose up -d filebeat
echo "âœ… Filebeat is ready"

echo "
========================================
ELK Stack started successfully! ğŸ‰
========================================

ğŸ“Š Kibana: http://localhost:5601
ğŸ” Elasticsearch: http://localhost:9200
ğŸ“ Logstash: http://localhost:9600

Next steps:
1. Open Kibana: http://localhost:5601
2. Create index pattern: lk-trade-*
3. Start exploring logs in Discover
========================================
"
```

```bash
#!/bin/bash
# scripts/stop-elk.sh

echo "ğŸ›‘ Stopping ELK Stack..."

docker-compose stop filebeat
docker-compose stop kibana
docker-compose stop logstash
docker-compose stop elasticsearch

echo "âœ… ELK Stack stopped"
```

### 4. Makefile í†µí•©

```makefile
# Makefile
.PHONY: elk-start elk-stop elk-logs elk-status logs-view logs-search

# ELK Stack ê´€ë¦¬
elk-start:
	@echo "ğŸš€ Starting ELK Stack..."
	@bash scripts/start-elk.sh

elk-stop:
	@echo "ğŸ›‘ Stopping ELK Stack..."
	@bash scripts/stop-elk.sh

elk-logs:
	@docker-compose logs -f elasticsearch logstash kibana filebeat

elk-status:
	@echo "ğŸ“Š Elasticsearch:"
	@curl -s http://localhost:9200 | jq
	@echo "\nğŸ“ Logstash:"
	@curl -s http://localhost:9600 | jq
	@echo "\nğŸ” Kibana:"
	@curl -s http://localhost:5601/api/status | jq

# ë¡œê·¸ ì¡°íšŒ
logs-view:
	@echo "Select service:"
	@echo "1) user-service"
	@echo "2) trade-service"
	@echo "3) account-service"
	@echo "4) strategy-service"
	@echo "5) all services"
	@read -p "Enter number: " choice; \
	case $$choice in \
		1) docker-compose logs -f user-service ;; \
		2) docker-compose logs -f trade-service ;; \
		3) docker-compose logs -f account-service ;; \
		4) docker-compose logs -f strategy-service ;; \
		5) docker-compose logs -f ;; \
		*) echo "Invalid choice" ;; \
	esac

# Kibanaì—ì„œ ìµœê·¼ ì—ëŸ¬ ê²€ìƒ‰
logs-search-errors:
	@echo "ğŸ” Searching for recent errors in Kibana..."
	@curl -s -X GET "http://localhost:9200/lk-trade-*/_search" \
		-H 'Content-Type: application/json' \
		-d '{"query":{"match":{"log_level":"ERROR"}},"size":10,"sort":[{"@timestamp":{"order":"desc"}}]}' \
		| jq '.hits.hits[]._source | {time: .timestamp, service: .service_name, message: .message}'
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: Filebeatê°€ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í•¨

```bash
# ì¦ìƒ
Kibanaì— ë¡œê·¸ê°€ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŒ

# ì›ì¸ í™•ì¸
docker logs lk-filebeat

# ì¼ë°˜ì ì¸ ì›ì¸:
# 1. Docker ì†Œì¼“ ê¶Œí•œ ë¬¸ì œ
# 2. ë¡œê·¸ ê²½ë¡œ ë§ˆìš´íŠ¸ ì˜¤ë¥˜
# 3. Logstash ì—°ê²° ì‹¤íŒ¨

# í•´ê²°ì±… 1: ê¶Œí•œ í™•ì¸
docker exec lk-filebeat ls -la /var/run/docker.sock
# ì¶œë ¥: srw-rw---- 1 root docker 0 Sep 30 10:00 /var/run/docker.sock

# í•´ê²°ì±… 2: Logstash ì—°ê²° í™•ì¸
docker exec lk-filebeat cat /usr/share/filebeat/filebeat.yml | grep logstash
# output.logstash.hostsê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸

# í•´ê²°ì±… 3: Filebeat ì¬ì‹œì‘
docker-compose restart filebeat
```

### ë¬¸ì œ 2: Logstashê°€ ë¡œê·¸ë¥¼ íŒŒì‹±í•˜ì§€ ëª»í•¨

```bash
# ì¦ìƒ
Elasticsearchì— ë¡œê·¸ê°€ ì €ì¥ë˜ì§€ë§Œ í•„ë“œê°€ íŒŒì‹±ë˜ì§€ ì•ŠìŒ

# ì›ì¸ í™•ì¸
docker logs lk-logstash

# ì¼ë°˜ì ì¸ ì›ì¸:
# - grok íŒ¨í„´ ì˜¤ë¥˜
# - JSON íŒŒì‹± ì‹¤íŒ¨

# í•´ê²°ì±…: Logstash íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
docker exec -it lk-logstash bash

# ìƒ˜í”Œ ë¡œê·¸ë¡œ í…ŒìŠ¤íŠ¸
echo '{"log":"2025-09-30 10:15:32.123 INFO [main] Application started\n","stream":"stdout"}' \
  | /usr/share/logstash/bin/logstash -f /usr/share/logstash/pipeline/logstash.conf --config.test_and_exit

# ì¶œë ¥ì—ì„œ íŒŒì‹± ê²°ê³¼ í™•ì¸
```

### ë¬¸ì œ 3: Elasticsearch ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

```bash
# ì¦ìƒ
Elasticsearchê°€ read-only ëª¨ë“œë¡œ ì „í™˜

# í™•ì¸
curl -X GET "http://localhost:9200/_cluster/health?pretty"

# í•´ê²°ì±… 1: ì˜¤ë˜ëœ ì¸ë±ìŠ¤ ì‚­ì œ
# 30ì¼ ì´ì „ ì¸ë±ìŠ¤ ì‚­ì œ
curl -X DELETE "http://localhost:9200/lk-trade-2025.08.*"

# í•´ê²°ì±… 2: Index Lifecycle Management (ILM) ì„¤ì •
curl -X PUT "http://localhost:9200/_ilm/policy/lk-trade-policy" -H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_size": "50gb",
            "max_age": "7d"
          }
        }
      },
      "delete": {
        "min_age": "30d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
'

# í•´ê²°ì±… 3: read-only ëª¨ë“œ í•´ì œ
curl -X PUT "http://localhost:9200/_cluster/settings" -H 'Content-Type: application/json' -d'
{
  "persistent": {
    "cluster.routing.allocation.disk.threshold_enabled": false
  }
}
'
curl -X PUT "http://localhost:9200/*/_settings" -H 'Content-Type: application/json' -d'
{
  "index.blocks.read_only_allow_delete": null
}
'
```

### ë¬¸ì œ 4: Kibanaê°€ ëŠë¦¼

```bash
# ì¦ìƒ
Kibana ëŒ€ì‹œë³´ë“œ ë¡œë”©ì´ ë§¤ìš° ëŠë¦¼

# ì›ì¸:
# - ë„ˆë¬´ ë§ì€ ë°ì´í„° ì¡°íšŒ
# - ì¸ë±ìŠ¤ê°€ ìµœì í™”ë˜ì§€ ì•ŠìŒ

# í•´ê²°ì±… 1: ì‹œê°„ ë²”ìœ„ ì¤„ì´ê¸°
# Kibanaì—ì„œ "Last 15 minutes" ë“±ìœ¼ë¡œ ë²”ìœ„ ì¶•ì†Œ

# í•´ê²°ì±… 2: ì¸ë±ìŠ¤ ìµœì í™”
curl -X POST "http://localhost:9200/lk-trade-*/_forcemerge?max_num_segments=1"

# í•´ê²°ì±… 3: Kibana ë©”ëª¨ë¦¬ ì¦ê°€
# docker-compose.ymlì—ì„œ:
kibana:
  environment:
    - NODE_OPTIONS="--max-old-space-size=4096"
```

---

## ë‹¤ìŒ ë‹¨ê³„

ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰ ì´ì œ Docker ë¡œê·¸ ê´€ë¦¬ì˜ ëª¨ë“  ê²ƒì„ ë°°ì› ìŠµë‹ˆë‹¤.

### ì´ë²ˆ ì„¹ì…˜ì—ì„œ ë°°ìš´ ê²ƒ

âœ… Docker ë¡œê·¸ ë“œë¼ì´ë²„ ì¢…ë¥˜ì™€ ì„¤ì •
âœ… ELK Stack (Elasticsearch + Logstash + Kibana) êµ¬ì¶•
âœ… Filebeatë¡œ Docker ì»¨í…Œì´ë„ˆ ë¡œê·¸ ìë™ ìˆ˜ì§‘
âœ… Logstashë¡œ ë¡œê·¸ íŒŒì‹± ë° ê°€ê³µ
âœ… Kibanaì—ì„œ ë¡œê·¸ ê²€ìƒ‰ ë° ì‹œê°í™”
âœ… êµ¬ì¡°í™”ëœ ë¡œê¹… ë° Correlation ID ì¶”ì 
âœ… ë¡œê·¸ ê´€ë¦¬ ëª¨ë²” ì‚¬ë¡€
âœ… LK-Trade í”„ë¡œì íŠ¸ì— ë¡œê·¸ ê´€ë¦¬ í†µí•©

### ë‹¤ìŒì— ë°°ìš¸ ê²ƒ

**ì„¹ì…˜ 27: ë³´ì•ˆ (Security)**ì—ì„œëŠ”:
- Docker ë³´ì•ˆ ëª¨ë²” ì‚¬ë¡€
- ì»¨í…Œì´ë„ˆ ê²©ë¦¬ ë° ê¶Œí•œ ê´€ë¦¬
- ì´ë¯¸ì§€ ì·¨ì•½ì  ìŠ¤ìº”
- Secrets ê´€ë¦¬
- ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ
- ë³´ì•ˆ ì •ì±… ì ìš©

### ì¶”ê°€ í•™ìŠµ ìë£Œ

**ê³µì‹ ë¬¸ì„œ:**
- [Docker Logging](https://docs.docker.com/config/containers/logging/)
- [Elastic Stack](https://www.elastic.co/guide/index.html)
- [Filebeat Reference](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)
- [Logstash Reference](https://www.elastic.co/guide/en/logstash/current/index.html)

**ì‹¬í™” í•™ìŠµ:**
- [ELK Stack Tutorial](https://www.elastic.co/webinars/getting-started-elasticsearch)
- [Structured Logging Best Practices](https://betterstack.com/community/guides/logging/structured-logging/)
- [Distributed Tracing with OpenTelemetry](https://opentelemetry.io/)

**ì‹¤ì „ ì—°ìŠµ:**
1. LK-Trade í”„ë¡œì íŠ¸ì— ELK Stack ì ìš©
2. Kibana ëŒ€ì‹œë³´ë“œ ì»¤ìŠ¤í„°ë§ˆì´ì§•
3. ì•Œë¦¼ ê·œì¹™ ì„¤ì • (Elasticsearch Watcher)
4. ë¡œê·¸ ê¸°ë°˜ ì„±ëŠ¥ ë¶„ì„ ë° ìµœì í™”

---

**ë‹¤ìŒ ì„¹ì…˜ì—ì„œ ë§Œë‚˜ìš”!** ğŸš€