# 24. 리소스 제한 및 관리

> **학습 목표**: Docker 컨테이너의 CPU, 메모리, 디스크 I/O, 네트워크 등 리소스를 효과적으로 제한하고 관리하여 안정적이고 예측 가능한 시스템을 구축할 수 있습니다.

**⏱️ 예상 학습 시간**: 2.5-3시간
**난이도**: ⭐⭐⭐⭐☆ (4개/5개)

---

## 목차
1. [리소스 제한의 중요성](#리소스-제한의-중요성)
2. [CPU 제한](#cpu-제한)
3. [메모리 제한](#메모리-제한)
4. [디스크 I/O 제한](#디스크-io-제한)
5. [네트워크 대역폭 제한](#네트워크-대역폭-제한)
6. [PID 제한](#pid-제한)
7. [리소스 예약 (Reservation)](#리소스-예약-reservation)
8. [실전 예제: LK-Trade 리소스 설정](#실전-예제-lk-trade-리소스-설정)
9. [주니어 개발자 시나리오](#주니어-개발자-시나리오)
10. [FAQ](#faq)
11. [면접 질문](#면접-질문)

---

## 💡 왜 리소스 제한이 필요한가?

### 실무 배경

**"컨테이너 하나가 서버 전체를 먹어버렸습니다!"**

#### ❌ 리소스 제한이 없으면 발생하는 문제

```
문제 1: Noisy Neighbor (시끄러운 이웃)
- 증상: 한 컨테이너가 CPU 100% 점유
- 대응: 다른 컨테이너들 응답 없음
- 영향: 전체 서비스 마비
- 비용: 시간당 수백만원 손실

문제 2: OOM Killer 공포
- 증상: "메모리 릭이 있는 컨테이너가 계속 메모리 소비"
- 대응: 호스트 메모리 고갈
- 영향: 중요 컨테이너까지 강제 종료
- 비용: 핵심 서비스 다운, 매출 손실

문제 3: 예측 불가능한 성능
- 증상: "어제는 빨랐는데 오늘은 느려요"
- 대응: 리소스 경합으로 성능 들쑥날쑥
- 영향: 사용자 경험 악화
- 비용: 고객 이탈률 증가
```

#### ✅ 리소스 제한을 설정하면

```
해결책 1: 격리된 환경
- 방법: CPU/메모리 제한으로 컨테이너별 격리
- 효과: 한 컨테이너 문제가 다른 컨테이너에 영향 안 줌
- 절감: 장애 영향 범위 95% 감소

해결책 2: 예측 가능한 비용
- 방법: 리소스 상한선 설정
- 효과: 클라우드 비용 폭증 방지
- 절감: 월 평균 클라우드 비용 40% 절감

해결책 3: 안정적인 성능
- 방법: 리소스 예약으로 최소 보장
- 효과: 일정한 성능 유지
- 절감: 사용자 만족도 85% 향상
```

### 수치로 보는 효과

| 지표 | Before | After | 개선율 |
|------|--------|-------|--------|
| 전체 서비스 마비 빈도 | 월 3회 | 월 0회 | **100%↓** |
| 장애 영향 범위 | 전체 시스템 | 단일 컨테이너 | **95%↓** |
| 클라우드 비용 초과 | 월 200만원 | 월 0원 | **100%↓** |
| OOM Killer 발생 | 주 5회 | 월 1회 | **80%↓** |
| 평균 응답 시간 변동 | ±300% | ±10% | **97%↓** |

---

## 🔍 실생활 비유로 이해하기

### 비유 1: 아파트 전기 사용량 제한 (차단기)

```
아파트 전체 전력: 100kW
각 집: 5kW 차단기

제한 없는 경우:
┌─────────────────────────────────────────┐
│ 201호: 에어컨 10대 가동 (50kW)          │
│ 202호: 정상 사용 (2kW)                  │
│ 203호: 정상 사용 (3kW)                  │
│ ────────────────────────────────────── │
│ 결과: 전체 아파트 정전! ⚡              │
└─────────────────────────────────────────┘

제한 있는 경우 (차단기):
┌─────────────────────────────────────────┐
│ 201호: 5kW 초과 시 차단 (자동 차단)     │
│ 202호: 정상 사용 (2kW) ✅               │
│ 203호: 정상 사용 (3kW) ✅               │
│ ────────────────────────────────────── │
│ 결과: 201호만 차단, 다른 집 정상 ✅     │
└─────────────────────────────────────────┘

Docker 리소스 제한도 동일:
┌─────────────────────────────────────────┐
│ 호스트 리소스: CPU 8코어, 메모리 32GB   │
│ ────────────────────────────────────── │
│ Container A: CPU 2코어, 메모리 4GB 제한 │
│ Container B: CPU 1코어, 메모리 2GB 제한 │
│ Container C: CPU 1코어, 메모리 2GB 제한 │
│ ────────────────────────────────────── │
│ 효과: 격리된 환경, 상호 영향 없음       │
└─────────────────────────────────────────┘
```

### 비유 2: 도로 차선 제한

```
고속도로 비유:

제한 없음 (무법 상태):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 🚛🚛🚛🚛 (대형 트럭이 모든 차선 점유)
 🚗💨 (일반 차량 못 감)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
결과: 전체 교통 마비

차선 제한 있음:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 [1차선: 🚗] [2차선: 🚙] [3차선: 🚛]
 각 차량이 할당된 차선만 사용
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
결과: 원활한 교통 흐름

Docker:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
 CPU 0-1: Container A
 CPU 2-3: Container B
 CPU 4-7: Container C
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
각 컨테이너가 할당된 CPU만 사용
→ 공평하고 예측 가능한 성능
```

### 비유 3: 뷔페 식당의 인분 제한

```
무제한 뷔페의 문제:

제한 없음:
┌─────────────────────────────────────┐
│ 손님 A: 접시 20개 가져감 🍽️🍽️🍽️    │
│ 손님 B: 음식 없어서 못 먹음 😢      │
│ 손님 C: 음식 없어서 못 먹음 😢      │
└─────────────────────────────────────┘
결과: 불공평, 손님 불만

1인당 접시 3개 제한:
┌─────────────────────────────────────┐
│ 손님 A: 접시 3개 (충분함) ✅        │
│ 손님 B: 접시 3개 (만족함) ✅        │
│ 손님 C: 접시 3개 (만족함) ✅        │
└─────────────────────────────────────┘
결과: 공평, 모두 만족

Docker 메모리 제한:
┌─────────────────────────────────────┐
│ Container A: 2GB 제한 (적정함)      │
│ Container B: 2GB 제한 (적정함)      │
│ Container C: 2GB 제한 (적정함)      │
└─────────────────────────────────────┘
호스트 메모리 32GB를 공평하게 분배
→ 모든 컨테이너가 안정적 실행
```

---

## 리소스 제한의 중요성

### 리소스 제한의 이점

```
┌────────────────────┬──────────────────────────────────┐
│     이점           │            설명                  │
├────────────────────┼──────────────────────────────────┤
│ 안정성 향상        │ 한 컨테이너가 전체 시스템        │
│                    │ 마비시키는 것 방지               │
├────────────────────┼──────────────────────────────────┤
│ 공평한 리소스 분배 │ 모든 컨테이너가 필요한           │
│                    │ 리소스 보장                      │
├────────────────────┼──────────────────────────────────┤
│ 비용 예측 가능     │ 클라우드 환경에서 비용           │
│                    │ 초과 방지                        │
├────────────────────┼──────────────────────────────────┤
│ 성능 예측 가능     │ 일정한 성능 보장                 │
├────────────────────┼──────────────────────────────────┤
│ 보안 강화          │ 리소스 고갈 공격(DoS) 방어       │
└────────────────────┴──────────────────────────────────┘
```

---

## CPU 제한

### CPU 제한 방식

#### 1. --cpus (추천)

가장 직관적인 방법으로, 사용할 CPU 코어 수를 지정합니다.

```bash
# 2개 CPU 코어 사용 제한
docker run -d --cpus="2.0" nginx

# 0.5개 CPU 코어 (50%)
docker run -d --cpus="0.5" nginx

# docker-compose.yml
services:
  user-service:
    image: user-service:latest
    cpus: 2.0  # 2 CPU 코어
```

**동작 원리**:
```
호스트: 8 CPU 코어
컨테이너: --cpus="2.0"

→ 컨테이너는 최대 2 CPU 코어만 사용 가능
→ 8 코어 모두 접근 가능하지만, 총 사용량은 2 코어로 제한
→ 100ms 중 200ms 사용 가능 (2.0 = 200%)
```

#### 2. --cpu-shares (상대적 가중치)

CPU 경합 시 우선순위를 결정합니다.

```bash
# 기본값: 1024
docker run -d --cpu-shares=512 nginx   # 50% 가중치
docker run -d --cpu-shares=1024 nginx  # 100% 가중치 (기본)
docker run -d --cpu-shares=2048 nginx  # 200% 가중치
```

**동작 원리**:
```
컨테이너 A: --cpu-shares=1024
컨테이너 B: --cpu-shares=2048
컨테이너 C: --cpu-shares=1024

CPU 경합 시 (모두 CPU 100% 원함):
- 총 shares: 4096 (1024 + 2048 + 1024)
- 컨테이너 A: 25% (1024 / 4096)
- 컨테이너 B: 50% (2048 / 4096)
- 컨테이너 C: 25% (1024 / 4096)

CPU 여유 시:
- 모든 컨테이너가 필요한 만큼 사용 가능
- 제한 없음
```

#### 3. --cpuset-cpus (특정 코어 할당)

특정 CPU 코어만 사용하도록 고정합니다.

```bash
# CPU 0, 1번만 사용
docker run -d --cpuset-cpus="0,1" nginx

# CPU 0-3번 사용
docker run -d --cpuset-cpus="0-3" nginx

# docker-compose.yml
services:
  user-service:
    cpuset: "0,1"  # CPU 0, 1번 코어만
```

**사용 사례**:
```
NUMA (Non-Uniform Memory Access) 시스템 최적화:

서버: 16 CPU 코어
- CPU 0-7: NUMA 노드 0 (메모리 뱅크 0 가까움)
- CPU 8-15: NUMA 노드 1 (메모리 뱅크 1 가까움)

최적화:
- Container A: --cpuset-cpus="0-7" (NUMA 노드 0)
- Container B: --cpuset-cpus="8-15" (NUMA 노드 1)

효과: 메모리 액세스 속도 30-40% 향상
```

### CPU 제한 비교

```yaml
# docker-compose.yml

services:
  # 1. 절대적 제한 (추천) - 명확한 상한선
  web-server:
    image: nginx
    cpus: 1.5  # 최대 1.5 CPU 코어
    # 언제든 최대 1.5 코어만 사용

  # 2. 상대적 가중치 - 유연한 분배
  background-job:
    image: worker
    cpu_shares: 512  # 낮은 우선순위
    # CPU 여유 시 많이 사용, 경합 시 적게 사용

  # 3. 특정 코어 할당 - 성능 최적화
  real-time-service:
    image: rt-service
    cpuset: "0,1"  # CPU 0, 1번 전용
    # 항상 같은 코어 사용 → 캐시 효율 향상
```

### CPU 사용량 모니터링

```bash
# 실시간 CPU 사용량
docker stats

# CPU 제한 확인
docker inspect container_id | jq '.[0].HostConfig.NanoCpus'
# 2000000000 = 2.0 CPU

# 컨테이너 내부에서 (cgroup v1)
docker exec container_id cat /sys/fs/cgroup/cpu/cpu.cfs_quota_us
docker exec container_id cat /sys/fs/cgroup/cpu/cpu.cfs_period_us
# quota / period = CPU 코어 수
# 예: 200000 / 100000 = 2.0 코어

# cgroup v2
docker exec container_id cat /sys/fs/cgroup/cpu.max
```

---

## 메모리 제한

### 메모리 제한 옵션

#### 1. --memory (하드 리미트)

메모리 사용량의 상한선을 설정합니다. 초과 시 OOM Killer가 작동합니다.

```bash
# 512MB 제한
docker run -d --memory="512m" nginx

# 2GB 제한
docker run -d --memory="2g" nginx

# docker-compose.yml
services:
  user-service:
    image: user-service:latest
    mem_limit: 1g  # 1GB
```

**동작 원리**:
```
메모리 제한: 512MB
프로세스가 512MB 초과 시도:

1. 먼저 스왑 사용 시도 (스왑 있으면)
2. 스왑도 부족하면 OOM Killer 작동
3. 컨테이너 프로세스 강제 종료
4. Exit Code 137 (128 + 9 SIGKILL)
```

#### 2. --memory-reservation (소프트 리미트)

메모리 부족 시 회수 우선순위를 결정하는 소프트 리미트입니다.

```bash
# 예약: 256MB, 최대: 512MB
docker run -d \
  --memory="512m" \
  --memory-reservation="256m" \
  nginx
```

**동작 원리**:
```
설정: reservation=256MB, limit=512MB

정상 상황:
- 256MB 보장받음
- 필요 시 512MB까지 사용 가능
- 256MB~512MB 구간은 자유롭게 사용

메모리 부족 상황 (호스트 전체):
- 256MB까지는 보장 (회수 안 됨)
- 256MB~512MB는 회수 대상
- reservation 초과분부터 회수
```

#### 3. --memory-swap (스왑 포함 제한)

메모리 + 스왑의 총합을 제한합니다.

```bash
# 메모리: 512MB, 스왑: 512MB (총 1GB)
docker run -d \
  --memory="512m" \
  --memory-swap="1g" \
  nginx

# 스왑 비활성화
docker run -d \
  --memory="512m" \
  --memory-swap="512m" \
  nginx

# 스왑 무제한
docker run -d \
  --memory="512m" \
  --memory-swap="-1" \
  nginx
```

**동작 원리**:
```
--memory="512m" --memory-swap="1g"
→ 물리 메모리: 512MB
→ 스왑: 512MB (1g - 512m)
→ 총: 1GB

--memory="512m" --memory-swap="512m"
→ 물리 메모리: 512MB
→ 스왑: 0 (스왑과 메모리가 같으면 스왑 비활성화)

--memory-swap 미설정
→ 스왑 = 메모리 × 2 (기본값)
→ 메모리 512MB이면 스왑도 512MB
```

### OOM (Out of Memory) 동작 설정

```bash
# OOM Killer 비활성화 (위험! 프로덕션 비추천)
docker run -d \
  --memory="512m" \
  --oom-kill-disable \
  nginx
# 주의: 호스트 전체 메모리 고갈 가능

# OOM 점수 조정 (우선순위)
docker run -d \
  --memory="512m" \
  --oom-score-adj=500 \
  nginx
# 값 범위: -1000 ~ 1000
# 낮을수록: 종료 우선순위 낮음 (중요 서비스)
# 높을수록: 종료 우선순위 높음 (덜 중요 서비스)
```

```yaml
# docker-compose.yml

services:
  # 핵심 서비스 (마지막에 종료)
  critical-service:
    image: critical:latest
    mem_limit: 1g
    oom_score_adj: -500  # 낮을수록 종료 우선순위 낮음

  # 비핵심 서비스 (먼저 종료)
  non-critical-service:
    image: worker:latest
    mem_limit: 512m
    oom_score_adj: 500   # 높을수록 먼저 종료됨
```

### 메모리 사용량 모니터링

```bash
# 실시간 메모리 사용량
docker stats

# 메모리 제한 확인
docker inspect container_id | jq '.[0].HostConfig.Memory'
# 536870912 = 512MB

# 컨테이너 내부에서 (cgroup v1)
docker exec container_id cat /sys/fs/cgroup/memory/memory.limit_in_bytes
docker exec container_id cat /sys/fs/cgroup/memory/memory.usage_in_bytes

# cgroup v2
docker exec container_id cat /sys/fs/cgroup/memory.max
docker exec container_id cat /sys/fs/cgroup/memory.current

# OOM Killed 확인
docker inspect container_id | jq '.[0].State.OOMKilled'
```

### JVM 메모리 설정 (Java/Kotlin)

JVM은 컨테이너 메모리 제한을 인식해야 합니다.

```dockerfile
# Dockerfile

FROM eclipse-temurin:21-jre-alpine

# JDK 8u191+ 부터 컨테이너 메모리 자동 인식
ENV JAVA_OPTS="-XX:+UseContainerSupport \
               -XX:MaxRAMPercentage=75.0 \
               -XX:InitialRAMPercentage=50.0 \
               -XX:MinRAMPercentage=50.0"

COPY app.jar /app/app.jar

CMD ["java", "-jar", "/app/app.jar"]
```

```yaml
# docker-compose.yml

services:
  user-service:
    image: user-service:latest
    mem_limit: 2g
    environment:
      # JVM이 컨테이너 메모리 2GB 인식
      # MaxRAMPercentage=75.0 → 힙 최대 1.5GB (2GB × 75%)
      # 나머지 0.5GB: 메타스페이스, 스레드, 네이티브 메모리
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
```

**메모리 배분 예시 (컨테이너 2GB)**:
```
총 컨테이너 메모리: 2GB

JVM 메모리 구성:
- 힙 메모리: 1.5GB (75%)
  ├─ Young Gen: 500MB
  └─ Old Gen: 1GB
- 메타스페이스: 256MB
- 스레드 스택: 100MB (100 threads × 1MB)
- 코드 캐시: 64MB
- Direct Buffer: 50MB
- 기타: 34MB
─────────────────────
총: 2GB
```

---

## 디스크 I/O 제한

### Block I/O 가중치

```bash
# 기본값: 500
docker run -d --blkio-weight=300 nginx  # 낮은 우선순위
docker run -d --blkio-weight=700 nginx  # 높은 우선순위

# 값 범위: 10 ~ 1000
# 낮을수록 낮은 우선순위, 높을수록 높은 우선순위
```

### 읽기/쓰기 속도 제한

```bash
# 읽기 속도: 10MB/s
docker run -d \
  --device-read-bps /dev/sda:10mb \
  nginx

# 쓰기 속도: 5MB/s
docker run -d \
  --device-write-bps /dev/sda:5mb \
  nginx

# docker-compose.yml
services:
  database:
    image: postgres:15
    device_read_bps:
      - path: /dev/sda
        rate: 50mb
    device_write_bps:
      - path: /dev/sda
        rate: 20mb
```

**주의사항**:
```bash
# 디바이스 경로 확인
lsblk

# 예시 출력:
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0  100G  0 disk
├─sda1   8:1    0   99G  0 part /
└─sda2   8:2    0    1G  0 part [SWAP]

# sda가 메인 디스크
```

### IOPS (Input/Output Operations Per Second) 제한

```bash
# 읽기 IOPS: 100
docker run -d \
  --device-read-iops /dev/sda:100 \
  nginx

# 쓰기 IOPS: 50
docker run -d \
  --device-write-iops /dev/sda:50 \
  nginx

# docker-compose.yml
services:
  database:
    image: postgres:15
    device_read_iops:
      - path: /dev/sda
        rate: 1000
    device_write_iops:
      - path: /dev/sda
        rate: 500
```

---

## 네트워크 대역폭 제한

Docker 자체는 네트워크 대역폭 제한 기능이 없지만, Linux의 `tc` (traffic control)를 사용할 수 있습니다.

### tc를 이용한 대역폭 제한

```bash
#!/bin/bash
# scripts/limit-bandwidth.sh

CONTAINER_ID=$1
BANDWIDTH=${2:-1mbit}  # 기본 1Mbps

# 컨테이너 네트워크 인터페이스 찾기
CONTAINER_PID=$(docker inspect -f '{{.State.Pid}}' $CONTAINER_ID)
IFACE=$(nsenter -t $CONTAINER_PID -n ip link | grep 'eth0' | awk '{print $2}' | tr -d ':')

# tc 규칙 추가
nsenter -t $CONTAINER_PID -n tc qdisc add dev eth0 root tbf \
    rate $BANDWIDTH \
    burst 32kbit \
    latency 400ms

echo "컨테이너 $CONTAINER_ID 대역폭을 $BANDWIDTH로 제한했습니다."
```

**사용 예시**:
```bash
# 1Mbps로 제한
./scripts/limit-bandwidth.sh user-service 1mbit

# 10Mbps로 제한
./scripts/limit-bandwidth.sh user-service 10mbit

# 제한 해제
CONTAINER_PID=$(docker inspect -f '{{.State.Pid}}' user-service)
nsenter -t $CONTAINER_PID -n tc qdisc del dev eth0 root
```

### Docker Network Plugin 사용

```yaml
# docker-compose.yml

services:
  user-service:
    image: user-service:latest
    networks:
      - limited-network

networks:
  limited-network:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1500
      # MTU 크기 조정으로 간접 제어
```

---

## PID 제한

### PID (프로세스 수) 제한

```bash
# 최대 100개 프로세스
docker run -d --pids-limit=100 nginx

# docker-compose.yml
services:
  user-service:
    image: user-service:latest
    pids_limit: 200
```

**사용 사례: 포크 폭탄(Fork Bomb) 방어**:
```bash
# 악의적 코드 예시
:(){ :|:& };:

# 또는
while true; do
    bash &
done

# 무한히 프로세스를 생성하여 시스템 마비

# PID 제한으로 방어:
docker run -d --pids-limit=100 untrusted-app

# 100개 프로세스 이상 생성 시:
# "Cannot fork: Resource temporarily unavailable"
```

---

## 리소스 예약 (Reservation)

Docker Swarm 모드 또는 Compose v3의 deploy 섹션에서 사용합니다.

### CPU 예약

```yaml
# docker-compose.yml

version: '3.8'

services:
  user-service:
    image: user-service:latest
    deploy:
      resources:
        limits:
          cpus: '2.0'      # 최대 2 CPU
        reservations:
          cpus: '1.0'      # 최소 1 CPU 보장
```

### 메모리 예약

```yaml
services:
  database:
    image: postgres:15
    deploy:
      resources:
        limits:
          memory: 4G       # 최대 4GB
        reservations:
          memory: 2G       # 최소 2GB 보장
```

**동작 원리**:
```
Reservations (예약):
- 스케줄러가 컨테이너 배치 시 고려
- 호스트에 예약된 리소스가 없으면 배치 안함
- "이 컨테이너는 최소 이만큼 필요합니다"

Limits (제한):
- 실제 런타임에서 강제 제한
- 초과 시 제한/종료
- "이 컨테이너는 최대 이만큼만 사용합니다"

예시:
reservations: CPU 1.0, memory 2GB
limits: CPU 2.0, memory 4GB

→ 최소 1 CPU, 2GB 확보 후 시작
→ 최대 2 CPU, 4GB까지 사용 가능
→ 평소: 1-2 CPU, 2-4GB 사이 유동적 사용
```

---

## 실전 예제: LK-Trade 리소스 설정

### 프로덕션 환경 리소스 설정

```yaml
# docker-compose.prod.yml

version: '3.8'

x-resource-limits: &standard-limits
  cpus: '1.0'
  mem_limit: 1g
  mem_reservation: 512m

x-resource-limits-high: &high-limits
  cpus: '2.0'
  mem_limit: 2g
  mem_reservation: 1g

services:
  # 인프라 서비스 (높은 리소스)
  postgres:
    image: postgres:15-alpine
    <<: *high-limits
    environment:
      - POSTGRES_DB=lktrade
      - POSTGRES_USER=lkuser
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    shm_size: 256m  # 공유 메모리 (PostgreSQL 성능 향상)
    oom_score_adj: -300  # 중요 서비스, 낮은 종료 우선순위

  redis:
    image: redis:7-alpine
    cpus: 0.5
    mem_limit: 512m
    mem_reservation: 256m
    command: >
      redis-server
      --maxmemory 400mb
      --maxmemory-policy allkeys-lru
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # User Service (표준 리소스)
  user-service:
    image: ${REGISTRY}/user-service:${VERSION}
    <<: *standard-limits
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Account Service (표준 리소스)
  account-service:
    image: ${REGISTRY}/account-service:${VERSION}
    <<: *standard-limits
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Trade Service (높은 리소스 - 실시간 거래)
  trade-service:
    image: ${REGISTRY}/trade-service:${VERSION}
    <<: *high-limits
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    # 높은 우선순위 (OOM 시 마지막에 종료)
    oom_score_adj: -500

  # AI Service (매우 높은 리소스 - GPT 호출)
  ai-service:
    image: ${REGISTRY}/ai-service:${VERSION}
    cpus: 2.0
    mem_limit: 3g
    mem_reservation: 2g
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=80.0
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2.0'
          memory: 3G
        reservations:
          cpus: '1.0'
          memory: 2G

  # Scraper Service (낮은 리소스 - 백그라운드 작업)
  scraper-service:
    image: ${REGISTRY}/scraper-service:${VERSION}
    cpus: 0.5
    mem_limit: 512m
    mem_reservation: 256m
    cpu_shares: 512  # 낮은 우선순위
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    # 낮은 우선순위 (OOM 시 먼저 종료)
    oom_score_adj: 500

  # Nginx (낮은 리소스)
  nginx:
    image: nginx:alpine
    cpus: 0.5
    mem_limit: 256m
    ports:
      - "80:80"
      - "443:443"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

volumes:
  postgres-data:
```

### 개발 환경 리소스 설정

```yaml
# docker-compose.dev.yml

version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    # 개발 환경: 제한 없음 (빠른 개발)
    shm_size: 128m

  redis:
    image: redis:7-alpine
    # 개발 환경: 제한 없음

  user-service:
    build:
      context: ./modules/user
      dockerfile: Dockerfile.dev
    # 개발 환경: 가벼운 제한만
    mem_limit: 2g
    # OOM 방지용, 핫 리로드 위한 여유 공간
    volumes:
      - ./modules/user/src:/app/src  # 코드 변경 시 자동 반영
```

### 리소스 설정 가이드라인

| 서비스 유형 | CPU | 메모리 | 우선순위 | 비고 |
|------------|-----|--------|---------|------|
| 데이터베이스 | 2.0 | 4G | 높음(-300) | 핵심 인프라 |
| 캐시(Redis) | 0.5 | 512M | 중간(0) | 빠른 응답 필요 |
| API 서비스 | 1.0 | 1G | 중간(0) | 표준 설정 |
| 실시간 서비스 | 2.0 | 2G | 높음(-500) | 거래 서비스 |
| AI/ML 서비스 | 2.0 | 3G | 중간(0) | 메모리 집약적 |
| 백그라운드 작업 | 0.5 | 512M | 낮음(500) | 덜 중요 |
| Nginx | 0.5 | 256M | 중간(0) | 경량 프록시 |

---

## 👨‍💻 주니어 개발자 시나리오

### 시나리오 1: 첫 OOM Killer 경험 - "컨테이너가 계속 죽어요!"

**상황**:
```
주니어 A: "user-service가 10분마다 죽어요. 로그에도 별 내용 없는데..."
팀장: "Exit Code가 뭐야?"
주니어 A: "137이요."
팀장: "아, OOM이구나. 메모리 제한 확인해봤어?"
주니어 A: "???"
```

**단계별 해결**:
```bash
# Step 1: Exit Code 137 확인
$ docker ps -a
CONTAINER ID   STATUS                       NAMES
a1b2c3d4e5f6   Exited (137) 2 minutes ago   user-service

# Exit Code 137 = OOM Killed (128 + 9 SIGKILL)

# Step 2: 메모리 사용량 확인
$ docker stats user-service
CONTAINER      MEM USAGE / LIMIT     MEM %
user-service   512MiB / 512MiB       100%

# 메모리 100% 사용 중!

# Step 3: 메모리 제한 확인
$ docker inspect user-service | jq '.[0].HostConfig.Memory'
536870912  # 512MB

# Step 4: 로그에서 OOM 확인
$ docker logs user-service --tail 50
java.lang.OutOfMemoryError: Java heap space
Exception in thread "main" java.lang.OutOfMemoryError: Java heap space

# Step 5: docker-compose.yml 수정
services:
  user-service:
    mem_limit: 1g  # 512m → 1g로 증가
    environment:
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0

# Step 6: 재시작
$ docker-compose up -d user-service

# Step 7: 모니터링
$ docker stats user-service
CONTAINER      MEM USAGE / LIMIT     MEM %
user-service   650MiB / 1GiB         63.5%

✅ 해결! 더 이상 죽지 않음
```

**배운 점**:
- Exit Code 137 = OOM Killed
- `docker stats`로 메모리 사용량 실시간 확인
- JVM은 컨테이너 메모리의 75% 이내로 힙 설정
- 메모리 제한은 여유 있게 (예상 사용량 × 1.5배)

---

### 시나리오 2: CPU 100% 문제 - "API가 너무 느려요!"

**상황**:
```
주니어 B: "갑자기 API 응답이 10초씩 걸려요!"
시니어: "다른 컨테이너는 괜찮아?"
주니어 B: "네, user-service만 느려요."
시니어: "CPU 사용률 봐봐."
```

**단계별 해결**:
```bash
# Step 1: CPU 사용률 확인
$ docker stats user-service
CONTAINER      CPU %   MEM USAGE
user-service   98.5%   450MiB / 1GiB

# CPU 거의 100%!

# Step 2: CPU 제한 확인
$ docker inspect user-service | jq '.[0].HostConfig.NanoCpus'
1000000000  # 1.0 CPU 코어

# Step 3: 컨테이너 내부 프로세스 확인
$ docker exec user-service top -bn1
  PID USER      PR  NI    VIRT    RES  %CPU  %MEM
    1 root      20   0  2.5g    450m  98.0  11.2  java

# Java 프로세스가 CPU 98% 사용

# Step 4: 임시 해결 - CPU 제한 증가
# docker-compose.yml
services:
  user-service:
    cpus: 2.0  # 1.0 → 2.0으로 증가

$ docker-compose up -d user-service

# Step 5: 확인
$ curl -w "\nTime: %{time_total}s\n" http://localhost:8080/api/users
Time: 0.5s  # 10초 → 0.5초로 개선!

# Step 6: 근본 원인 파악 (스레드 덤프)
$ docker exec user-service jstack 1 > thread-dump.txt
$ cat thread-dump.txt | grep -A 10 "RUNNABLE"

# 무한 루프 발견! (코드 수정 필요)

✅ 임시 해결: CPU 증가
📝 근본 해결: 코드 수정 예정
```

**배운 점**:
- `docker stats`로 CPU 병목 빠르게 발견
- 임시 해결: 리소스 증가
- 근본 해결: 코드 최적화
- 프로덕션: 항상 여유 있는 리소스 설정

---

### 시나리오 3: 다른 서비스 영향 - "DB 컨테이너도 느려졌어요"

**상황**:
```
주니어 C: "scraper-service를 돌렸더니 DB까지 느려졌어요!"
팀장: "scraper가 리소스를 독점하고 있나보네. 제한 설정했어?"
주니어 C: "아니요... 필요한가요?"
```

**단계별 해결**:
```bash
# Step 1: 전체 컨테이너 리소스 확인
$ docker stats
CONTAINER         CPU %   MEM USAGE / LIMIT
postgres          15%     1.2GiB / 2GiB
user-service      25%     800MiB / 1GiB
scraper-service   350%    3.8GiB / 4GiB  # 독점!

# scraper가 CPU 350% (3.5 코어) 사용!

# Step 2: 문제 파악
# scraper가 대량의 웹 페이지 크롤링
# → CPU와 메모리 독점
# → 다른 컨테이너 느려짐

# Step 3: scraper 리소스 제한 추가
# docker-compose.yml
services:
  scraper-service:
    cpus: 1.0           # 최대 1 CPU만
    mem_limit: 1g       # 최대 1GB만
    cpu_shares: 512     # 낮은 우선순위
    oom_score_adj: 500  # OOM 시 먼저 종료

  postgres:
    cpus: 2.0
    mem_limit: 2g
    oom_score_adj: -300  # OOM 시 마지막에 종료

# Step 4: 재시작
$ docker-compose up -d

# Step 5: 확인
$ docker stats
CONTAINER         CPU %   MEM USAGE / LIMIT
postgres          12%     1.2GiB / 2GiB  # 정상!
user-service      20%     800MiB / 1GiB  # 정상!
scraper-service   95%     980MiB / 1GiB  # 제한됨

✅ 해결! 각 컨테이너가 정해진 리소스만 사용
```

**배운 점**:
- **Noisy Neighbor 문제**: 한 컨테이너가 다른 컨테이너 방해
- 모든 컨테이너에 리소스 제한 필수
- 중요도에 따라 우선순위 설정 (cpu_shares, oom_score_adj)
- 백그라운드 작업은 낮은 우선순위로

---

### 시나리오 4: 스왑 사용으로 느려짐 - "메모리는 충분한데 왜 느리죠?"

**상황**:
```
주니어 D: "메모리 사용률 70%인데 왜 이렇게 느리죠?"
시니어: "스왑 사용 중인 거 아니야?"
주니어 D: "스왑이요?"
```

**단계별 해결**:
```bash
# Step 1: 메모리 사용량 확인
$ docker stats user-service
CONTAINER      MEM USAGE / LIMIT     MEM %
user-service   700MiB / 1GiB         68.5%

# 겉보기엔 정상

# Step 2: 컨테이너 내부 메모리 확인
$ docker exec user-service free -h
              total        used        free      shared  buff/cache   available
Mem:           1.0G        700M        100M         10M        200M        200M
Swap:          1.0G        900M        100M  # 스왑 900MB 사용 중!

# 스왑 사용 → 디스크 I/O → 느림

# Step 3: 스왑 비활성화
# docker-compose.yml
services:
  user-service:
    mem_limit: 1g
    mem_swap_limit: 1g  # mem_limit와 같게 → 스왑 비활성화
    # 또는
    memswap_limit: 1g   # 동일

# Step 4: 메모리 증가 (스왑 필요 없도록)
services:
  user-service:
    mem_limit: 1.5g      # 1g → 1.5g
    mem_swap_limit: 1.5g

# Step 5: 재시작
$ docker-compose up -d user-service

# Step 6: 확인
$ docker exec user-service free -h
              total        used        free      shared  buff/cache   available
Mem:           1.5G        800M        500M         10M        200M        500M
Swap:          1.5G          0M       1.5G  # 스왑 사용 안 함!

$ curl -w "\nTime: %{time_total}s\n" http://localhost:8080/api/users
Time: 0.2s  # 빨라짐!

✅ 해결! 스왑 사용 제거 → 성능 향상
```

**배운 점**:
- **스왑 사용 = 느린 성능**: 디스크는 메모리보다 100배 느림
- 메모리 사용률만 보지 말고 스왑도 확인
- 프로덕션: 스왑 비활성화 권장 (mem_limit = memswap_limit)
- 스왑 필요 없도록 충분한 메모리 할당

---

## ❓ FAQ

<details>
<summary><strong>Q1: CPU 제한을 2.0으로 했는데 docker stats에서 200%로 표시돼요. 정상인가요?</strong></summary>

**A**: **네, 정상입니다!** Docker는 CPU 사용률을 코어별로 표시합니다.

**상세 설명**:

**CPU 사용률 표시 방식**:
```bash
# 호스트: 8 CPU 코어
# 컨테이너: --cpus="2.0"

$ docker stats user-service
CONTAINER      CPU %
user-service   200%

# 200% = 2.0 CPU 코어 100% 사용
# 100% = 1.0 CPU 코어 100% 사용
# 50% = 0.5 CPU 코어 100% 사용
```

**왜 100%가 아니라 200%?**:
```
Docker stats는 호스트 전체 CPU를 기준으로 표시하지 않고,
사용 가능한 CPU 코어 수를 100%로 계산합니다.

예시:
- 8 코어 호스트에서 1 코어 100% 사용 = 12.5% (Linux top 방식)
- Docker stats: 100% (1 코어 전체 사용)

- 8 코어 호스트에서 2 코어 100% 사용 = 25% (Linux top 방식)
- Docker stats: 200% (2 코어 전체 사용)
```

**확인 방법**:
```bash
# CPU 제한 확인
$ docker inspect user-service | jq '.[0].HostConfig.NanoCpus'
2000000000  # 2.0 CPU

# 2000000000 nanoseconds = 2.0 CPU 코어
# 1000000000 nanoseconds = 1.0 CPU 코어

# cgroup으로 확인
$ docker exec user-service cat /sys/fs/cgroup/cpu/cpu.cfs_quota_us
200000

$ docker exec user-service cat /sys/fs/cgroup/cpu/cpu.cfs_period_us
100000

# quota / period = 200000 / 100000 = 2.0 CPU
```

**정리**:
- CPU 제한 2.0 → docker stats에서 최대 200% 표시 ✅
- CPU 제한 1.0 → docker stats에서 최대 100% 표시 ✅
- CPU 제한 0.5 → docker stats에서 최대 50% 표시 ✅

</details>

<details>
<summary><strong>Q2: 메모리 제한을 1GB로 했는데 컨테이너 내부에서 free -h를 보면 다르게 나와요. 왜 그런가요?</strong></summary>

**A**: **컨테이너 내부의 free 명령은 호스트 메모리를 보여주기 때문**입니다.

**상세 설명**:

**문제 상황**:
```bash
# docker-compose.yml
services:
  user-service:
    mem_limit: 1g

# 컨테이너 실행 후
$ docker exec user-service free -h
              total        used        free
Mem:            32G         28G          4G

# 어? 1GB로 제한했는데 32GB로 보임!
```

**원인**:
```
free, top, htop 같은 명령어는 /proc/meminfo를 읽습니다.
컨테이너는 호스트의 /proc를 공유하므로 호스트 메모리를 보여줍니다.

오래된 이미지나 cgroup v1 환경에서 발생합니다.
```

**올바른 확인 방법**:

**방법 1: docker stats (추천)**
```bash
$ docker stats user-service --no-stream
CONTAINER      MEM USAGE / LIMIT     MEM %
user-service   450MiB / 1GiB         43.95%

# 정확한 메모리 사용량 표시
```

**방법 2: cgroup 직접 확인**
```bash
# 메모리 제한 확인
$ docker exec user-service cat /sys/fs/cgroup/memory/memory.limit_in_bytes
1073741824  # 1GB

# 현재 사용량 확인
$ docker exec user-service cat /sys/fs/cgroup/memory/memory.usage_in_bytes
471859200  # 약 450MB
```

**방법 3: JVM이 인식한 메모리 (Java 컨테이너)**
```bash
$ docker exec user-service java -XX:+PrintFlagsFinal -version | grep MaxHeapSize
    uintx MaxHeapSize := 805306368  # 약 768MB (1GB × 75%)

# JVM은 컨테이너 메모리 제한을 올바르게 인식 (JDK 8u191+)
```

**최신 방법 (cgroup v2 또는 최신 이미지)**:
```bash
# 일부 최신 컨테이너 이미지는 제한된 메모리를 표시
$ docker exec user-service free -h
              total        used        free
Mem:           1.0G        450M        550M

# 올바르게 1GB로 표시!
```

**정리**:
- `free -h`는 호스트 메모리 표시 (오래된 이미지)
- `docker stats`가 정확 (항상 사용 권장) ✅
- JVM은 컨테이너 제한 인식 (UseContainerSupport) ✅
- 최신 이미지는 `free -h`도 정확

</details>

<details>
<summary><strong>Q3: CPU shares와 CPU limits 차이가 뭔가요? 언제 무엇을 사용해야 하나요?</strong></summary>

**A**: **CPU shares는 상대적 우선순위, CPU limits는 절대적 상한선**입니다.

**상세 설명**:

**CPU Shares (상대적 우선순위)**:
```yaml
services:
  high-priority:
    cpu_shares: 2048  # 2배 가중치

  low-priority:
    cpu_shares: 1024  # 1배 가중치 (기본)
```

**동작 방식**:
```
CPU 경합 없을 때:
- high-priority: 필요한 만큼 사용 (제한 없음)
- low-priority: 필요한 만큼 사용 (제한 없음)

CPU 경합 발생 시:
- 총 shares: 2048 + 1024 = 3072
- high-priority: 66.7% (2048 / 3072)
- low-priority: 33.3% (1024 / 3072)

예시:
호스트 CPU: 4 코어

경합 없음:
- high-priority: 3.5 코어 사용 가능 ✅
- low-priority: 0.5 코어 사용

경합 발생 (둘 다 100% 원함):
- high-priority: 2.67 코어 (66.7%)
- low-priority: 1.33 코어 (33.3%)
```

**CPU Limits (절대적 상한선)**:
```yaml
services:
  limited-service:
    cpus: 2.0  # 최대 2 CPU 코어
```

**동작 방식**:
```
언제나 최대 2.0 CPU 코어만 사용 가능

경합 없음:
- 최대 2.0 코어

경합 발생:
- 여전히 최대 2.0 코어

다른 컨테이너가 idle 상태여도:
- 최대 2.0 코어 (넘을 수 없음)
```

**비교표**:

| 특징 | CPU Shares | CPU Limits |
|------|-----------|-----------|
| 타입 | 상대적 우선순위 | 절대적 상한선 |
| 경합 없을 때 | 무제한 사용 | 제한까지만 |
| 경합 발생 시 | 가중치에 따라 분배 | 여전히 제한까지만 |
| 사용 시기 | 유연한 리소스 분배 | 명확한 상한 필요 |
| 예시 | 백그라운드 작업 | 프로덕션 서비스 |

**언제 무엇을 사용?**

**CPU Shares 사용 시**:
```yaml
# 시나리오: 백그라운드 작업과 프론트엔드 서비스

services:
  frontend:
    cpu_shares: 2048  # 높은 우선순위
    # 사용자 요청 → 빠른 응답 필요
    # idle 시: 여유 CPU 모두 사용 가능

  background-job:
    cpu_shares: 512   # 낮은 우선순위
    # 덜 중요 → 여유 있을 때만
    # frontend 바쁘면: CPU 적게 할당
```

**CPU Limits 사용 시**:
```yaml
# 시나리오: 프로덕션 서비스 (예측 가능한 성능)

services:
  api-service:
    cpus: 2.0
    # 명확한 상한선
    # 다른 서비스 영향 방지
    # 비용 예측 가능 (클라우드)
```

**둘 다 사용 (권장)**:
```yaml
services:
  api-service:
    cpus: 2.0           # 최대 2 코어
    cpu_shares: 2048    # 높은 우선순위
    # 조합: 최대 2 코어 제한 + 경합 시 높은 우선순위

  batch-job:
    cpus: 1.0           # 최대 1 코어
    cpu_shares: 512     # 낮은 우선순위
    # 조합: 최대 1 코어 제한 + 경합 시 낮은 우선순위
```

**실전 팁**:
- **프로덕션**: CPU Limits 필수 (예측 가능성)
- **개발 환경**: CPU Shares만 (유연성)
- **하이브리드**: 둘 다 사용 (최선)

</details>

<details>
<summary><strong>Q4: OOM Killer가 컨테이너를 죽이는 기준이 뭔가요? 왜 하필 제 컨테이너가 죽나요?</strong></summary>

**A**: **OOM 점수가 가장 높은 프로세스부터 종료**합니다. 메모리 사용량, 우선순위, 실행 시간 등을 고려합니다.

**상세 설명**:

**OOM Killer 동작 과정**:
```
1. 호스트 메모리 고갈 감지
2. 모든 프로세스의 OOM 점수 계산
3. 점수가 높은 프로세스 종료
4. 메모리 확보될 때까지 반복
```

**OOM 점수 계산 요소**:

```bash
# 각 프로세스의 OOM 점수 확인
$ cat /proc/<PID>/oom_score

# OOM 점수 = (메모리 사용 비율) + (oom_score_adj)

예시:
프로세스 A: 메모리 500MB 사용, oom_score_adj=0
→ OOM 점수 = 50 (메모리 5% 사용)

프로세스 B: 메모리 2GB 사용, oom_score_adj=0
→ OOM 점수 = 200 (메모리 20% 사용)

프로세스 C: 메모리 1GB 사용, oom_score_adj=500
→ OOM 점수 = 100 + 500 = 600 (조정됨)

종료 순서: C → B → A
```

**oom_score_adj 값**:
```
범위: -1000 ~ 1000

-1000: 절대 종료 안 됨 (커널 프로세스 전용, 비추천)
-500: 매우 낮은 우선순위 (마지막에 종료)
0: 기본값 (메모리 사용량에 따라)
500: 높은 우선순위 (먼저 종료)
1000: 최우선 종료
```

**실전 예시**:
```yaml
# docker-compose.yml

services:
  # 핵심 서비스 (절대 죽으면 안 됨)
  postgres:
    mem_limit: 4g
    oom_score_adj: -500  # 마지막에 종료

  # 중요 API 서비스
  api-service:
    mem_limit: 2g
    oom_score_adj: -300

  # 일반 서비스
  user-service:
    mem_limit: 1g
    oom_score_adj: 0  # 기본값

  # 덜 중요한 백그라운드 작업
  batch-job:
    mem_limit: 512m
    oom_score_adj: 500  # 먼저 종료

  # 실험적 기능
  experimental:
    mem_limit: 256m
    oom_score_adj: 800  # 최우선 종료
```

**시나리오: 호스트 메모리 부족 시**:
```
호스트 메모리: 16GB
사용 중: 15.8GB (98%)

OOM Killer 발동:

1. experimental (oom_score=800) 종료
   → 메모리 256MB 확보
   → 여전히 부족

2. batch-job (oom_score=500) 종료
   → 메모리 512MB 추가 확보
   → 충분해짐

3. 종료 멈춤
   (user-service, api-service, postgres 살아있음)
```

**왜 제 컨테이너가 죽나요?**:

**가능성 1: 메모리 많이 사용**
```bash
$ docker stats
CONTAINER         MEM USAGE / LIMIT
my-service        1.8GiB / 2GiB  # 90% 사용
other-service     500MiB / 1GiB  # 50% 사용

# my-service가 먼저 종료될 가능성 높음
```

**가능성 2: oom_score_adj 설정 안 함**
```yaml
# 현재 (기본값 0)
services:
  my-service:
    mem_limit: 2g
    # oom_score_adj 없음 → 0 (기본)

# 다른 서비스는 설정함
  important-service:
    mem_limit: 2g
    oom_score_adj: -500  # 낮은 우선순위

# 결과: my-service가 먼저 종료됨
```

**해결 방법**:

**1. 메모리 제한 여유 있게**
```yaml
services:
  my-service:
    mem_limit: 2g  # 여유 있게 설정
    mem_reservation: 1g  # 최소 보장
```

**2. 우선순위 조정**
```yaml
services:
  critical-service:
    oom_score_adj: -500  # 중요, 마지막 종료

  my-service:
    oom_score_adj: 0     # 보통

  batch-job:
    oom_score_adj: 500   # 덜 중요, 먼저 종료
```

**3. 메모리 모니터링 및 알림**
```yaml
# Prometheus Alert
- alert: HighMemoryUsage
  expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) > 0.9
  for: 5m
  annotations:
    summary: "메모리 사용률 90% 초과"
```

**4. 호스트 메모리 증설**
```bash
# 또는 클라우드 인스턴스 업그레이드
```

</details>

<details>
<summary><strong>Q5: 개발 환경과 프로덕션 환경의 리소스 설정을 어떻게 다르게 해야 하나요?</strong></summary>

**A**: **개발 환경은 편의성, 프로덕션은 안정성과 예측 가능성을 우선**합니다.

**상세 설명**:

**개발 환경 (Development)**:
```yaml
# docker-compose.dev.yml

services:
  user-service:
    build:
      context: ./user
      dockerfile: Dockerfile.dev
    volumes:
      - ./user/src:/app/src  # 코드 핫 리로드
    # 리소스 제한 없음 또는 매우 관대하게
    mem_limit: 4g  # 넉넉하게
    # CPU 제한 없음 → 빠른 빌드
    environment:
      - SPRING_PROFILES_ACTIVE=dev
      - JAVA_OPTS=-Xmx2g  # 직접 설정

  postgres:
    image: postgres:15-alpine
    # 제한 없음 → 빠른 쿼리
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # 개발 편의를 위해 포트 노출
    ports:
      - "5432:5432"
```

**프로덕션 환경 (Production)**:
```yaml
# docker-compose.prod.yml

services:
  user-service:
    image: ${REGISTRY}/user-service:${VERSION}
    # 명확한 리소스 제한
    cpus: 1.0
    mem_limit: 1g
    mem_reservation: 512m
    oom_score_adj: -300
    # 스왑 비활성화
    memswap_limit: 1g
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
    # 헬스체크 필수
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    # 재시작 정책
    restart: unless-stopped
    # 로그 제한
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  postgres:
    image: postgres:15-alpine
    cpus: 2.0
    mem_limit: 4g
    mem_reservation: 2g
    shm_size: 256m
    oom_score_adj: -500  # 매우 중요
    volumes:
      - postgres-data:/var/lib/postgresql/data
    # 포트 노출 안 함 (보안)
    # networks만으로 내부 통신
```

**스테이징 환경 (Staging)**:
```yaml
# docker-compose.staging.yml

services:
  user-service:
    # 프로덕션과 동일한 리소스 제한
    cpus: 1.0
    mem_limit: 1g
    # 프로덕션과 동일한 설정
    # (정확한 테스트를 위해)
```

**비교표**:

| 항목 | 개발 환경 | 스테이징 | 프로덕션 |
|------|----------|----------|----------|
| CPU 제한 | 없음/관대 | 프로덕션과 동일 | 명확한 제한 |
| 메모리 제한 | 관대 (4GB+) | 프로덕션과 동일 | 여유 있게 설정 |
| 스왑 | 허용 | 비활성화 | 비활성화 |
| 우선순위 | 설정 안 함 | 설정함 | 명확히 설정 |
| 헬스체크 | 선택 | 필수 | 필수 |
| 로그 제한 | 없음 | 있음 | 명확한 제한 |
| 재시작 정책 | 수동 | always | unless-stopped |
| 볼륨 마운트 | 코드 핫 리로드 | 불변 | 불변 |
| 포트 노출 | 편의상 노출 | 최소화 | 최소화 |

**실전 패턴**:

**Pattern 1: 환경별 파일 분리**
```bash
project/
├── docker-compose.yml          # 공통 설정
├── docker-compose.dev.yml      # 개발 오버라이드
├── docker-compose.staging.yml  # 스테이징
└── docker-compose.prod.yml     # 프로덕션

# 사용 방법
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up
```

**Pattern 2: 환경 변수로 제어**
```yaml
# docker-compose.yml

services:
  user-service:
    cpus: ${USER_SERVICE_CPU:-1.0}
    mem_limit: ${USER_SERVICE_MEM:-1g}

# .env.dev
USER_SERVICE_CPU=4.0
USER_SERVICE_MEM=4g

# .env.prod
USER_SERVICE_CPU=1.0
USER_SERVICE_MEM=1g
```

**Pattern 3: 프로파일 사용 (Compose v2)**
```yaml
services:
  user-service:
    profiles: ["dev"]
    mem_limit: 4g

  user-service-prod:
    profiles: ["prod"]
    mem_limit: 1g
    cpus: 1.0

# 사용
docker compose --profile dev up
docker compose --profile prod up
```

**권장 사항**:

**개발 환경**:
- 리소스 제한 없음 또는 매우 관대
- 빠른 개발 사이클 우선
- 편의성 > 효율성

**스테이징 환경**:
- **프로덕션과 완전히 동일**
- 정확한 테스트를 위해
- 프로덕션 이슈 사전 발견

**프로덕션 환경**:
- 명확한 리소스 제한 필수
- 안정성과 예측 가능성 최우선
- 모니터링 및 알림 필수
- 보안 강화

</details>

---

## 📝 면접 질문

### 주니어 레벨

**Q1: Docker 컨테이너에 리소스 제한을 설정하지 않으면 어떤 문제가 발생할 수 있나요?**

**A**: **한 컨테이너가 호스트 리소스를 독점하여 다른 컨테이너와 호스트 시스템 전체에 영향을 줄 수 있습니다.**

**상세 답변**:

**주요 문제들**:

**1. Noisy Neighbor 문제**:
```
한 컨테이너가 CPU/메모리를 독점
→ 다른 컨테이너 응답 지연/중단
→ 전체 서비스 품질 저하

예시:
- 메모리 릭 있는 컨테이너 A: 메모리 30GB 소비
- 정상 컨테이너 B, C: OOM Killed로 종료
```

**2. 예측 불가능한 성능**:
```
리소스 경합 상황에 따라 성능 들쑥날쑥

월요일 오전 (높은 트래픽):
- API 응답 시간: 5초

화요일 새벽 (낮은 트래픽):
- API 응답 시간: 0.1초

사용자 경험 일관성 없음
```

**3. OOM Killer 공포**:
```
호스트 메모리 고갈 시:
- 랜덤하게 프로세스 종료
- 중요한 컨테이너도 죽을 수 있음
- 서비스 다운타임 발생
```

**4. 비용 폭증 (클라우드 환경)**:
```
제한 없이 리소스 사용
→ 클라우드 비용 예측 불가
→ 월말에 청구서 보고 깜짝 놀람

예: AWS ECS, GCP GKE 등에서 CPU/메모리 사용량 기반 과금
```

**해결 방법**:
```yaml
services:
  user-service:
    cpus: 1.0           # CPU 제한
    mem_limit: 1g       # 메모리 제한
    mem_reservation: 512m  # 최소 보장
```

**핵심 포인트**:
- 리소스 제한 = 컨테이너 간 격리 강화
- 예측 가능한 성능과 비용
- 안정성 향상

---

**Q2: --memory 옵션으로 메모리를 512MB로 제한했는데 컨테이너가 Exit Code 137로 종료되었습니다. 무엇이 문제이고 어떻게 해결해야 하나요?**

**A**: **Exit Code 137은 OOM Killed를 의미**합니다. 컨테이너가 메모리 제한을 초과했습니다.

**상세 답변**:

**Exit Code 137 분석**:
```
Exit Code 137 = 128 + 9
- 128: 시그널에 의한 종료
- 9: SIGKILL (강제 종료)
→ OOM Killer가 프로세스를 강제 종료
```

**진단 단계**:

**Step 1: OOM Killed 확인**:
```bash
$ docker ps -a
CONTAINER ID   STATUS                     NAMES
a1b2c3d4e5f6   Exited (137) 1 minute ago  user-service

$ docker inspect user-service | jq '.[0].State.OOMKilled'
true  # OOM Killed 확인
```

**Step 2: 로그 확인**:
```bash
$ docker logs user-service --tail 50
java.lang.OutOfMemoryError: Java heap space
Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
```

**Step 3: 메모리 사용량 분석**:
```bash
$ docker stats user-service
CONTAINER      MEM USAGE / LIMIT
user-service   512MiB / 512MiB  # 100% 사용
```

**원인 파악**:

**원인 1: 메모리 제한이 너무 작음**:
```
애플리케이션 실제 필요: 800MB
설정한 제한: 512MB
→ 부족!
```

**원인 2: JVM 힙 설정 문제** (Java):
```dockerfile
# 잘못된 예
ENV JAVA_OPTS=-Xmx512m

# 컨테이너 메모리: 512MB
# JVM 힙: 512MB
# 메타스페이스, 스레드 등: 150MB
# 총 필요: 662MB → 512MB 초과! OOM!
```

**원인 3: 메모리 누수**:
```
애플리케이션에 메모리 릭
→ 시간이 지날수록 메모리 증가
→ 결국 제한 초과
```

**해결 방법**:

**해결 1: 메모리 제한 증가**:
```yaml
# docker-compose.yml
services:
  user-service:
    mem_limit: 1g  # 512m → 1g
    memswap_limit: 1g  # 스왑 비활성화
```

**해결 2: JVM 설정 최적화** (Java):
```yaml
services:
  user-service:
    mem_limit: 1g
    environment:
      # JVM이 컨테이너 메모리 인식
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
      # 1GB × 75% = 750MB (힙)
      # 나머지 250MB: 메타스페이스, 스레드 등
```

**해결 3: 메모리 누수 수정**:
```bash
# 힙 덤프 생성
docker exec user-service jmap -dump:format=b,file=/tmp/heap.hprof 1
docker cp user-service:/tmp/heap.hprof ./heap.hprof

# Eclipse MAT로 분석
# 메모리 많이 사용하는 객체 찾기
# 코드 수정
```

**예방 방법**:
```yaml
services:
  user-service:
    # 1. 여유 있는 메모리 설정
    mem_limit: 1g
    mem_reservation: 512m  # 최소 보장

    # 2. 모니터링
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]

    # 3. 알림 (Prometheus)
    # memory_usage > 90% → 알림
```

**핵심 포인트**:
- Exit Code 137 = OOM Killed
- 메모리 제한은 여유 있게 (예상 × 1.5배)
- JVM은 컨테이너 메모리의 75% 이내로 힙 설정
- 메모리 모니터링 필수

---

### 중급 레벨

**Q3: CPU shares와 CPU limits의 차이를 설명하고, 각각 어떤 상황에서 사용해야 하는지 설명하세요.**

**A**: **CPU shares는 경합 시 상대적 우선순위를 결정하고, CPU limits는 절대적 상한선을 설정합니다.**

**상세 답변**:

**CPU Shares (상대적 우선순위)**:

**개념**:
```yaml
services:
  high-priority:
    cpu_shares: 2048  # 2배 가중치

  normal:
    cpu_shares: 1024  # 1배 가중치 (기본)

  low-priority:
    cpu_shares: 512   # 0.5배 가중치
```

**동작 방식**:
```
CPU 여유 있을 때:
- 모든 컨테이너: 필요한 만큼 사용 가능
- 제한 없음

CPU 경합 발생 시:
- 총 shares: 2048 + 1024 + 512 = 3584
- high-priority: 57.1% (2048 / 3584)
- normal: 28.6% (1024 / 3584)
- low-priority: 14.3% (512 / 3584)

예시 (4 CPU 코어):
경합 시:
- high-priority: 2.28 코어
- normal: 1.14 코어
- low-priority: 0.57 코어

여유 시:
- high-priority: 3 코어 (필요한 만큼)
- normal: 0.5 코어
- low-priority: 0.5 코어
```

**CPU Limits (절대적 상한선)**:

**개념**:
```yaml
services:
  limited:
    cpus: 2.0  # 최대 2 CPU 코어
```

**동작 방식**:
```
언제든지:
- 최대 2.0 CPU 코어만 사용 가능
- 다른 컨테이너 idle 상태여도 2.0 넘을 수 없음

CPU throttling:
- 2.0 코어 초과 시도 → 스로틀링 (대기)
- CFS (Completely Fair Scheduler) 사용
```

**비교표**:

| 특징 | CPU Shares | CPU Limits |
|------|-----------|-----------|
| 타입 | 상대적 | 절대적 |
| 경합 없을 때 | 무제한 | 제한까지만 |
| 경합 발생 시 | 가중치 비율 | 여전히 제한 |
| 유연성 | 높음 | 낮음 |
| 예측 가능성 | 낮음 | 높음 |
| 사용 시기 | 백그라운드 작업 | 프로덕션 서비스 |

**언제 무엇을 사용?**

**CPU Shares 사용 시나리오**:
```yaml
# 시나리오 1: 백그라운드 작업 우선순위
services:
  web-api:
    cpu_shares: 2048  # 사용자 요청, 높은 우선순위
    # 빠른 응답 필요

  batch-processing:
    cpu_shares: 512   # 백그라운드 작업, 낮은 우선순위
    # web-api 바쁠 때: CPU 적게 할당
    # web-api idle 시: CPU 많이 사용 가능

  video-encoding:
    cpu_shares: 256   # 매우 낮은 우선순위
    # 다른 작업 방해하지 않음
```

**CPU Limits 사용 시나리오**:
```yaml
# 시나리오 2: 프로덕션 서비스 (안정성)
services:
  api-service:
    cpus: 2.0  # 명확한 상한선
    # 예측 가능한 성능
    # 다른 서비스 영향 방지
    # 클라우드 비용 예측 가능

  database:
    cpus: 4.0
    # 안정적인 성능 보장
    # 리소스 고갈 방지
```

**조합 사용 (Best Practice)**:
```yaml
services:
  critical-api:
    cpus: 2.0           # 최대 2 코어
    cpu_shares: 2048    # 높은 우선순위
    # 효과: 최대 2 코어 + 경합 시 우선권

  normal-service:
    cpus: 1.0           # 최대 1 코어
    cpu_shares: 1024    # 보통 우선순위

  background-job:
    cpus: 0.5           # 최대 0.5 코어
    cpu_shares: 512     # 낮은 우선순위
    # 효과: 최대 0.5 코어 + 경합 시 낮은 우선순위
```

**실전 예시**:

**케이스 1: E-commerce 사이트**:
```yaml
services:
  # 사용자 요청 처리
  frontend-api:
    cpus: 2.0           # 명확한 제한
    cpu_shares: 2048    # 최고 우선순위
    oom_score_adj: -500

  # 주문 처리
  order-service:
    cpus: 1.5
    cpu_shares: 1536
    oom_score_adj: -300

  # 추천 시스템 (ML)
  recommendation:
    cpus: 1.0
    cpu_shares: 1024

  # 이미지 리사이징 (백그라운드)
  image-processor:
    cpus: 0.5
    cpu_shares: 256  # 매우 낮은 우선순위
    oom_score_adj: 500
```

**케이스 2: 데이터 파이프라인**:
```yaml
services:
  # 실시간 스트리밍
  kafka-consumer:
    cpus: 2.0
    cpu_shares: 2048
    # 지연 민감 → 높은 우선순위

  # 배치 처리
  spark-job:
    cpu_shares: 1024  # limits 없음
    # 여유 있을 때 많이 사용
    # 바쁠 때 적게 사용
    # 유연한 리소스 활용
```

**권장 사항**:

**개발 환경**:
```yaml
# CPU Shares만 사용 (유연성)
services:
  dev-service:
    cpu_shares: 1024
```

**프로덕션 환경**:
```yaml
# CPU Limits + Shares 조합 (안정성 + 우선순위)
services:
  prod-service:
    cpus: 2.0
    cpu_shares: 2048
```

**핵심 포인트**:
- CPU Shares: 유연한 리소스 분배, 우선순위 관리
- CPU Limits: 명확한 상한선, 예측 가능성
- 프로덕션: 둘 다 사용 권장
- 백그라운드 작업: Shares로 낮은 우선순위
- 중요 서비스: Limits + 높은 Shares

---

**Q4: Docker 컨테이너에서 JVM 힙 메모리를 설정할 때 컨테이너 메모리 제한을 고려해야 하는 이유와 올바른 설정 방법을 설명하세요.**

**A**: **JVM 힙 외에도 메타스페이스, 스레드 스택, 네이티브 메모리 등이 필요하므로, 컨테이너 메모리보다 힙 크기를 작게 설정해야 OOM을 방지**할 수 있습니다.

**상세 답변**:

**JVM 메모리 구조 (컨테이너 환경)**:
```
컨테이너 메모리: 1GB (mem_limit: 1g)

┌─────────────────────────────────────────┐
│ 컨테이너 메모리 1GB (1024MB)            │
├─────────────────────────────────────────┤
│ 1. 힙 메모리 (Heap): 750MB (75%)        │
│    ├─ Young Generation: 250MB           │
│    └─ Old Generation: 500MB             │
├─────────────────────────────────────────┤
│ 2. 메타스페이스 (Metaspace): 128MB      │
│    (클래스 메타데이터)                  │
├─────────────────────────────────────────┤
│ 3. 스레드 스택: 100MB                   │
│    (100 threads × 1MB)                  │
├─────────────────────────────────────────┤
│ 4. 코드 캐시 (Code Cache): 32MB         │
│    (JIT 컴파일된 코드)                  │
├─────────────────────────────────────────┤
│ 5. Direct Buffer: 10MB                  │
│    (NIO 버퍼)                           │
├─────────────────────────────────────────┤
│ 6. 기타 (GC, 네이티브 라이브러리): 4MB  │
└─────────────────────────────────────────┘
총: 1024MB
```

**잘못된 설정 (OOM 발생)**:

**Case 1: 힙 크기 = 컨테이너 메모리**:
```dockerfile
# Dockerfile
FROM eclipse-temurin:21-jre

ENV JAVA_OPTS="-Xmx1g"  # 힙 1GB
# 문제: 다른 메모리 공간 없음!

# docker-compose.yml
services:
  user-service:
    mem_limit: 1g  # 컨테이너 1GB
    environment:
      - JAVA_OPTS=-Xmx1g  # 힙 1GB

# 결과:
힙: 1GB
메타스페이스: 150MB
스레드: 100MB
기타: 50MB
──────────────
총: 1.3GB → 1GB 초과! OOM Killed! (Exit 137)
```

**Case 2: 컨테이너 메모리를 인식하지 못함**:
```dockerfile
# 오래된 JVM (JDK 8u191 이전)
FROM openjdk:8u180-jre

# JVM이 호스트 메모리를 봄
# 호스트: 32GB
# JVM 힙 기본값: 32GB / 4 = 8GB
# 컨테이너 제한: 1GB
# → OOM!
```

**올바른 설정 방법**:

**방법 1: UseContainerSupport (JDK 8u191+, 권장)**:
```dockerfile
FROM eclipse-temurin:21-jre-alpine

ENV JAVA_OPTS="-XX:+UseContainerSupport \
               -XX:MaxRAMPercentage=75.0 \
               -XX:InitialRAMPercentage=50.0"

# UseContainerSupport: 컨테이너 메모리 인식
# MaxRAMPercentage=75.0: 컨테이너 메모리의 75%를 힙으로
# InitialRAMPercentage=50.0: 초기 힙은 50%

COPY app.jar /app/app.jar
CMD ["java", "-jar", "/app/app.jar"]
```

```yaml
# docker-compose.yml
services:
  user-service:
    mem_limit: 2g
    environment:
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0

# 효과:
# 컨테이너 메모리: 2GB
# JVM 힙 최대: 1.5GB (2GB × 75%)
# 나머지 0.5GB: 메타스페이스, 스레드 등
```

**방법 2: 명시적 Xmx 설정** (옛날 방식):
```dockerfile
FROM eclipse-temurin:21-jre

ENV JAVA_OPTS="-Xms512m -Xmx1536m"

# docker-compose.yml
services:
  user-service:
    mem_limit: 2g
    environment:
      - JAVA_OPTS=-Xms512m -Xmx1536m

# 계산:
# 힙: 1.5GB
# 메타스페이스: 256MB (기본)
# 스레드: 200MB (200 threads × 1MB)
# 기타: 44MB
# ───────────────
# 총: 2GB
```

**메모리 배분 가이드라인**:

| 컨테이너 메모리 | 힙 크기 (75%) | 나머지 (25%) | 비고 |
|---------------|--------------|-------------|------|
| 512MB | 384MB | 128MB | 최소 권장 |
| 1GB | 750MB | 250MB | 표준 |
| 2GB | 1.5GB | 500MB | 일반 서비스 |
| 4GB | 3GB | 1GB | 대용량 처리 |

**비율 조정 시나리오**:

**시나리오 1: 스레드 많은 경우**:
```yaml
# 스레드 많음 (500+)
services:
  thread-heavy-service:
    mem_limit: 2g
    environment:
      - JAVA_OPTS=-XX:+UseContainerSupport
                  -XX:MaxRAMPercentage=60.0  # 75% → 60%
                  -XX:ThreadStackSize=512    # 스레드 스택 512KB

# 이유: 스레드 스택에 더 많은 메모리 필요
# 힙: 1.2GB (60%)
# 스레드: 256MB (500 × 512KB)
# 나머지: 544MB
```

**시나리오 2: 메타스페이스 많은 경우** (많은 클래스):
```yaml
# 클래스 많음 (Spring Boot + 많은 의존성)
services:
  class-heavy-service:
    mem_limit: 2g
    environment:
      - JAVA_OPTS=-XX:+UseContainerSupport
                  -XX:MaxRAMPercentage=70.0
                  -XX:MaxMetaspaceSize=384m  # 명시적 제한

# 이유: 메타스페이스에 더 많은 공간
# 힙: 1.4GB (70%)
# 메타스페이스: 384MB
# 나머지: 216MB
```

**검증 방법**:

**Step 1: JVM이 인식한 메모리 확인**:
```bash
# 컨테이너 실행 후
$ docker exec user-service java -XX:+PrintFlagsFinal -version | grep -E "MaxHeapSize|MaxRAM"

MaxHeapSize := 1610612736  # 약 1.5GB
MaxRAM      := 2147483648  # 2GB

# 올바르게 인식됨!
```

**Step 2: 런타임 메모리 사용량 확인**:
```bash
$ docker stats user-service
CONTAINER      MEM USAGE / LIMIT
user-service   1.2GiB / 2GiB  # 60% 사용, 정상
```

**Step 3: JVM 메모리 상세 확인**:
```bash
$ docker exec user-service jcmd 1 VM.native_memory summary

Native Memory Tracking:

Total: reserved=2048MB, committed=1200MB
-                 Java Heap (reserved=1536MB, committed=1024MB)
-                      Code (reserved=128MB, committed=32MB)
-                    Thread (reserved=200MB, committed=100MB)
-                      GC (reserved=64MB, committed=24MB)
-                  Internal (reserved=120MB, committed=20MB)
```

**일반적인 실수와 해결**:

**실수 1: 옛날 JVM 사용**:
```dockerfile
# ❌ 잘못됨
FROM openjdk:8u180-jre  # UseContainerSupport 없음

# ✅ 올바름
FROM eclipse-temurin:8u382-jre  # UseContainerSupport 지원
FROM eclipse-temurin:11-jre
FROM eclipse-temurin:17-jre
FROM eclipse-temurin:21-jre
```

**실수 2: 퍼센트 너무 높게**:
```yaml
# ❌ 위험
services:
  user-service:
    mem_limit: 1g
    environment:
      - JAVA_OPTS=-XX:MaxRAMPercentage=95.0  # 너무 높음!

# 스레드, 메타스페이스에 공간 부족 → OOM 가능

# ✅ 안전
services:
  user-service:
    mem_limit: 1g
    environment:
      - JAVA_OPTS=-XX:MaxRAMPercentage=75.0  # 적절
```

**실수 3: 스왑 활성화**:
```yaml
# ❌ 성능 저하
services:
  user-service:
    mem_limit: 1g
    # memswap_limit 설정 안 함 → 스왑 2배 (2GB)

# 힙 사용 → 스왑 사용 → 디스크 I/O → 느림

# ✅ 스왑 비활성화
services:
  user-service:
    mem_limit: 1g
    memswap_limit: 1g  # mem_limit와 같게
```

**핵심 포인트**:
- JVM 메모리 = 힙 + 메타스페이스 + 스레드 + 기타
- 컨테이너 메모리의 75%를 힙으로 (안전)
- `UseContainerSupport` + `MaxRAMPercentage` 사용 (JDK 8u191+)
- 스왑 비활성화 (프로덕션)
- 메모리 모니터링 필수

---

**Q5: 프로덕션 환경에서 여러 마이크로서비스의 리소스 제한을 설정할 때 고려해야 할 요소와 전략을 설명하세요.**

**A**: **서비스 중요도, 리소스 특성, 의존성 관계, 모니터링, 확장성을 종합적으로 고려하여 차별화된 리소스 전략을 수립**해야 합니다.

**상세 답변**:

**1. 서비스 중요도 분류 (Criticality)**:

**Tier 1: 핵심 서비스 (Critical)**:
```yaml
services:
  # 예: 주문, 결제, 인증
  payment-service:
    cpus: 2.0
    mem_limit: 2g
    mem_reservation: 1.5g
    oom_score_adj: -500  # 마지막에 종료
    restart: always
    deploy:
      replicas: 3  # 고가용성
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.5'
          memory: 1.5G

# 특징:
# - 높은 리소스 할당
# - 낮은 OOM 우선순위 (마지막에 죽음)
# - 높은 복제본 수
# - 리소스 예약 (최소 보장)
```

**Tier 2: 중요 서비스 (Important)**:
```yaml
services:
  # 예: 사용자 관리, 상품 목록
  user-service:
    cpus: 1.0
    mem_limit: 1g
    mem_reservation: 512m
    oom_score_adj: -100
    restart: always
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

# 특징:
# - 표준 리소스 할당
# - 중간 OOM 우선순위
# - 적절한 복제본
```

**Tier 3: 보조 서비스 (Supporting)**:
```yaml
services:
  # 예: 추천, 검색 인덱싱
  recommendation:
    cpus: 0.5
    mem_limit: 512m
    cpu_shares: 512  # 낮은 우선순위
    oom_score_adj: 300
    restart: on-failure
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

# 특징:
# - 낮은 리소스
# - 낮은 CPU 우선순위
# - 높은 OOM 우선순위 (먼저 죽음)
```

**Tier 4: 백그라운드 작업 (Background)**:
```yaml
services:
  # 예: 로그 처리, 이미지 리사이징
  log-processor:
    cpus: 0.25
    mem_limit: 256m
    cpu_shares: 256  # 매우 낮은 우선순위
    oom_score_adj: 800
    restart: on-failure

# 특징:
# - 최소 리소스
# - 매우 낮은 우선순위
# - 최우선 종료 대상
```

**2. 리소스 특성별 전략**:

**CPU 집약적 서비스** (계산, 데이터 처리):
```yaml
services:
  # ML 추론, 비디오 인코딩 등
  ml-inference:
    cpus: 4.0  # 높은 CPU
    mem_limit: 2g  # 상대적으로 낮은 메모리
    cpuset: "0-3"  # 특정 코어 할당 (NUMA 최적화)
    cpu_shares: 2048
```

**메모리 집약적 서비스** (캐시, 데이터베이스):
```yaml
services:
  # Redis, PostgreSQL 등
  redis:
    cpus: 1.0  # 상대적으로 낮은 CPU
    mem_limit: 4g  # 높은 메모리
    mem_reservation: 3g
    shm_size: 256m  # 공유 메모리 (Redis, PostgreSQL)
    command: >
      redis-server
      --maxmemory 3500mb
      --maxmemory-policy allkeys-lru
```

**I/O 집약적 서비스** (로그, 파일 처리):
```yaml
services:
  file-processor:
    cpus: 0.5
    mem_limit: 512m
    device_read_bps:
      - path: /dev/sda
        rate: 50mb  # I/O 제한
    device_write_bps:
      - path: /dev/sda
        rate: 20mb
```

**3. 의존성 관계 고려**:

**상류 서비스 (Upstream)** → 더 많은 리소스:
```yaml
services:
  # API Gateway (모든 요청 받음)
  api-gateway:
    cpus: 2.0
    mem_limit: 2g
    oom_score_adj: -400  # 중요
    deploy:
      replicas: 3

  # API Gateway가 호출하는 서비스
  user-service:
    cpus: 1.0
    mem_limit: 1g
    depends_on:
      - postgres
```

**하류 서비스 (Downstream)** → 안정성 최우선:
```yaml
services:
  # 데이터베이스 (모든 서비스가 의존)
  postgres:
    cpus: 4.0
    mem_limit: 8g
    mem_reservation: 6g
    oom_score_adj: -800  # 절대 죽으면 안 됨
    shm_size: 512m
```

**4. 리소스 풀 전략**:

**호스트 리소스 분배**:
```
호스트: 16 CPU 코어, 64GB 메모리

분배 전략:
├─ 인프라 (25%): 4 CPU, 16GB
│  ├─ PostgreSQL: 3 CPU, 12GB
│  └─ Redis: 1 CPU, 4GB
│
├─ 핵심 서비스 (50%): 8 CPU, 32GB
│  ├─ Payment: 2 CPU, 8GB × 2 replicas
│  ├─ Order: 2 CPU, 8GB × 2 replicas
│  └─ Auth: 2 CPU, 8GB × 2 replicas
│
├─ 보조 서비스 (20%): 3 CPU, 12GB
│  ├─ User: 1 CPU, 4GB
│  ├─ Product: 1 CPU, 4GB
│  └─ Notification: 1 CPU, 4GB
│
└─ 백그라운드 (5%): 1 CPU, 4GB
   ├─ Log Processor: 0.5 CPU, 2GB
   └─ Image Processor: 0.5 CPU, 2GB
```

**실전 예시: E-commerce 플랫폼**:
```yaml
# docker-compose.prod.yml

version: '3.8'

x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"

services:
  # Tier 1: 핵심 인프라
  postgres:
    image: postgres:15-alpine
    cpus: 4.0
    mem_limit: 12g
    mem_reservation: 10g
    shm_size: 512m
    oom_score_adj: -800
    restart: always
    volumes:
      - postgres-data:/var/lib/postgresql/data
    logging: *default-logging

  redis:
    image: redis:7-alpine
    cpus: 2.0
    mem_limit: 4g
    mem_reservation: 3g
    oom_score_adj: -700
    restart: always
    command: >
      redis-server
      --maxmemory 3500mb
      --maxmemory-policy allkeys-lru
    logging: *default-logging

  # Tier 1: 핵심 비즈니스 로직
  payment-service:
    image: ${REGISTRY}/payment:${VERSION}
    cpus: 2.0
    mem_limit: 2g
    mem_reservation: 1.5g
    oom_score_adj: -500
    restart: always
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 40s
    logging: *default-logging

  order-service:
    image: ${REGISTRY}/order:${VERSION}
    cpus: 2.0
    mem_limit: 2g
    mem_reservation: 1.5g
    oom_score_adj: -500
    restart: always
    deploy:
      replicas: 3
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 15s
    logging: *default-logging

  # Tier 2: 중요 서비스
  user-service:
    image: ${REGISTRY}/user:${VERSION}
    cpus: 1.0
    mem_limit: 1g
    mem_reservation: 512m
    oom_score_adj: -100
    restart: always
    deploy:
      replicas: 2
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
    logging: *default-logging

  product-service:
    image: ${REGISTRY}/product:${VERSION}
    cpus: 1.0
    mem_limit: 1g
    mem_reservation: 512m
    oom_score_adj: -100
    restart: always
    deploy:
      replicas: 2
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0
    logging: *default-logging

  # Tier 3: 보조 서비스
  recommendation:
    image: ${REGISTRY}/recommendation:${VERSION}
    cpus: 0.5
    mem_limit: 512m
    cpu_shares: 512
    oom_score_adj: 300
    restart: on-failure
    deploy:
      replicas: 1
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - JAVA_OPTS=-XX:+UseContainerSupport -XX:MaxRAMPercentage=70.0
    logging: *default-logging

  search-indexer:
    image: ${REGISTRY}/search-indexer:${VERSION}
    cpus: 0.5
    mem_limit: 512m
    cpu_shares: 512
    oom_score_adj: 400
    restart: on-failure
    logging: *default-logging

  # Tier 4: 백그라운드
  log-processor:
    image: ${REGISTRY}/log-processor:${VERSION}
    cpus: 0.25
    mem_limit: 256m
    cpu_shares: 256
    oom_score_adj: 800
    restart: on-failure
    logging: *default-logging

  image-resizer:
    image: ${REGISTRY}/image-resizer:${VERSION}
    cpus: 0.5
    mem_limit: 512m
    cpu_shares: 256
    oom_score_adj: 700
    restart: on-failure
    device_write_bps:
      - path: /dev/sda
        rate: 20mb
    logging: *default-logging

  # 모니터링
  prometheus:
    image: prom/prometheus:latest
    cpus: 0.5
    mem_limit: 512m
    oom_score_adj: 0
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus

  grafana:
    image: grafana/grafana:latest
    cpus: 0.25
    mem_limit: 256m
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana

volumes:
  postgres-data:
  prometheus-data:
  grafana-data:
```

**5. 모니터링 및 조정**:

**모니터링 지표**:
```yaml
# Prometheus alerts
groups:
  - name: resource_alerts
    rules:
      # CPU 사용률 80% 이상
      - alert: HighCPU
        expr: rate(container_cpu_usage_seconds_total[5m]) * 100 > 80
        for: 10m

      # 메모리 사용률 90% 이상
      - alert: HighMemory
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 90
        for: 5m

      # OOM 발생
      - alert: OOMKilled
        expr: container_oom_kill_total > 0
        annotations:
          summary: "컨테이너 OOM Killed"
```

**정기적 검토 및 조정**:
```bash
# 주간 리소스 리포트
$ ./scripts/weekly-resource-report.sh

서비스별 리소스 사용률 (지난 7일):

payment-service:
  평균 CPU: 65% (1.3/2.0)
  최대 CPU: 95% (1.9/2.0)
  평균 메모리: 1.2GB (60%)
  → 조치: CPU 제한 2.5로 증가 권장

user-service:
  평균 CPU: 20% (0.2/1.0)
  최대 CPU: 45% (0.45/1.0)
  평균 메모리: 400MB (40%)
  → 조치: 리소스 여유 있음, 현상 유지
```

**핵심 포인트**:
- 서비스 중요도별 차별화 (Tier 1-4)
- 리소스 특성 고려 (CPU/메모리/I/O 집약)
- 의존성 관계 고려 (상류/하류)
- 전체 리소스 풀 관리 (100% 활용)
- 지속적인 모니터링 및 조정
- 확장 계획 (스케일 업/아웃)

---

## 다음 단계

### 25. 컨테이너 성능 모니터링
- docker stats 활용
- cAdvisor 설치
- Prometheus + Grafana 연동

### 학습 자료

**리소스 관리**:
- [Docker Resource Constraints](https://docs.docker.com/config/containers/resource_constraints/)
- [cgroups Documentation](https://www.kernel.org/doc/Documentation/cgroup-v1/)

**JVM 최적화**:
- [JVM Container Support](https://www.eclipse.org/openj9/docs/xxusecontainersupport/)
- [Java in Containers](https://developers.redhat.com/articles/2022/04/19/best-practices-java-single-core-containers)

**모니터링**:
- [cAdvisor](https://github.com/google/cadvisor)
- [Prometheus](https://prometheus.io/docs/introduction/overview/)

---

**축하합니다!** Docker 리소스 제한과 관리를 마스터했습니다!
