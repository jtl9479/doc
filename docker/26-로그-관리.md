# 섹션 26: 로그 관리

## 비유로 시작하기

로그 관리는 **블랙박스 녹화**와 같습니다.

```
자동차 블랙박스                      Docker 로그 관리
================                      ==================
📹 전방 카메라                   →    stdout/stderr 로그
📹 후방 카메라                   →    애플리케이션 로그
💾 SD 카드 저장                  →    로그 드라이버
🔄 용량 꽉 차면 덮어쓰기         →    로그 로테이션
📂 사고 시 영상 분석             →    ELK로 로그 분석
🚨 충격 감지 시 자동 저장        →    에러 로그 자동 수집
```

블랙박스가 없으면 사고 원인을 알 수 없듯이, 로그 관리가 없으면 시스템 장애 원인을 찾을 수 없습니다.

---

## 왜 로그 관리가 중요한가?

### 1. 로그 관리의 필요성

```
문제 발생 시나리오
==================

❌ 로그 관리 없을 때:
------------------
사용자: "주문이 안 돼요!"
개발자: "언제요? 어떤 에러였나요?"
사용자: "아까요... 잘 모르겠어요..."
개발자: "로그가 없어서 확인 불가능..."
    ↓
원인 파악 불가 😱


✅ 로그 관리 있을 때:
------------------
사용자: "주문이 안 돼요!"
개발자: "확인해보겠습니다."
    ↓
1. Kibana에서 사용자 ID로 검색
2. 13:24:15에 "Insufficient balance" 에러 발견
3. 계좌 잔액 부족이 원인임을 즉시 파악
4. 사용자에게 "잔액 부족입니다" 안내
    ↓
5분 만에 문제 해결! 😊
```

### 2. 로그 관리가 해결하는 문제

| 문제 | 로그 관리 없이 | 로그 관리로 |
|------|--------------|-----------|
| 🐛 버그 추적 | "재현 안 돼요..." | 정확한 에러 스택 확인 |
| ⚡ 성능 이슈 | "느린 것 같아요..." | 정확한 응답 시간 측정 |
| 🔒 보안 사고 | "누가 해킹했나?" | 접근 기록 전체 추적 |
| 📊 사용 통계 | "얼마나 쓰나요?" | 정확한 사용량 분석 |
| 🚨 장애 대응 | "언제 죽었어요?" | 정확한 장애 시간 파악 |

---

## Docker 로그의 기본 이해

### 1. Docker 로그 수집 메커니즘

```
Container 내부                         Docker Daemon                    로그 저장소
==============                         ==============                   ===========

Application
    |
    | stdout (System.out)
    ├──────────────────────>
    |                                  Log Driver
    | stderr (System.err)              (json-file,
    └──────────────────────>           syslog, etc.)
                                           |
                                           | 포맷 변환
                                           | 버퍼링
                                           ↓
                                       로그 파일
                                       (/var/lib/docker/containers/
                                        <container-id>/<container-id>-json.log)
                                           |
                                           | (옵션) 원격 전송
                                           ↓
                                       Elasticsearch
                                       Fluentd
                                       Splunk
                                       등등...
```

### 2. 로그 드라이버 종류

Docker는 다양한 로그 드라이버를 지원합니다:

| 드라이버 | 설명 | 사용 시나리오 |
|---------|------|-------------|
| **json-file** | JSON 형식 로컬 파일 (기본값) | 개발 환경, 소규모 운영 |
| **journald** | systemd 저널에 전송 | Linux systemd 환경 |
| **syslog** | Syslog 서버로 전송 | 기존 syslog 인프라 활용 |
| **fluentd** | Fluentd로 전송 | 대규모 로그 수집 |
| **gelf** | Graylog로 전송 | Graylog 사용 시 |
| **awslogs** | AWS CloudWatch로 전송 | AWS 환경 |
| **gcplogs** | Google Cloud Logging | GCP 환경 |
| **splunk** | Splunk로 전송 | Splunk 사용 기업 |
| **none** | 로그 수집 안 함 | 로그 불필요한 컨테이너 |

---

## 로그 드라이버 설정

### 1. json-file 드라이버 (기본값)

가장 많이 사용되는 드라이버입니다.

#### docker-compose.yml 설정

```yaml
# docker-compose.yml
version: '3.8'

services:
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "json-file"
      options:
        max-size: "10m"        # 로그 파일 최대 크기
        max-file: "3"          # 로그 파일 최대 개수
        labels: "service=user" # 메타데이터 추가
        env: "ENVIRONMENT"     # 환경변수 포함
```

#### 동작 방식

```
로그 파일 로테이션
==================

user-service-json.log          (10MB 도달)
    ↓
user-service-json.log.1        (이름 변경)
user-service-json.log          (새 파일 생성)
    ↓
user-service-json.log.2        (이름 변경)
user-service-json.log.1        (이름 변경)
user-service-json.log          (새 파일 생성)
    ↓
user-service-json.log.2        (삭제, max-file=3 초과)
user-service-json.log.1        (이름 변경)
user-service-json.log          (새 파일 생성)
```

#### 로그 파일 위치

```bash
# 컨테이너 로그 파일 위치 확인
docker inspect --format='{{.LogPath}}' user-service

# 출력 예시:
# /var/lib/docker/containers/abc123.../abc123...-json.log

# 로그 파일 직접 보기 (Linux/Mac)
sudo tail -f /var/lib/docker/containers/abc123.../abc123...-json.log

# 로그 파일 내용 예시
{"log":"2025-09-30 10:15:32.123 INFO  [main] Application started\n","stream":"stdout","time":"2025-09-30T01:15:32.123456789Z"}
{"log":"2025-09-30 10:15:33.456 ERROR [http-nio-8080-exec-1] Connection refused\n","stream":"stderr","time":"2025-09-30T01:15:33.456789012Z"}
```

### 2. syslog 드라이버

기존 syslog 인프라가 있을 때 유용합니다.

```yaml
# docker-compose.yml
services:
  trade-service:
    image: lk-trade/trade-service:latest
    logging:
      driver: "syslog"
      options:
        syslog-address: "tcp://syslog-server:514"
        syslog-facility: "daemon"
        tag: "{{.Name}}/{{.ID}}"
```

### 3. fluentd 드라이버 (권장 - 대규모 환경)

Fluentd는 강력한 로그 수집기입니다.

```yaml
# docker-compose.yml
services:
  # Fluentd 컨테이너
  fluentd:
    image: fluent/fluentd:v1.16-1
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    volumes:
      - ./fluentd/conf:/fluentd/etc
      - ./fluentd/logs:/fluentd/log
    networks:
      - lk-trade-network

  # 애플리케이션 컨테이너
  user-service:
    image: lk-trade/user-service:latest
    logging:
      driver: "fluentd"
      options:
        fluentd-address: "localhost:24224"
        tag: "lk-trade.user-service"
        fluentd-async: "true"      # 비동기 전송
        fluentd-buffer-limit: "1m" # 버퍼 크기
    depends_on:
      - fluentd
    networks:
      - lk-trade-network
```

#### Fluentd 설정 파일

```ruby
# fluentd/conf/fluent.conf

# 입력: Docker 컨테이너로부터 로그 수신
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# 필터: JSON 파싱
<filter lk-trade.**>
  @type parser
  key_name log
  <parse>
    @type json
  </parse>
</filter>

# 필터: 로그 레벨 추출
<filter lk-trade.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    level ${record["level"] || "INFO"}
  </record>
</filter>

# 출력 1: Elasticsearch로 전송
<match lk-trade.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix lk-trade
  <buffer>
    @type file
    path /fluentd/log/buffer
    flush_interval 10s
  </buffer>
</match>

# 출력 2: 파일로도 백업 저장
<match lk-trade.**>
  @type copy
  <store>
    @type file
    path /fluentd/log/${tag}/%Y%m%d
    <buffer tag,time>
      timekey 1d
      timekey_wait 10m
    </buffer>
  </store>
</match>
```

---

## ELK Stack으로 로그 수집하기

ELK = **E**lasticsearch + **L**ogstash + **K**ibana

```
전체 아키텍처
=============

Docker Containers                     Filebeat                  Logstash                Elasticsearch         Kibana
=================                     ========                  ========                =============         ======

[user-service]
   stdout/stderr  ────┐
                      │
[trade-service]       ├───> Filebeat ───> Logstash ───> Elasticsearch ───> Kibana
   stdout/stderr  ────┤      (수집)        (가공)         (저장)           (시각화)
                      │
[account-service]     │
   stdout/stderr  ────┘

각 역할:
- Filebeat: 로그 파일을 실시간으로 읽어서 Logstash로 전송
- Logstash: 로그를 파싱하고 필터링하여 구조화
- Elasticsearch: 로그를 색인하고 저장
- Kibana: 로그를 검색하고 시각화
```

### 1. ELK Stack docker-compose 구성

```yaml
# docker-compose.elk.yml
version: '3.8'

services:
  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"  # JVM 힙 크기
      - xpack.security.enabled=false   # 개발 환경에서는 보안 비활성화
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - elk-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"  # Filebeat 입력
      - "9600:9600"  # Logstash API
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
    networks:
      - elk-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  # Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - elk-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  # Filebeat
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: filebeat
    user: root  # Docker 소켓 접근 권한 필요
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data:/usr/share/filebeat/data
    command: filebeat -e -strict.perms=false
    networks:
      - elk-network
    depends_on:
      - logstash

volumes:
  elasticsearch-data:
    driver: local
  filebeat-data:
    driver: local

networks:
  elk-network:
    driver: bridge
```

### 2. Filebeat 설정

Filebeat는 Docker 컨테이너의 로그를 수집합니다.

```yaml
# filebeat/filebeat.yml
filebeat.inputs:
  # Docker 컨테이너 로그 자동 수집
  - type: container
    enabled: true
    paths:
      - '/var/lib/docker/containers/*/*.log'

    # JSON 로그 파싱
    json.keys_under_root: true
    json.add_error_key: true
    json.message_key: log

    # Docker 메타데이터 추가
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"

      - decode_json_fields:
          fields: ["message"]
          target: ""
          overwrite_keys: true

      # 불필요한 필드 제거
      - drop_fields:
          fields: ["agent", "ecs", "host", "input"]

# Logstash로 출력
output.logstash:
  hosts: ["logstash:5044"]

# 로그 레벨 설정
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

### 3. Logstash 파이프라인 설정

Logstash는 로그를 파싱하고 가공합니다.

```ruby
# logstash/pipeline/logstash.conf

input {
  beats {
    port => 5044
  }
}

filter {
  # Docker 컨테이너 로그 필터
  if [container] {
    # 컨테이너 이름에서 서비스 이름 추출
    grok {
      match => {
        "[container][name]" => "^/?(%{DATA:service_name})[-_]"
      }
    }

    # Spring Boot 로그 파싱
    if [service_name] =~ /user|trade|account|strategy/ {
      grok {
        match => {
          "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} +\[%{DATA:thread}\] %{DATA:logger} : %{GREEDYDATA:log_message}"
        }
      }

      # 타임스탬프 파싱
      date {
        match => ["timestamp", "ISO8601"]
        target => "@timestamp"
      }
    }

    # 에러 로그 태그 추가
    if [log_level] == "ERROR" or [log_level] == "FATAL" {
      mutate {
        add_tag => ["error"]
      }
    }

    # 성능 관련 로그 태그
    if [message] =~ /took \d+ms/ or [message] =~ /response time/ {
      grok {
        match => {
          "message" => "took %{NUMBER:response_time_ms:int}ms"
        }
      }
      mutate {
        add_tag => ["performance"]
      }
    }
  }

  # 불필요한 필드 제거
  mutate {
    remove_field => ["agent", "ecs", "input", "host"]
  }
}

output {
  # Elasticsearch로 출력
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "lk-trade-%{+YYYY.MM.dd}"

    # 템플릿 설정
    template_name => "lk-trade"
    template_pattern => "lk-trade-*"
  }

  # 디버깅용 stdout (개발 환경에서만)
  stdout {
    codec => rubydebug
  }
}
```

### 4. 애플리케이션의 구조화된 로그 출력

Spring Boot 애플리케이션에서 JSON 형식으로 로그를 출력하면 파싱이 쉬워집니다.

#### Logback 설정 (JSON 로그)

```xml
<!-- src/main/resources/logback-spring.xml -->
<configuration>
    <springProperty scope="context" name="serviceName" source="spring.application.name"/>

    <!-- JSON Encoder 의존성 필요: net.logstash.logback:logstash-logback-encoder -->
    <appender name="JSON" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>{"service":"${serviceName}"}</customFields>
            <fieldNames>
                <timestamp>timestamp</timestamp>
                <message>message</message>
                <logger>logger</logger>
                <thread>thread</thread>
                <level>level</level>
                <stackTrace>stack_trace</stackTrace>
            </fieldNames>
        </encoder>
    </appender>

    <root level="INFO">
        <appender-ref ref="JSON"/>
    </root>
</configuration>
```

#### Gradle 의존성 추가

```kotlin
// build.gradle.kts
dependencies {
    // JSON 로그 출력
    implementation("net.logstash.logback:logstash-logback-encoder:7.4")
}
```

#### 로그 출력 예시

```kotlin
// UserService.kt
import org.slf4j.LoggerFactory
import org.slf4j.MDC

class UserService {
    private val logger = LoggerFactory.getLogger(UserService::class.java)

    fun createUser(request: CreateUserRequest): User {
        // MDC로 추적 ID 추가 (전체 요청에서 추적 가능)
        MDC.put("userId", request.email)
        MDC.put("requestId", UUID.randomUUID().toString())

        try {
            logger.info("Creating user: {}", request.email)

            val user = userRepository.save(User(email = request.email))

            logger.info("User created successfully: {}", user.id)
            return user

        } catch (e: Exception) {
            logger.error("Failed to create user: {}", request.email, e)
            throw e
        } finally {
            MDC.clear()
        }
    }
}
```

#### JSON 로그 출력 예시

```json
{
  "timestamp": "2025-09-30T10:15:32.123+09:00",
  "level": "INFO",
  "thread": "http-nio-8080-exec-1",
  "logger": "com.lk.trade.user.service.UserService",
  "message": "Creating user: test@example.com",
  "service": "user-service",
  "userId": "test@example.com",
  "requestId": "abc-123-def-456"
}
```

---

## Kibana에서 로그 검색과 시각화

### 1. Kibana 접속 및 Index Pattern 설정

```bash
# Kibana 접속
http://localhost:5601

# 최초 접속 시 Index Pattern 생성
1. Management > Stack Management > Index Patterns
2. "Create index pattern" 클릭
3. Index pattern name: lk-trade-*
4. Time field: @timestamp
5. "Create index pattern" 클릭
```

### 2. 기본 로그 검색

```
Kibana Discover 화면
====================

검색 쿼리 예시:

1. 특정 서비스 로그 검색
   service_name: "user-service"

2. 에러 로그만 검색
   log_level: "ERROR"

3. 특정 사용자 관련 로그
   userId: "test@example.com"

4. 특정 시간대 로그
   @timestamp: [2025-09-30T00:00:00 TO 2025-09-30T23:59:59]

5. 복합 조건 (AND, OR)
   service_name: "trade-service" AND log_level: "ERROR"

6. 응답 시간이 느린 요청
   response_time_ms: >1000

7. 특정 메시지 포함
   message: *"Connection refused"*
```

### 3. 시각화 대시보드 구성

Kibana에서 유용한 시각화:

#### 로그 레벨별 분포 (Pie Chart)

```
Visualization Type: Pie Chart
Metrics: Count
Buckets:
  - Split slices
  - Aggregation: Terms
  - Field: log_level.keyword
  - Size: 10
```

#### 시간대별 에러 발생 추이 (Line Chart)

```
Visualization Type: Line Chart
Metrics: Count
Buckets:
  - X-Axis
  - Aggregation: Date Histogram
  - Field: @timestamp
  - Interval: Auto

Filters: log_level: "ERROR"
```

#### 서비스별 로그 양 (Bar Chart)

```
Visualization Type: Bar Chart (Vertical)
Metrics: Count
Buckets:
  - X-Axis
  - Aggregation: Terms
  - Field: service_name.keyword
  - Order By: metric: Count
  - Order: Descending
  - Size: 10
```

#### 응답 시간 분포 (Histogram)

```
Visualization Type: Histogram
Metrics: Average response_time_ms
Buckets:
  - X-Axis
  - Aggregation: Histogram
  - Field: response_time_ms
  - Interval: 100
```

### 4. 대시보드 구성 예시

```
LK-Trade 로그 모니터링 대시보드
====================================

┌─────────────────────────────────────────────────────────────┐
│  시간 범위: Last 24 hours                  🔄 Auto-refresh  │
└─────────────────────────────────────────────────────────────┘

┌──────────────────┬──────────────────┬──────────────────────┐
│  총 로그 수      │  에러 수         │  평균 응답 시간      │
│  1,234,567       │  42 (0.003%)     │  123ms               │
└──────────────────┴──────────────────┴──────────────────────┘

┌─────────────────────────────┬─────────────────────────────┐
│  시간대별 로그 발생량       │  서비스별 로그 분포         │
│  [Line Chart]               │  [Pie Chart]                │
│                             │  - user-service: 35%        │
│     ╱╲                      │  - trade-service: 28%       │
│    ╱  ╲      ╱╲            │  - account-service: 20%     │
│   ╱    ╲    ╱  ╲           │  - strategy-service: 17%    │
│  ╱      ╲  ╱    ╲          │                             │
└─────────────────────────────┴─────────────────────────────┘

┌─────────────────────────────┬─────────────────────────────┐
│  에러 로그 추이             │  응답 시간 분포             │
│  [Area Chart]               │  [Histogram]                │
│                             │                             │
│      ╱╲                     │      ┃                      │
│     ╱  ╲╱╲                  │      ┃                      │
│    ╱       ╲╱╲              │  ┃   ┃                      │
│   ╱            ╲            │  ┃   ┃  ┃                   │
└─────────────────────────────┴─────────────────────────────┘

┌───────────────────────────────────────────────────────────┐
│  최근 에러 로그 (실시간)                                  │
├───────────────────────────────────────────────────────────┤
│  [10:15:32] user-service | ERROR | Connection refused     │
│  [10:14:28] trade-service | ERROR | Insufficient balance │
│  [10:13:45] account-service | ERROR | API rate limit     │
└───────────────────────────────────────────────────────────┘
```

---

## 로그 관리 모범 사례

### 1. 로그 레벨 전략

```kotlin
// ❌ 나쁜 예
logger.info("User: $user, Password: ${user.password}, Request: $request")
// 문제: 민감 정보 노출, 너무 상세

logger.debug("Step 1")
logger.debug("Step 2")
logger.debug("Step 3")
// 문제: 의미 없는 로그

logger.error("Error occurred")
// 문제: 구체적인 정보 없음


// ✅ 좋은 예
// INFO: 비즈니스 중요 이벤트
logger.info("User registered successfully",
    kv("userId", user.id),
    kv("email", user.email.maskEmail())  // 이메일 마스킹
)

// DEBUG: 디버깅에 필요한 상세 정보
logger.debug("Processing order",
    kv("orderId", order.id),
    kv("items", order.items.size),
    kv("totalAmount", order.totalAmount)
)

// ERROR: 예외 상황, 스택 트레이스 포함
logger.error("Failed to process payment",
    kv("orderId", order.id),
    kv("errorCode", errorCode),
    e  // Exception 객체
)
```

### 2. 로그 레벨 가이드라인

| 레벨 | 용도 | 예시 |
|-----|------|-----|
| **TRACE** | 매우 상세한 디버그 정보 | "Entering method", "Loop iteration 5" |
| **DEBUG** | 디버깅에 필요한 정보 | "Query: SELECT * FROM users WHERE...", "Cache hit" |
| **INFO** | 중요 비즈니스 이벤트 | "User login successful", "Order created" |
| **WARN** | 잠재적 문제 상황 | "API rate limit 80% reached", "Retrying connection" |
| **ERROR** | 에러 발생, 복구 가능 | "Payment failed", "External API timeout" |
| **FATAL** | 치명적 오류, 복구 불가 | "Database connection lost", "Out of memory" |

### 3. 구조화된 로깅 (Structured Logging)

```kotlin
// ❌ 비구조화된 로그 (파싱 어려움)
logger.info("User test@example.com created order #12345 with amount $99.99")

// ✅ 구조화된 로그 (검색 쉬움)
logger.info("Order created",
    kv("userId", user.id),
    kv("userEmail", user.email),
    kv("orderId", order.id),
    kv("amount", order.amount),
    kv("currency", "USD")
)

// JSON 출력 예시:
// {
//   "message": "Order created",
//   "userId": 123,
//   "userEmail": "test@example.com",
//   "orderId": 12345,
//   "amount": 99.99,
//   "currency": "USD"
// }
```

### 4. 상관 관계 추적 (Correlation ID)

요청 전체를 추적하기 위한 상관 ID 사용:

```kotlin
// Spring Boot Interceptor
@Component
class CorrelationIdInterceptor : HandlerInterceptor {
    companion object {
        const val CORRELATION_ID_HEADER = "X-Correlation-ID"
        const val CORRELATION_ID_MDC_KEY = "correlationId"
    }

    override fun preHandle(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any
    ): Boolean {
        // 헤더에서 Correlation ID 가져오기 or 새로 생성
        val correlationId = request.getHeader(CORRELATION_ID_HEADER)
            ?: UUID.randomUUID().toString()

        // MDC에 저장 (모든 로그에 자동 포함됨)
        MDC.put(CORRELATION_ID_MDC_KEY, correlationId)

        // 응답 헤더에도 추가
        response.setHeader(CORRELATION_ID_HEADER, correlationId)

        return true
    }

    override fun afterCompletion(
        request: HttpServletRequest,
        response: HttpServletResponse,
        handler: Any,
        ex: Exception?
    ) {
        // 요청 완료 후 MDC 정리
        MDC.clear()
    }
}

// 사용 예시
class OrderService {
    private val logger = LoggerFactory.getLogger(OrderService::class.java)

    fun createOrder(request: CreateOrderRequest): Order {
        // correlationId는 자동으로 모든 로그에 포함됨
        logger.info("Creating order for user {}", request.userId)

        // 다른 서비스 호출 시에도 Correlation ID 전달
        val user = userClient.getUser(request.userId)

        logger.info("Order created successfully")
        return order
    }
}

// Feign Client에서 Correlation ID 전달
@Component
class CorrelationIdFeignInterceptor : RequestInterceptor {
    override fun apply(template: RequestTemplate) {
        val correlationId = MDC.get(CorrelationIdInterceptor.CORRELATION_ID_MDC_KEY)
        if (correlationId != null) {
            template.header(
                CorrelationIdInterceptor.CORRELATION_ID_HEADER,
                correlationId
            )
        }
    }
}
```

이렇게 하면 Kibana에서 `correlationId`로 검색하여 전체 요청 흐름을 추적할 수 있습니다:

```
Kibana 검색:
correlationId: "abc-123-def-456"

결과:
┌──────────────────────────────────────────────────────────────┐
│ 10:15:32.123 | user-service     | Authenticating user       │
│ 10:15:32.234 | user-service     | User authenticated        │
│ 10:15:32.345 | account-service  | Fetching account balance  │
│ 10:15:32.456 | account-service  | Balance: $1,000           │
│ 10:15:32.567 | trade-service    | Creating order            │
│ 10:15:32.678 | trade-service    | Order created: #12345     │
│ 10:15:32.789 | notification     | Sending email             │
└──────────────────────────────────────────────────────────────┘
```

### 5. 민감 정보 보호

```kotlin
// 이메일 마스킹
fun String.maskEmail(): String {
    val parts = this.split("@")
    if (parts.size != 2) return "***"
    val local = parts[0]
    val domain = parts[1]
    val masked = local.take(2) + "*".repeat(local.length - 2)
    return "$masked@$domain"
}

// 전화번호 마스킹
fun String.maskPhone(): String {
    return this.replaceRange(4, this.length - 4, "*".repeat(this.length - 8))
}

// 카드 번호 마스킹
fun String.maskCardNumber(): String {
    return this.replaceRange(4, 12, "****-****")
}

// 사용 예시
logger.info("User registered",
    kv("email", user.email.maskEmail()),  // te**@example.com
    kv("phone", user.phone.maskPhone())   // 010-****-5678
)
```

---

## LK-Trade 프로젝트에 적용하기

### 1. 전체 docker-compose 통합

```yaml
# docker-compose.yml (전체 통합 버전)
version: '3.8'

services:
  # ========================================
  # ELK Stack
  # ========================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: lk-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - lk-trade-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: lk-logstash
    volumes:
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5044:5044"
      - "9600:9600"
    environment:
      - "LS_JAVA_OPTS=-Xmx1g -Xms1g"
    networks:
      - lk-trade-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: lk-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - lk-trade-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: lk-filebeat
    user: root
    volumes:
      - ./elk/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data:/usr/share/filebeat/data
    command: filebeat -e -strict.perms=false
    networks:
      - lk-trade-network
    depends_on:
      - logstash

  # ========================================
  # Application Services (로그 설정 포함)
  # ========================================
  user-service:
    build:
      context: ./modules/user/api
      dockerfile: Dockerfile
    container_name: lk-user-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=user"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/lk_trade
    ports:
      - "8081:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres
      - redis

  trade-service:
    build:
      context: ./modules/trade/api
      dockerfile: Dockerfile
    container_name: lk-trade-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=trade"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8082:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres
      - redis

  account-service:
    build:
      context: ./modules/account/api
      dockerfile: Dockerfile
    container_name: lk-account-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=account"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8083:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres

  strategy-service:
    build:
      context: ./modules/strategy/api
      dockerfile: Dockerfile
    container_name: lk-strategy-service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=strategy"
    environment:
      - SPRING_PROFILES_ACTIVE=prod
    ports:
      - "8084:8080"
    networks:
      - lk-trade-network
    depends_on:
      - postgres

  # ========================================
  # Infrastructure
  # ========================================
  postgres:
    image: postgres:16-alpine
    container_name: lk-postgres
    environment:
      - POSTGRES_DB=lk_trade
      - POSTGRES_USER=lk_admin
      - POSTGRES_PASSWORD=secure_password
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - lk-trade-network

  redis:
    image: redis:7-alpine
    container_name: lk-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - lk-trade-network

volumes:
  elasticsearch-data:
  filebeat-data:
  postgres-data:
  redis-data:

networks:
  lk-trade-network:
    driver: bridge
```

### 2. 디렉토리 구조

```
C:\trade\backend1\
├── elk/
│   ├── filebeat/
│   │   └── filebeat.yml
│   └── logstash/
│       ├── config/
│       │   └── logstash.yml
│       └── pipeline/
│           └── logstash.conf
├── modules/
│   ├── user/api/
│   │   └── src/main/resources/
│   │       └── logback-spring.xml
│   ├── trade/api/
│   │   └── src/main/resources/
│   │       └── logback-spring.xml
│   └── ...
└── scripts/
    ├── start-elk.sh
    └── stop-elk.sh
```

### 3. 시작/중지 스크립트

```bash
#!/bin/bash
# scripts/start-elk.sh

echo "🚀 Starting ELK Stack..."

# Elasticsearch 시작
docker-compose up -d elasticsearch
echo "⏳ Waiting for Elasticsearch to be healthy..."
until docker exec lk-elasticsearch curl -s http://localhost:9200 > /dev/null; do
    sleep 5
done
echo "✅ Elasticsearch is ready"

# Logstash 시작
docker-compose up -d logstash
echo "⏳ Waiting for Logstash..."
sleep 30
echo "✅ Logstash is ready"

# Kibana 시작
docker-compose up -d kibana
echo "⏳ Waiting for Kibana..."
sleep 30
echo "✅ Kibana is ready"

# Filebeat 시작
docker-compose up -d filebeat
echo "✅ Filebeat is ready"

echo "
========================================
ELK Stack started successfully! 🎉
========================================

📊 Kibana: http://localhost:5601
🔍 Elasticsearch: http://localhost:9200
📝 Logstash: http://localhost:9600

Next steps:
1. Open Kibana: http://localhost:5601
2. Create index pattern: lk-trade-*
3. Start exploring logs in Discover
========================================
"
```

```bash
#!/bin/bash
# scripts/stop-elk.sh

echo "🛑 Stopping ELK Stack..."

docker-compose stop filebeat
docker-compose stop kibana
docker-compose stop logstash
docker-compose stop elasticsearch

echo "✅ ELK Stack stopped"
```

### 4. Makefile 통합

```makefile
# Makefile
.PHONY: elk-start elk-stop elk-logs elk-status logs-view logs-search

# ELK Stack 관리
elk-start:
	@echo "🚀 Starting ELK Stack..."
	@bash scripts/start-elk.sh

elk-stop:
	@echo "🛑 Stopping ELK Stack..."
	@bash scripts/stop-elk.sh

elk-logs:
	@docker-compose logs -f elasticsearch logstash kibana filebeat

elk-status:
	@echo "📊 Elasticsearch:"
	@curl -s http://localhost:9200 | jq
	@echo "\n📝 Logstash:"
	@curl -s http://localhost:9600 | jq
	@echo "\n🔍 Kibana:"
	@curl -s http://localhost:5601/api/status | jq

# 로그 조회
logs-view:
	@echo "Select service:"
	@echo "1) user-service"
	@echo "2) trade-service"
	@echo "3) account-service"
	@echo "4) strategy-service"
	@echo "5) all services"
	@read -p "Enter number: " choice; \
	case $$choice in \
		1) docker-compose logs -f user-service ;; \
		2) docker-compose logs -f trade-service ;; \
		3) docker-compose logs -f account-service ;; \
		4) docker-compose logs -f strategy-service ;; \
		5) docker-compose logs -f ;; \
		*) echo "Invalid choice" ;; \
	esac

# Kibana에서 최근 에러 검색
logs-search-errors:
	@echo "🔍 Searching for recent errors in Kibana..."
	@curl -s -X GET "http://localhost:9200/lk-trade-*/_search" \
		-H 'Content-Type: application/json' \
		-d '{"query":{"match":{"log_level":"ERROR"}},"size":10,"sort":[{"@timestamp":{"order":"desc"}}]}' \
		| jq '.hits.hits[]._source | {time: .timestamp, service: .service_name, message: .message}'
```

---

## 트러블슈팅

### 문제 1: Filebeat가 로그를 수집하지 못함

```bash
# 증상
Kibana에 로그가 나타나지 않음

# 원인 확인
docker logs lk-filebeat

# 일반적인 원인:
# 1. Docker 소켓 권한 문제
# 2. 로그 경로 마운트 오류
# 3. Logstash 연결 실패

# 해결책 1: 권한 확인
docker exec lk-filebeat ls -la /var/run/docker.sock
# 출력: srw-rw---- 1 root docker 0 Sep 30 10:00 /var/run/docker.sock

# 해결책 2: Logstash 연결 확인
docker exec lk-filebeat cat /usr/share/filebeat/filebeat.yml | grep logstash
# output.logstash.hosts가 올바른지 확인

# 해결책 3: Filebeat 재시작
docker-compose restart filebeat
```

### 문제 2: Logstash가 로그를 파싱하지 못함

```bash
# 증상
Elasticsearch에 로그가 저장되지만 필드가 파싱되지 않음

# 원인 확인
docker logs lk-logstash

# 일반적인 원인:
# - grok 패턴 오류
# - JSON 파싱 실패

# 해결책: Logstash 파이프라인 테스트
docker exec -it lk-logstash bash

# 샘플 로그로 테스트
echo '{"log":"2025-09-30 10:15:32.123 INFO [main] Application started\n","stream":"stdout"}' \
  | /usr/share/logstash/bin/logstash -f /usr/share/logstash/pipeline/logstash.conf --config.test_and_exit

# 출력에서 파싱 결과 확인
```

### 문제 3: Elasticsearch 디스크 공간 부족

```bash
# 증상
Elasticsearch가 read-only 모드로 전환

# 확인
curl -X GET "http://localhost:9200/_cluster/health?pretty"

# 해결책 1: 오래된 인덱스 삭제
# 30일 이전 인덱스 삭제
curl -X DELETE "http://localhost:9200/lk-trade-2025.08.*"

# 해결책 2: Index Lifecycle Management (ILM) 설정
curl -X PUT "http://localhost:9200/_ilm/policy/lk-trade-policy" -H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_size": "50gb",
            "max_age": "7d"
          }
        }
      },
      "delete": {
        "min_age": "30d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
'

# 해결책 3: read-only 모드 해제
curl -X PUT "http://localhost:9200/_cluster/settings" -H 'Content-Type: application/json' -d'
{
  "persistent": {
    "cluster.routing.allocation.disk.threshold_enabled": false
  }
}
'
curl -X PUT "http://localhost:9200/*/_settings" -H 'Content-Type: application/json' -d'
{
  "index.blocks.read_only_allow_delete": null
}
'
```

### 문제 4: Kibana가 느림

```bash
# 증상
Kibana 대시보드 로딩이 매우 느림

# 원인:
# - 너무 많은 데이터 조회
# - 인덱스가 최적화되지 않음

# 해결책 1: 시간 범위 줄이기
# Kibana에서 "Last 15 minutes" 등으로 범위 축소

# 해결책 2: 인덱스 최적화
curl -X POST "http://localhost:9200/lk-trade-*/_forcemerge?max_num_segments=1"

# 해결책 3: Kibana 메모리 증가
# docker-compose.yml에서:
kibana:
  environment:
    - NODE_OPTIONS="--max-old-space-size=4096"
```

---

## 다음 단계

축하합니다! 🎉 이제 Docker 로그 관리의 모든 것을 배웠습니다.

### 이번 섹션에서 배운 것

✅ Docker 로그 드라이버 종류와 설정
✅ ELK Stack (Elasticsearch + Logstash + Kibana) 구축
✅ Filebeat로 Docker 컨테이너 로그 자동 수집
✅ Logstash로 로그 파싱 및 가공
✅ Kibana에서 로그 검색 및 시각화
✅ 구조화된 로깅 및 Correlation ID 추적
✅ 로그 관리 모범 사례
✅ LK-Trade 프로젝트에 로그 관리 통합

### 다음에 배울 것

**섹션 27: 보안 (Security)**에서는:
- Docker 보안 모범 사례
- 컨테이너 격리 및 권한 관리
- 이미지 취약점 스캔
- Secrets 관리
- 네트워크 보안
- 보안 정책 적용

### 추가 학습 자료

**공식 문서:**
- [Docker Logging](https://docs.docker.com/config/containers/logging/)
- [Elastic Stack](https://www.elastic.co/guide/index.html)
- [Filebeat Reference](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)
- [Logstash Reference](https://www.elastic.co/guide/en/logstash/current/index.html)

**심화 학습:**
- [ELK Stack Tutorial](https://www.elastic.co/webinars/getting-started-elasticsearch)
- [Structured Logging Best Practices](https://betterstack.com/community/guides/logging/structured-logging/)
- [Distributed Tracing with OpenTelemetry](https://opentelemetry.io/)

**실전 연습:**
1. LK-Trade 프로젝트에 ELK Stack 적용
2. Kibana 대시보드 커스터마이징
3. 알림 규칙 설정 (Elasticsearch Watcher)
4. 로그 기반 성능 분석 및 최적화

---

**다음 섹션에서 만나요!** 🚀