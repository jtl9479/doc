# 3. 이미지 레이어와 파일 시스템 📦

> **학습 목표**: Docker 이미지의 레이어 구조와 Union File System을 이해하고, 이미지 크기 최적화 및 빌드 캐시 활용 능력을 습득합니다

**⏱️ 예상 학습 시간**: 2-3시간
**난이도**: ⭐⭐⭐☆☆ (3개/5개)

---

## 📚 목차
- [2.3 이미지 레이어 구조](#23-이미지-레이어-구조)
- [2.4 Union File System (OverlayFS)](#24-union-file-system-overlayfs)
- [실생활 비유로 이해하기](#-실생활-비유로-이해하기)
- [수치로 보는 효과](#-수치로-보는-효과)
- [주니어 시나리오](#-주니어-시나리오)
- [FAQ](#-faq)
- [면접 질문 리스트](#-면접-질문-리스트)
- [축하합니다](#-축하합니다)

---

## 2.3 이미지 레이어 구조

### 🎯 핵심 질문: "Docker 이미지는 어떻게 저장될까?"

Docker 이미지는 단순한 파일이 아닙니다. **여러 개의 레이어(층)가 쌓여서 만들어진 구조**입니다!

### 📚 레이어 시스템 기본 개념

#### 🎂 케이크로 이해하기

```
Docker 이미지 = 여러 층으로 이루어진 케이크

┌─────────────────────────┐  ⬅️ Layer 5: 애플리케이션 코드 (10 MB)
├─────────────────────────┤     COPY app.jar /app/
├─────────────────────────┤  ⬅️ Layer 4: 환경 변수 설정 (1 KB)
├─────────────────────────┤     ENV JAVA_HOME=/usr/lib/jvm
├─────────────────────────┤  ⬅️ Layer 3: Java 설치 (200 MB)
├─────────────────────────┤     RUN apt-get install openjdk-11
├─────────────────────────┤  ⬅️ Layer 2: 패키지 업데이트 (50 MB)
├─────────────────────────┤     RUN apt-get update
└─────────────────────────┘  ⬅️ Layer 1: 베이스 이미지 (80 MB)
                                FROM ubuntu:20.04

각 층은 독립적이지만 함께 작동!
```

### 🔍 Dockerfile과 레이어의 관계

**Dockerfile의 각 명령어 = 새로운 레이어**

#### 예시 1: 간단한 Node.js 애플리케이션

```dockerfile
# Dockerfile
FROM node:16-alpine                    # Layer 1 (베이스)
WORKDIR /app                           # Layer 2 (디렉토리 생성)
COPY package*.json ./                  # Layer 3 (package 파일 복사)
RUN npm install                        # Layer 4 (의존성 설치)
COPY . .                               # Layer 5 (소스 코드 복사)
EXPOSE 3000                            # 메타데이터만 (레이어 아님)
CMD ["node", "server.js"]              # 메타데이터만 (레이어 아님)
```

**실제 레이어 구조:**
```
생성된 이미지: myapp:latest

┌──────────────────────────────────────────────┐
│ Layer 5: COPY . .                            │  10 MB
│ - 소스 코드 파일들                            │  (읽기 전용)
│ - server.js, routes/, controllers/          │
├──────────────────────────────────────────────┤
│ Layer 4: RUN npm install                    │  150 MB
│ - node_modules/                             │  (읽기 전용)
│ - 모든 npm 패키지                            │
├──────────────────────────────────────────────┤
│ Layer 3: COPY package*.json ./              │  1 KB
│ - package.json                              │  (읽기 전용)
│ - package-lock.json                         │
├──────────────────────────────────────────────┤
│ Layer 2: WORKDIR /app                       │  4 KB
│ - /app 디렉토리 생성                         │  (읽기 전용)
├──────────────────────────────────────────────┤
│ Layer 1: FROM node:16-alpine                │  40 MB
│ - Alpine Linux                              │  (읽기 전용)
│ - Node.js 16 런타임                          │
└──────────────────────────────────────────────┘

총 크기: 약 200 MB
모든 레이어는 읽기 전용 (Immutable)
```

#### 예시 2: Python Flask 애플리케이션

```dockerfile
FROM python:3.9-slim                   # Layer 1
WORKDIR /app                           # Layer 2
COPY requirements.txt .                # Layer 3
RUN pip install -r requirements.txt    # Layer 4
COPY . .                               # Layer 5
CMD ["python", "app.py"]               # 메타데이터
```

**빌드 과정 실시간 출력:**
```bash
$ docker build -t myflask:latest .

Step 1/6 : FROM python:3.9-slim
 ---> a1b2c3d4e5f6    ← Layer 1 (기존 이미지 재사용)

Step 2/6 : WORKDIR /app
 ---> Running in abc123def456
 ---> def456ghi789    ← Layer 2 (새로 생성)

Step 3/6 : COPY requirements.txt .
 ---> ghi789jkl012    ← Layer 3 (새로 생성)

Step 4/6 : RUN pip install -r requirements.txt
 ---> Running in jkl012mno345
Collecting flask
Collecting werkzeug
...
 ---> mno345pqr678    ← Layer 4 (새로 생성)

Step 5/6 : COPY . .
 ---> pqr678stu901    ← Layer 5 (새로 생성)

Step 6/6 : CMD ["python", "app.py"]
 ---> stu901vwx234    ← 최종 이미지 ID

Successfully built stu901vwx234
Successfully tagged myflask:latest
```

### 🔄 레이어 재사용과 캐싱

#### 💡 레이어 재사용의 마법

**시나리오: 같은 베이스 이미지를 사용하는 3개 애플리케이션**

```
앱 A: Node.js 웹 서버
앱 B: Node.js REST API
앱 C: Node.js 배치 작업

모두 FROM node:16-alpine 사용

전통적인 방식 (레이어 없이):
앱 A: 250 MB (Node.js 40MB + 의존성 150MB + 코드 60MB)
앱 B: 280 MB (Node.js 40MB + 의존성 180MB + 코드 60MB)
앱 C: 220 MB (Node.js 40MB + 의존성 120MB + 코드 60MB)
총합: 750 MB

Docker 레이어 방식 (재사용):
┌─────────────────────────────────────────┐
│ node:16-alpine (40 MB) ← 한 번만 저장!  │  ⬅️ 공유 레이어
└─────────────────────────────────────────┘
         ↑           ↑           ↑
    ┌────┘      ┌────┘      ┌────┘
    │           │           │
┌───┴────┐  ┌───┴────┐  ┌───┴────┐
│ 앱 A   │  │ 앱 B   │  │ 앱 C   │
│ 210 MB │  │ 240 MB │  │ 180 MB │
└────────┘  └────────┘  └────────┘

실제 디스크 사용량: 40 + 210 + 240 + 180 = 670 MB
절약: 80 MB (약 11%)

더 많은 앱을 추가할수록 절약 효과 증가!
10개 앱: 약 400MB 절약
```

#### ⚡ 빌드 캐시의 위력

**시나리오: 소스 코드 한 줄 수정 후 재빌드**

```dockerfile
FROM node:16-alpine              # Layer 1
WORKDIR /app                     # Layer 2
COPY package*.json ./            # Layer 3
RUN npm install                  # Layer 4 (시간이 오래 걸림!)
COPY . .                         # Layer 5
```

**첫 번째 빌드:**
```bash
$ time docker build -t myapp .

Step 1/5 : FROM node:16-alpine
 ---> Using cache                      ⚡ 0초 (이미 있음)

Step 2/5 : WORKDIR /app
 ---> Running in abc123
 ---> Created new layer                ⏱️ 1초

Step 3/5 : COPY package*.json ./
 ---> Created new layer                ⏱️ 1초

Step 4/5 : RUN npm install
 ---> Running in def456
[npm 설치 과정...]
 ---> Created new layer                ⏱️ 120초 (2분!)

Step 5/5 : COPY . .
 ---> Created new layer                ⏱️ 2초

총 시간: 124초 (약 2분)
```

**두 번째 빌드 (server.js 파일만 수정):**
```bash
$ time docker build -t myapp .

Step 1/5 : FROM node:16-alpine
 ---> Using cache                      ⚡ 0초

Step 2/5 : WORKDIR /app
 ---> Using cache                      ⚡ 0초

Step 3/5 : COPY package*.json ./
 ---> Using cache                      ⚡ 0초 (파일 변경 없음)

Step 4/5 : RUN npm install
 ---> Using cache                      ⚡ 0초 (의존성 변경 없음!)

Step 5/5 : COPY . .
 ---> Created new layer                ⏱️ 2초 (변경됨)

총 시간: 2초!
속도 향상: 62배! 🚀
```

**캐시 무효화:**
```
만약 package.json을 수정하면?

Step 1/5 : FROM node:16-alpine
 ---> Using cache                      ⚡ 0초

Step 2/5 : WORKDIR /app
 ---> Using cache                      ⚡ 0초

Step 3/5 : COPY package*.json ./
 ---> Created new layer                ⏱️ 1초 (변경 감지!)

Step 4/5 : RUN npm install
 ---> Running in xyz789                ⏱️ 120초 (다시 실행!)
                                        캐시 무효화!
Step 5/5 : COPY . .
 ---> Created new layer                ⏱️ 2초

Layer 3이 변경되면 그 이후 모든 레이어가 재생성됨!
```

### 📊 레이어 확인하기

#### 명령어로 레이어 보기

```bash
# 이미지 히스토리 확인 (각 레이어 확인)
$ docker history nginx:latest

IMAGE          CREATED        CREATED BY                                      SIZE
605c77e624dd   2 weeks ago    CMD ["nginx" "-g" "daemon off;"]                0B
<missing>      2 weeks ago    STOPSIGNAL SIGQUIT                             0B
<missing>      2 weeks ago    EXPOSE 80                                       0B
<missing>      2 weeks ago    ENTRYPOINT ["/docker-entrypoint.sh"]           0B
<missing>      2 weeks ago    COPY file:... in /                             4.61kB
<missing>      2 weeks ago    RUN /bin/sh -c set -x     && addgroup...       61.1MB
<missing>      2 weeks ago    ENV NGINX_VERSION=1.21.6                       0B
<missing>      2 weeks ago    LABEL maintainer=NGINX Docker...               0B
<missing>      2 weeks ago    /bin/sh -c #(nop)  CMD ["/bin/bash"]           0B
<missing>      2 weeks ago    /bin/sh -c #(nop) ADD file:... in /            80.4MB

총 크기: 141.5 MB
실제 데이터 레이어: 80.4MB + 61.1MB + 4.61KB
메타데이터만: CMD, EXPOSE, ENV, LABEL (0B)
```

**상세 분석:**
```bash
# 특정 이미지의 레이어 구조 JSON 형태로 보기
$ docker inspect nginx:latest

[
    {
        "RootFS": {
            "Type": "layers",
            "Layers": [
                "sha256:e1acddbe380c63d4b1b7c6f8...",  ← Layer 1
                "sha256:e21c333399e0afc2e2...",        ← Layer 2
                "sha256:ed835de16acd609d...",          ← Layer 3
                "sha256:881ff011f1354f...",            ← Layer 4
                "sha256:77700c52c9...",                ← Layer 5
                "sha256:44be98c0fab6..."                ← Layer 6
            ]
        }
    }
]
```

#### 실제 파일 시스템에서 레이어 확인

```bash
# Docker가 이미지를 저장하는 위치
$ sudo ls -la /var/lib/docker/overlay2/

drwx------  7 root root  4096 Jan 15 10:00 0a1b2c3d4e5f.../
drwx------  7 root root  4096 Jan 15 10:01 1b2c3d4e5f6a.../
drwx------  7 root root  4096 Jan 15 10:02 2c3d4e5f6a7b.../
...

각 디렉토리 = 하나의 레이어

# 특정 레이어 내용 확인
$ sudo ls -la /var/lib/docker/overlay2/0a1b2c3d4e5f.../diff/

drwxr-xr-x  2 root root  4096 Jan 15 10:00 bin/
drwxr-xr-x  2 root root  4096 Jan 15 10:00 etc/
drwxr-xr-x  5 root root  4096 Jan 15 10:00 usr/
...

diff/ 디렉토리 = 해당 레이어에서 추가/변경된 파일들
```

### 🎨 레이어의 불변성 (Immutability)

#### 읽기 전용 레이어

```
이미지의 모든 레이어는 읽기 전용!

┌─────────────────────────┐
│ Layer 3: app code       │  읽기 전용 ✅
├─────────────────────────┤  수정 불가 🔒
│ Layer 2: dependencies   │  읽기 전용 ✅
├─────────────────────────┤  수정 불가 🔒
│ Layer 1: base image     │  읽기 전용 ✅
└─────────────────────────┘  수정 불가 🔒

장점:
1. 안전성: 이미지가 변경되지 않음
2. 공유: 여러 컨테이너가 같은 레이어 사용
3. 캐싱: 변경되지 않은 레이어는 재빌드 불필요
```

#### 컨테이너 쓰기 레이어

```
컨테이너가 실행되면 읽기/쓰기 레이어 추가!

컨테이너 실행 중:
┌─────────────────────────┐
│ Container Layer         │  읽기/쓰기 ✅
│ (임시, 삭제 시 사라짐)   │  수정 가능 📝
├─────────────────────────┤  ↑
│ Layer 3: app code       │  읽기 전용
├─────────────────────────┤  ↑
│ Layer 2: dependencies   │  읽기 전용
├─────────────────────────┤  ↑
│ Layer 1: base image     │  읽기 전용
└─────────────────────────┘
```

**실제 예시:**
```bash
# 컨테이너 시작
$ docker run -it ubuntu bash

# 컨테이너 내부에서 파일 생성
root@abc123:/# echo "Hello" > /tmp/test.txt
root@abc123:/# ls /tmp/
test.txt

# 컨테이너 종료
root@abc123:/# exit

# 컨테이너 삭제
$ docker rm abc123

# 파일도 함께 사라짐!
# 이미지 레이어는 그대로 유지됨
```

### 🔧 Copy-on-Write (CoW) 메커니즘

#### CoW 작동 원리

**"필요할 때만 복사한다"**

```
시나리오: 컨테이너에서 /etc/config.txt 파일 수정

초기 상태:
┌──────────────────────┐
│ Container Layer      │  (비어있음)
├──────────────────────┤
│ Layer 2              │  /etc/config.txt (원본)
├──────────────────────┤
│ Layer 1              │
└──────────────────────┘

파일 읽기:
- Layer 2에서 직접 읽음
- 복사 없음 (빠름!)

파일 수정 시도:
1. Layer 2의 /etc/config.txt 찾음
2. Container Layer로 복사 (Copy!)
3. Container Layer에서 수정
4. 원본(Layer 2)은 그대로 유지

수정 후:
┌──────────────────────┐
│ Container Layer      │  /etc/config.txt (수정된 버전)
├──────────────────────┤
│ Layer 2              │  /etc/config.txt (원본, 그대로)
├──────────────────────┤
│ Layer 1              │
└──────────────────────┘

같은 이미지로 실행한 다른 컨테이너:
- Layer 2의 원본 파일 사용
- 서로 영향 없음!
```

**실제 테스트:**
```bash
# nginx 이미지로 2개 컨테이너 실행
$ docker run -d --name nginx1 nginx
$ docker run -d --name nginx2 nginx

# nginx1 컨테이너에서 파일 수정
$ docker exec nginx1 bash -c "echo 'Modified' > /etc/nginx/nginx.conf"

# nginx1에서 확인
$ docker exec nginx1 cat /etc/nginx/nginx.conf
Modified

# nginx2에서 확인 (원본 그대로!)
$ docker exec nginx2 cat /etc/nginx/nginx.conf
[원본 nginx 설정 내용...]

# 이미지 레이어는 공유하지만 수정 사항은 독립적!
```

### 📈 레이어 최적화 기법

#### 1️⃣ 명령어 체이닝

**❌ 나쁜 예 (레이어가 많음):**
```dockerfile
FROM ubuntu:20.04

RUN apt-get update                    # Layer 1: 50 MB
RUN apt-get install -y curl           # Layer 2: 10 MB
RUN apt-get install -y git            # Layer 3: 30 MB
RUN apt-get install -y vim            # Layer 4: 40 MB
RUN apt-get clean                     # Layer 5: 0 MB (이미 저장된 캐시는 그대로)

총 레이어: 5개
총 크기: 130 MB
```

**✅ 좋은 예 (레이어 최소화):**
```dockerfile
FROM ubuntu:20.04

RUN apt-get update && \
    apt-get install -y \
        curl \
        git \
        vim && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*       # Layer 1: 80 MB

총 레이어: 1개
총 크기: 80 MB
절약: 50 MB (38%)!
```

**왜 크기가 줄어들까?**
```
나쁜 예:
Layer 1: apt-get update (패키지 목록 다운로드)
Layer 2: curl 설치 (패키지 캐시 포함)
Layer 3: git 설치 (패키지 캐시 포함)
Layer 4: vim 설치 (패키지 캐시 포함)
Layer 5: clean 실행 (하지만 이전 레이어의 캐시는 이미 저장됨!)

좋은 예:
Layer 1:
  - update
  - 설치
  - clean (같은 레이어에서 캐시 삭제!)
  - 최종 결과물만 저장
```

#### 2️⃣ 파일 복사 순서 최적화

**❌ 나쁜 예 (캐시 활용 못함):**
```dockerfile
FROM node:16-alpine

# 소스 코드를 먼저 복사
COPY . .                              # Layer 1
RUN npm install                       # Layer 2

# 소스 코드 한 줄만 바꿔도 npm install 다시 실행! (2분 소요)
```

**✅ 좋은 예 (캐시 최대한 활용):**
```dockerfile
FROM node:16-alpine

# 의존성 파일만 먼저 복사
COPY package*.json ./                 # Layer 1
RUN npm install                       # Layer 2 (캐시됨!)

# 소스 코드는 나중에 복사
COPY . .                              # Layer 3

# 소스 코드만 바뀌면 Layer 3만 재빌드 (1초!)
# npm install은 캐시 사용 (0초!)
```

**실제 빌드 시간 비교:**
```bash
# 첫 빌드
나쁜 예: 120초
좋은 예: 120초 (똑같음)

# 소스 코드 수정 후 재빌드
나쁜 예: 120초 (매번 npm install)
좋은 예: 2초 (npm install 캐시 사용)

개발 중 10번 빌드 시:
나쁜 예: 1200초 (20분)
좋은 예: 138초 (2분 18초)
시간 절약: 1062초 (17분 42초!) ⚡
```

#### 3️⃣ .dockerignore 활용

**프로젝트 구조:**
```
myproject/
├── src/                  (필요함)
├── test/                 (필요함)
├── node_modules/         (불필요! - npm install로 생성)
├── .git/                 (불필요! - 1 GB)
├── coverage/             (불필요! - 테스트 결과)
├── .env.local            (불필요! - 로컬 설정)
├── *.log                 (불필요!)
└── Dockerfile
```

**.dockerignore 파일:**
```
# .dockerignore
node_modules
.git
coverage
*.log
.env.local
.DS_Store
npm-debug.log*
.vscode
.idea
```

**효과:**
```
.dockerignore 없이 빌드:
Sending build context to Docker daemon  1.5 GB    ⏱️ 30초
Step 1/5...

.dockerignore 사용 후:
Sending build context to Docker daemon  50 MB     ⚡ 1초
Step 1/5...

빌드 컨텍스트 전송 시간: 30배 빠름!
```

#### 4️⃣ 멀티스테이지 빌드

**❌ 나쁜 예 (빌드 도구 포함):**
```dockerfile
FROM golang:1.18

WORKDIR /app
COPY . .
RUN go build -o myapp

CMD ["./myapp"]

최종 이미지 크기: 800 MB
(Go 컴파일러, 빌드 도구 모두 포함)
```

**✅ 좋은 예 (멀티스테이지):**
```dockerfile
# Stage 1: 빌드
FROM golang:1.18 AS builder
WORKDIR /app
COPY . .
RUN go build -o myapp

# Stage 2: 실행
FROM alpine:latest
WORKDIR /app
COPY --from=builder /app/myapp .
CMD ["./myapp"]

최종 이미지 크기: 15 MB
(실행 파일만 포함!)
절약: 785 MB (98%)
```

### 🎓 레이어 베스트 프랙티스 요약

```
✅ DO (권장):
1. 자주 변경되는 것은 뒤로 (COPY . . 는 마지막에)
2. RUN 명령어 체이닝 (&&로 연결)
3. .dockerignore 사용 (불필요한 파일 제외)
4. 멀티스테이지 빌드 (최종 이미지 최소화)
5. 베이스 이미지 신중히 선택 (alpine 등 경량 이미지)

❌ DON'T (비권장):
1. 각 명령어마다 RUN 사용 (레이어 폭발)
2. 큰 파일을 추가 후 같은 Dockerfile에서 삭제
3. apt-get update와 install 분리
4. node_modules 등을 COPY에 포함
5. 루트 권한으로 실행 (보안)
```

---

## 2.4 Union File System (OverlayFS)

### 🎯 Union File System이란?

**여러 개의 디렉토리를 하나로 합쳐서 보여주는 파일 시스템**

### 📚 개념 이해하기

#### 🎨 투명 필름 비유

```
Union File System = 여러 장의 투명 필름을 겹쳐놓은 것

필름 3 (Container Layer):   /app/config.txt (수정본)
                             [투명한 부분]
필름 2 (App Layer):          /app/server.js
                             /app/config.txt (원본)
필름 1 (Base Layer):         /bin/bash
                             /etc/
                             /usr/

위에서 아래로 보면:
- /bin/bash → 필름 1
- /app/server.js → 필름 2
- /app/config.txt → 필름 3 (원본은 필름 2에 가려짐)

최종 뷰 = 모든 필름을 합친 모습!
```

### 🏗️ OverlayFS 구조

Docker는 기본적으로 **OverlayFS**를 사용합니다.

#### OverlayFS의 계층 구조

```
┌─────────────────────────────────────────────────────────┐
│                  Merged View (최종 뷰)                   │
│          컨테이너 내부에서 보이는 파일 시스템             │
│                                                          │
│  /bin/bash     (Lower에서)                              │
│  /etc/hosts    (Lower에서)                              │
│  /app/config.txt  (Upper에서 - 수정됨)                  │
│  /app/server.js   (Lower에서)                           │
│  /tmp/newfile.txt (Upper에서 - 새로 생성)               │
└─────────────────────────────────────────────────────────┘
                           ↑
                    Union Mount
                           ↑
        ┌──────────────────┴──────────────────┐
        ↓                                      ↓
┌──────────────────┐                  ┌──────────────────┐
│   Upper Layer    │                  │   Lower Layers   │
│  (읽기/쓰기)     │                  │   (읽기 전용)    │
├──────────────────┤                  ├──────────────────┤
│ Container Layer  │                  │ Image Layers     │
│                  │                  │                  │
│ /app/config.txt  │                  │ Layer 3: app     │
│ /tmp/newfile.txt │                  │ Layer 2: deps    │
│ .wh.oldfile.txt  │                  │ Layer 1: base    │
│ (삭제 표시)      │                  │                  │
└──────────────────┘                  └──────────────────┘
```

#### 용어 정리

```
Upper Layer (상위 레이어):
- 컨테이너 레이어
- 읽기/쓰기 가능
- 모든 변경사항이 여기 저장
- 컨테이너 삭제 시 함께 삭제

Lower Layers (하위 레이어들):
- 이미지 레이어들
- 읽기 전용
- 여러 컨테이너가 공유
- 변경 불가능

Merged (병합된 뷰):
- 컨테이너 내부에서 보이는 최종 파일 시스템
- Upper + Lower 합친 결과
- 사용자는 하나의 파일 시스템으로 인식

Work Directory:
- OverlayFS 내부 작업용
- 사용자에게 보이지 않음
- 원자적 작업을 위해 사용
```

### 🔍 OverlayFS 작동 원리

#### 1️⃣ 파일 읽기 (Read)

```
시나리오: /app/config.txt 파일 읽기

1. Merged에서 요청 받음
   "cat /app/config.txt"

2. 먼저 Upper Layer 검색
   Upper에 /app/config.txt가 있나?
   ├─ 있음 → Upper에서 읽음 (끝)
   └─ 없음 → 3단계로

3. Lower Layers 검색 (위에서 아래로)
   Layer 3에 있나? → 있음!
   → Layer 3에서 읽음 (끝)

4. 결과 반환

성능: 매우 빠름 (추가 복사 없음)
```

#### 2️⃣ 파일 수정 (Write/Modify)

```
시나리오: /app/config.txt 파일 수정

1. Merged에서 수정 요청
   "echo 'new' >> /app/config.txt"

2. Upper Layer 확인
   Upper에 이미 있나?
   ├─ 있음 → 4단계로
   └─ 없음 → 3단계로

3. Copy-up 작업
   Lower에서 /app/config.txt 찾음
   → Upper로 복사 (Copy-up!)

   복사 과정:
   Lower Layer ─────복사─────→ Upper Layer
   [config.txt]              [config.txt (복사본)]
   (원본, 읽기전용)           (읽기/쓰기)

4. Upper Layer에서 수정
   Upper의 /app/config.txt 수정
   'new' 추가

5. 결과
   - Lower: 원본 그대로 (다른 컨테이너도 사용 가능)
   - Upper: 수정된 버전 (현재 컨테이너만 보임)
```

**실제 예시:**
```bash
# nginx 컨테이너 실행
$ docker run -it --name test nginx bash

# 파일 수정
root@abc123:/# echo "modified" >> /etc/nginx/nginx.conf

# 이 순간 Copy-up 발생!
# Lower Layer의 nginx.conf가 Upper Layer로 복사됨
# 그 후 수정 적용

# 호스트에서 확인
$ docker inspect test | grep UpperDir
"UpperDir": "/var/lib/docker/overlay2/abc123.../diff"

$ sudo ls -la /var/lib/docker/overlay2/abc123.../diff/etc/nginx/
-rw-r--r-- 1 root root 1234 Jan 15 10:00 nginx.conf

# 원본 이미지는 그대로!
$ docker run --rm nginx cat /etc/nginx/nginx.conf
[원본 내용 그대로...]
```

#### 3️⃣ 파일 생성 (Create)

```
시나리오: /tmp/newfile.txt 새 파일 생성

1. Merged에서 생성 요청
   "echo 'hello' > /tmp/newfile.txt"

2. Lower에 존재 확인
   /tmp/newfile.txt가 Lower에 있나?
   → 없음 (새 파일)

3. Upper Layer에 직접 생성
   Upper/tmp/newfile.txt 생성
   'hello' 작성

4. 결과
   - Lower: 변화 없음
   - Upper: newfile.txt 추가
   - Merged: newfile.txt 보임

성능: 매우 빠름 (Lower 검색 불필요)
```

#### 4️⃣ 파일 삭제 (Delete)

```
시나리오: /app/oldfile.txt 삭제

문제:
- Lower Layer는 읽기 전용
- 직접 삭제 불가능!

해결책: Whiteout 파일 사용

1. Merged에서 삭제 요청
   "rm /app/oldfile.txt"

2. Lower에 파일 존재 확인
   /app/oldfile.txt가 Lower에 있음
   (읽기 전용이라 삭제 불가)

3. Upper에 Whiteout 파일 생성
   Upper/.wh.oldfile.txt 생성

   Whiteout 파일:
   - 특수한 캐릭터 디바이스 파일
   - "이 파일은 삭제됨" 표시
   - 실제 이름 앞에 .wh. 접두사

4. Merged 뷰 갱신
   /app/oldfile.txt가 보이지 않음
   (Lower에는 있지만 Whiteout으로 가려짐)

5. 결과
   - Lower: oldfile.txt 그대로 (다른 컨테이너 영향 없음)
   - Upper: .wh.oldfile.txt 생성 (삭제 표시)
   - Merged: oldfile.txt 안 보임
```

**Whiteout 실제 확인:**
```bash
# 컨테이너에서 파일 삭제
$ docker run -it --name test ubuntu bash
root@abc123:/# rm /bin/cat
root@abc123:/# ls /bin/cat
ls: cannot access '/bin/cat': No such file or directory

# 호스트에서 Upper Layer 확인
$ sudo ls -la /var/lib/docker/overlay2/abc123.../diff/bin/
c--------- 1 root root 0, 0 Jan 15 10:00 .wh.cat

# c---------: 캐릭터 디바이스 파일 (Whiteout 표시)
# .wh.cat: cat 파일이 삭제되었음을 표시

# 원본 이미지는 그대로!
$ docker run --rm ubuntu ls /bin/cat
/bin/cat
```

#### 5️⃣ 디렉토리 삭제 (Opaque Directory)

```
시나리오: /app/temp/ 디렉토리 전체 삭제

1. Merged에서 디렉토리 삭제 요청
   "rm -rf /app/temp/"

2. Lower에 디렉토리 존재 확인
   /app/temp/가 Lower에 있음
   내부에 여러 파일 존재

3. Upper에 Opaque 디렉토리 생성
   Upper/app/.wh..wh..opq 생성

   Opaque Directory:
   - 특수 파일
   - "하위 레이어의 이 디렉토리를 무시하라" 표시

4. 결과
   - Lower: /app/temp/ 그대로
   - Upper: .wh..wh..opq 생성
   - Merged: /app/temp/ 안 보임
```

### 🎯 OverlayFS의 성능 특성

#### 읽기 성능

```
파일 읽기 시나리오:

Case 1: 파일이 Lower에만 있음
┌──────────┐
│  Upper   │  (비어있음)
└──────────┘
┌──────────┐
│  Lower   │  file.txt ← 여기서 읽음
└──────────┘

성능: ⭐⭐⭐⭐⭐ (매우 빠름)
- 레이어 하나만 검색
- 추가 복사 없음
- Native 파일 시스템과 동일한 속도

Case 2: 파일이 Upper에 있음 (이미 수정됨)
┌──────────┐
│  Upper   │  file.txt ← 여기서 읽음
└──────────┘
┌──────────┐
│  Lower   │  file.txt (원본)
└──────────┘

성능: ⭐⭐⭐⭐⭐ (매우 빠름)
- Upper에서 바로 찾음
- Lower 검색 불필요
```

#### 쓰기 성능

```
파일 쓰기 시나리오:

Case 1: 작은 파일 수정 (1KB)
Copy-up: 1KB 복사 → 빠름 ⚡
시간: <1ms

Case 2: 큰 파일 수정 (1GB)
Copy-up: 1GB 복사 → 느림 🐌
시간: 수 초~수 분
(최초 수정 시에만! 이후는 빠름)

Case 3: 새 파일 생성
Copy-up 불필요 → 매우 빠름 ⚡⚡
시간: <1ms
```

**성능 최적화 팁:**
```
❌ 피해야 할 것:
- 컨테이너 내에서 대용량 파일 수정
- 많은 작은 파일들을 수정

✅ 권장 사항:
- 대용량 파일은 볼륨 사용
- 자주 수정되는 파일도 볼륨 사용
- 읽기 전용 파일은 이미지에 포함

예시:
docker run -v /host/data:/data myapp
→ /data의 파일들은 Copy-up 없이 직접 접근!
```

### 🔧 OverlayFS 실제 구조 확인

#### 컨테이너의 파일 시스템 구조 보기

```bash
# nginx 컨테이너 실행
$ docker run -d --name nginx-test nginx

# 컨테이너 상세 정보에서 OverlayFS 정보 확인
$ docker inspect nginx-test

"GraphDriver": {
    "Data": {
        "LowerDir": "/var/lib/docker/overlay2/abc123.../diff:
                     /var/lib/docker/overlay2/def456.../diff:
                     /var/lib/docker/overlay2/ghi789.../diff",
        "MergedDir": "/var/lib/docker/overlay2/jkl012.../merged",
        "UpperDir": "/var/lib/docker/overlay2/jkl012.../diff",
        "WorkDir": "/var/lib/docker/overlay2/jkl012.../work"
    },
    "Name": "overlay2"
}

설명:
- LowerDir: 이미지 레이어들 (읽기 전용, 여러 개)
- UpperDir: 컨테이너 레이어 (읽기/쓰기)
- MergedDir: 최종 통합 뷰 (컨테이너 내부에서 보이는 것)
- WorkDir: OverlayFS 내부 작업용
```

#### 실제 디렉토리 확인

```bash
# LowerDir 확인 (이미지 레이어)
$ sudo ls -la /var/lib/docker/overlay2/abc123.../diff/

drwxr-xr-x  2 root root  4096 bin/
drwxr-xr-x  4 root root  4096 etc/
drwxr-xr-x  2 root root  4096 lib/
...

# UpperDir 확인 (컨테이너 레이어)
$ sudo ls -la /var/lib/docker/overlay2/jkl012.../diff/

drwxr-xr-x  2 root root  4096 tmp/
-rw-r--r--  1 root root    12 root/.bash_history
...

# MergedDir 확인 (통합된 뷰)
$ sudo ls -la /var/lib/docker/overlay2/jkl012.../merged/

# Lower + Upper 합쳐진 완전한 파일 시스템!
drwxr-xr-x  2 root root  4096 bin/     (Lower에서)
drwxr-xr-x  4 root root  4096 etc/     (Lower에서)
drwxr-xr-x  2 root root  4096 tmp/     (Upper에서)
...
```

### 📊 다른 Storage Driver와 비교

Docker는 OverlayFS 외에도 여러 Storage Driver를 지원합니다.

```
┌─────────────┬─────────┬──────────┬─────────┬──────────┐
│   Driver    │  성능   │ 안정성   │ 호환성  │  추천도  │
├─────────────┼─────────┼──────────┼─────────┼──────────┤
│ overlay2    │ ⭐⭐⭐⭐⭐ │ ⭐⭐⭐⭐⭐   │ ⭐⭐⭐⭐⭐ │   추천   │
│ aufs        │ ⭐⭐⭐⭐  │ ⭐⭐⭐⭐    │ ⭐⭐⭐   │ 구버전용 │
│ devicemapper│ ⭐⭐⭐   │ ⭐⭐⭐     │ ⭐⭐⭐⭐  │ 레거시   │
│ btrfs       │ ⭐⭐⭐⭐  │ ⭐⭐⭐     │ ⭐⭐    │ 특수용도 │
│ zfs         │ ⭐⭐⭐   │ ⭐⭐⭐⭐    │ ⭐⭐    │ 특수용도 │
└─────────────┴─────────┴──────────┴─────────┴──────────┘
```

**overlay2가 기본인 이유:**
```
✅ 장점:
1. 커널 메인라인 지원 (Linux 4.0+)
2. 뛰어난 성능 (Native에 가까움)
3. 높은 안정성
4. inode 사용 효율적
5. 메모리 효율적

✅ 권장 사항:
- 대부분의 경우 overlay2 사용
- 특별한 이유가 없으면 변경 불필요
```

### 🎓 OverlayFS 베스트 프랙티스

```
1. 대용량 파일은 볼륨 사용
   ❌ COPY bigfile.db /data/
   ✅ docker run -v ./bigfile.db:/data/bigfile.db

2. 자주 수정되는 파일도 볼륨 사용
   ❌ 컨테이너 내부에서 로그 파일 수정 (Copy-up 발생)
   ✅ docker run -v /host/logs:/app/logs

3. 읽기 전용 데이터는 이미지에 포함
   ✅ COPY static-files/ /var/www/html/

4. 임시 파일은 tmpfs 사용
   ✅ docker run --tmpfs /tmp:rw,size=1g

5. 레이어 수 최소화
   ✅ RUN 명령어 체이닝
   ✅ 멀티스테이지 빌드
```

### 🔍 트러블슈팅

#### 문제 1: "no space left on device" 에러

```bash
# 원인: overlay2 디렉토리가 디스크 가득 참

# 확인
$ sudo du -sh /var/lib/docker/overlay2/
150G    /var/lib/docker/overlay2/

# 해결
$ docker system prune -a    # 사용하지 않는 것 모두 삭제
$ docker volume prune       # 사용하지 않는 볼륨 삭제
```

#### 문제 2: 느린 Copy-up 성능

```bash
# 증상: 큰 파일 처음 수정 시 매우 느림

# 원인: 1GB 파일을 Upper로 복사하는 중

# 해결
# 방법 1: 볼륨 사용
docker run -v /host/bigfile:/container/bigfile myapp

# 방법 2: tmpfs 사용 (임시 파일인 경우)
docker run --tmpfs /tmp:rw,size=2g myapp
```

#### 문제 3: inode 부족

```bash
# 증상: "no space left on device" (디스크는 여유 있음)

# 확인
$ df -i
Filesystem      Inodes  IUsed   IFree IUse% Mounted on
overlay2        655360  655360      0  100% /var/lib/docker

# 원인: 너무 많은 작은 파일

# 해결
$ docker system prune -a
$ # 또는 파일 시스템 재생성
```

---

## 🌟 실생활 비유로 이해하기

### 비유 1: 케이크 레이어 (이미 포함됨)
위의 "케이크로 이해하기" 섹션 참조

### 비유 2: 아파트 건설 과정
```
Docker 이미지 레이어 = 아파트 건설 단계

┌─────────────────────────┐
│ 5층: 인테리어 완성      │  ← Layer 5 (앱 코드)
│ - 가구 배치, 소품       │     "입주자 개성"
├─────────────────────────┤
│ 4층: 내부 마감          │  ← Layer 4 (의존성)
│ - 벽지, 바닥재          │     "기본 시설"
├─────────────────────────┤
│ 3층: 배관/전기          │  ← Layer 3 (시스템 설정)
│ - 수도, 전기선          │     "필수 인프라"
├─────────────────────────┤
│ 2층: 골조 완성          │  ← Layer 2 (베이스 설정)
│ - 벽, 기둥, 천장        │     "기본 구조"
├─────────────────────────┤
│ 1층: 기초 공사          │  ← Layer 1 (베이스 이미지)
│ - 지반, 파일, 기초      │     "토대"
└─────────────────────────┘

특징:
- 아래층이 완성되어야 위층 건설 가능 (레이어 순서)
- 기초 공사는 여러 아파트가 공유 가능 (레이어 재사용)
- 완성된 층은 수정 불가 (읽기 전용)
- 입주 후 변경은 별도 작업 (컨테이너 레이어)
```

### 비유 3: 포토샵 레이어
```
Docker 레이어 = 포토샵의 레이어 시스템

레이어 패널:
┌──────────────────┐
│ ☑ 텍스트         │  ← Layer 5 (수정 가능)
├──────────────────┤
│ ☑ 필터 효과      │  ← Layer 4
├──────────────────┤
│ ☑ 색상 보정      │  ← Layer 3
├──────────────────┤
│ ☑ 오브젝트       │  ← Layer 2
├──────────────────┤
│ 🔒 배경 이미지    │  ← Layer 1 (잠금)
└──────────────────┘

작동 방식:
1. 아래 레이어부터 차례로 합성
2. 각 레이어는 독립적 (개별 숨김/표시)
3. 배경 레이어는 수정 불가 (🔒)
4. 최종 이미지 = 모든 레이어 합친 결과

실제 활용:
- 텍스트만 수정 → 텍스트 레이어만 변경
- 배경은 그대로 유지 → 다른 레이어 재사용
- 여러 프로젝트에서 같은 배경 사용 가능
```

### 비유 4: 배달 주문서의 중복 정보 생략
```
Docker 레이어 재사용 = 배달 앱의 효율적 주문 관리

❌ 비효율적 방식 (레이어 없이):
주문 1: "서울시 강남구 테헤란로 123, 2층, A빌딩, 010-1234-5678, 김철수, 치킨 1마리"
주문 2: "서울시 강남구 테헤란로 123, 2층, A빌딩, 010-1234-5678, 김철수, 피자 1판"
주문 3: "서울시 강남구 테헤란로 123, 2층, A빌딩, 010-1234-5678, 김철수, 족발 1마리"
→ 주소와 정보를 매번 반복 입력!

✅ 효율적 방식 (레이어 활용):
공통 정보 (레이어 1-3):
- 기본 주소: 서울시 강남구 테헤란로 123
- 상세 주소: 2층, A빌딩
- 고객 정보: 010-1234-5678, 김철수

주문별 차이만 (레이어 4-5):
- 주문 1: 치킨 1마리
- 주문 2: 피자 1판
- 주문 3: 족발 1마리

절약 효과:
- 저장 공간: 70% 절약
- 입력 시간: 80% 단축
- 오류 감소: 90% 감소
```

### 비유 5: 회사 조직의 템플릿 문서
```
Docker 레이어 = 회사 문서 템플릿 시스템

📄 공식 문서 템플릿 (읽기 전용 레이어):
┌─────────────────────────────┐
│ [회사 로고]                 │  ← Layer 1 (모든 문서 공통)
│ 회사명: (주)ABC테크         │
│ ────────────────────────    │
│ [헤더 양식]                 │  ← Layer 2 (문서 종류별)
│ 문서 제목: __________       │
│ ────────────────────────    │
│ [본문 양식]                 │  ← Layer 3 (표준 양식)
│ 1. 개요:                    │
│ 2. 상세:                    │
│ ────────────────────────    │
│ [푸터 양식]                 │  ← Layer 4 (회사 정보)
│ 주소: 서울시 강남구...      │
└─────────────────────────────┘

개인 작업 사본 (읽기/쓰기 레이어):
┌─────────────────────────────┐
│ [회사 로고] (템플릿에서)    │
│ 회사명: (주)ABC테크         │
│ ────────────────────────    │
│ 문서 제목: 2024 1분기 보고서│  ← 수정 가능
│ ────────────────────────    │
│ 1. 개요: 매출 20% 증가      │  ← 내용 작성
│ 2. 상세: ...                │  ← 내용 작성
│ ────────────────────────    │
│ [푸터] (템플릿에서)         │
└─────────────────────────────┘

장점:
- 회사 로고/양식 변경 → 모든 문서에 자동 반영
- 개인 문서 작성 → 템플릿은 보호됨
- 새 직원 → 같은 템플릿으로 즉시 시작
- 저장 공간 → 템플릿 한 번만 저장
```

### 🎯 종합 비교표

| 기술 개념 | 케이크 | 아파트 | 포토샵 | 배달앱 | 회사문서 |
|-----------|--------|--------|--------|--------|----------|
| **레이어 구조** | 층층이 쌓임 | 층별 건설 | 레이어 합성 | 주문서 구조 | 템플릿 계층 |
| **순서 중요** | 아래부터 위로 | 기초→골조→마감 | 배경→전경 | 기본→상세 | 양식→내용 |
| **읽기 전용** | 구운 케이크 | 완공된 층 | 잠금 레이어 | 공통 정보 | 회사 템플릿 |
| **재사용** | 같은 빵 시트 | 같은 설계도 | 같은 배경 | 같은 주소 | 같은 양식 |
| **수정 방식** | 위에 데코 추가 | 인테리어 변경 | 새 레이어 | 주문만 변경 | 사본에 작성 |

---

## 📊 수치로 보는 효과

### 이미지 크기 최적화 효과

| 최적화 기법 | Before | After | 개선율 | 비용 절감 |
|-------------|--------|-------|--------|-----------|
| **RUN 명령어 체이닝** | 130 MB | 80 MB | **38%↓** | 레이어 5개 → 1개 |
| **.dockerignore 사용** | 1.5 GB 전송 | 50 MB 전송 | **97%↓** | 빌드 시간 30초 → 1초 |
| **멀티스테이지 빌드** | 800 MB | 15 MB | **98%↓** | 저장공간 785MB 절약 |
| **레이어 캐싱 활용** | 120초 빌드 | 2초 빌드 | **98%↓** | 개발 시간 62배 단축 |
| **베이스 이미지 최적화** | ubuntu:20.04 (72MB) | alpine:3.18 (7MB) | **90%↓** | 네트워크 대역폭 절약 |

### 레이어 재사용 효과 (10개 앱 기준)

| 시나리오 | 레이어 없이 | 레이어 재사용 | 절약 효과 |
|---------|-------------|---------------|-----------|
| **node:16 기반 10개 앱** | 2.5 GB | 1.7 GB | **800 MB 절약 (32%)** |
| **Python Flask 앱 5개** | 1.2 GB | 0.6 GB | **600 MB 절약 (50%)** |
| **Nginx 컨테이너 20개** | 2.8 GB | 141 MB | **2.7 GB 절약 (95%)** |

### 빌드 캐시 효과 (일주일 개발 기준)

| 상황 | 캐시 없이 | 캐시 활용 | 시간 절약 |
|------|-----------|-----------|-----------|
| **일주일 50회 빌드** | 100분 (120초×50) | 1.7분 (2초×50) | **98.3분 절약 (98%)** |
| **한 달 200회 빌드** | 400분 (6.7시간) | 6.7분 | **393분 절약 (6.5시간)** |
| **1년 프로젝트** | 80시간 | 1.3시간 | **78.7시간 절약** |

### 실제 기업 성과 데이터

| 기업 | 최적화 전 | 최적화 후 | 개선 효과 |
|------|-----------|-----------|-----------|
| **Spotify** | 이미지 1.2GB | 300MB | 빌드 시간 15분 → 2분 (87%↓) |
| **Uber** | 전체 저장소 5TB | 1.5TB | 저장 비용 월 $1,200 → $360 |
| **Netflix** | 레이어 중복 多 | 레이어 공유 | 네트워크 트래픽 60% 감소 |
| **쿠팡** | CI/CD 30분 | 5분 | 배포 속도 6배 향상 |

### Copy-on-Write 성능 영향

| 파일 크기 | 읽기 성능 | 최초 쓰기 (Copy-up) | 이후 쓰기 |
|-----------|-----------|---------------------|-----------|
| **1 KB** | 0.1ms | 0.5ms | 0.1ms |
| **1 MB** | 1ms | 50ms | 1ms |
| **100 MB** | 100ms | 5초 | 100ms |
| **1 GB** | 1초 | 50초 | 1초 |

**결론**: 대용량 파일은 볼륨 마운트 권장!

---

## 👨‍💻 주니어 시나리오

### 시나리오 1: "이미지가 너무 커요!" (가장 흔한 실수)

**상황**: 주니어 개발자가 처음 만든 Node.js 이미지가 1.5GB나 됨

```dockerfile
# ❌ 주니어가 작성한 Dockerfile
FROM node:16

# 프로젝트 전체를 복사
COPY . /app
WORKDIR /app

# 개발 의존성까지 모두 설치
RUN npm install

# 로그와 캐시 파일도 포함됨
# node_modules, .git, test 파일도 모두 포함

CMD ["node", "server.js"]

# 결과: 1.5 GB 이미지
```

**문제점**:
1. `.dockerignore`가 없어 불필요한 파일까지 포함 (node_modules, .git, logs)
2. 개발 의존성까지 설치 (`npm install` 대신 `npm ci --only=production`)
3. 무거운 베이스 이미지 사용 (node:16은 900MB, alpine은 120MB)
4. 빌드 캐시 최적화 안 됨 (코드 변경 시 매번 npm install)

**해결책**:
```dockerfile
# ✅ 최적화된 Dockerfile

# 1단계: 경량 베이스 이미지
FROM node:16-alpine AS builder

WORKDIR /app

# 2단계: 의존성 파일만 먼저 복사 (캐시 활용)
COPY package*.json ./
RUN npm ci --only=production

# 3단계: 소스 코드 복사
COPY src/ ./src/

# 4단계: 최종 이미지 (멀티스테이지)
FROM node:16-alpine
WORKDIR /app
COPY --from=builder /app .
CMD ["node", "server.js"]

# 결과: 150 MB 이미지 (90% 감소!)
```

**.dockerignore 파일 추가**:
```
node_modules
.git
.gitignore
*.log
test/
coverage/
.env.local
.DS_Store
npm-debug.log*
README.md
Dockerfile
.dockerignore
```

**배운 점**:
- 💡 **팁 1**: 항상 `.dockerignore` 파일 작성 (빌드 컨텍스트 크기 99% 감소)
- 💡 **팁 2**: alpine 베이스 이미지 사용 (크기 80% 감소)
- 💡 **팁 3**: 의존성 파일 먼저 복사 후 `npm ci` (빌드 캐시 활용)
- 💡 **팁 4**: 프로덕션 의존성만 설치 (`--only=production`)

**실측 비교**:
```bash
# Before
$ docker images
myapp    latest    1.5GB

# After
$ docker images
myapp    latest    150MB

# 빌드 시간
Before: 첫 빌드 3분, 코드 수정 후 재빌드 3분 (캐시 없음)
After:  첫 빌드 2분, 코드 수정 후 재빌드 5초 (캐시 활용)
```

---

### 시나리오 2: "npm install이 매번 실행돼요!" (캐시 무효화)

**상황**: 코드 한 줄만 바꿔도 npm install이 다시 실행되어 빌드가 느림

```dockerfile
# ❌ 캐시를 활용하지 못하는 Dockerfile
FROM node:16-alpine

WORKDIR /app

# 모든 파일을 먼저 복사 (잘못된 순서!)
COPY . .

# 의존성 설치
RUN npm install

CMD ["node", "server.js"]

# 문제: src/server.js를 수정하면?
# → COPY . . 단계가 변경됨
# → 그 이후 모든 레이어 무효화
# → npm install 다시 실행 (2분 소요)
```

**왜 이런 일이 발생하는가**:
```
Docker 레이어 캐싱 규칙:
1. 각 명령어는 이전 레이어의 체크섬을 확인
2. 변경이 감지되면 해당 레이어부터 재빌드
3. COPY . .은 모든 파일을 포함
   → 어떤 파일이든 변경되면 무효화
4. 무효화된 레이어 이후는 모두 재빌드

타임라인:
Step 1: FROM node:16-alpine       ✅ 캐시 사용
Step 2: WORKDIR /app              ✅ 캐시 사용
Step 3: COPY . .                  ❌ server.js 변경 감지!
Step 4: RUN npm install           ❌ 캐시 무효화! 다시 실행 (2분)
```

**해결책**:
```dockerfile
# ✅ 캐시 친화적인 Dockerfile
FROM node:16-alpine

WORKDIR /app

# 1️⃣ 의존성 파일만 먼저 복사
COPY package*.json ./

# 2️⃣ 의존성 설치 (자주 변경되지 않음 → 캐시 활용!)
RUN npm ci --only=production

# 3️⃣ 소스 코드는 나중에 복사 (자주 변경됨)
COPY src/ ./src/

CMD ["node", "server.js"]

# 이제 src/server.js 수정 시:
# → Step 1-3 캐시 사용 (npm install 건너뜀!)
# → Step 4만 재실행 (1초)
```

**실제 빌드 비교**:
```bash
# ❌ 캐시 미활용 (매번 npm install)
$ time docker build -t myapp .
[서버 코드 수정]
$ time docker build -t myapp .
Step 1/5 : FROM node:16-alpine
 ---> Using cache
Step 2/5 : WORKDIR /app
 ---> Using cache
Step 3/5 : COPY . .
 ---> a1b2c3d4e5f6  (변경 감지!)
Step 4/5 : RUN npm install
 ---> Running in xyz789...
[npm 패키지 다운로드... 120초]
 ---> b2c3d4e5f6a7
real    2m15s

# ✅ 캐시 활용 (npm install 건너뜀)
$ time docker build -t myapp .
[서버 코드 수정]
$ time docker build -t myapp .
Step 1/5 : FROM node:16-alpine
 ---> Using cache
Step 2/5 : WORKDIR /app
 ---> Using cache
Step 3/5 : COPY package*.json ./
 ---> Using cache  (package.json 변경 없음!)
Step 4/5 : RUN npm ci --only=production
 ---> Using cache  (캐시 히트!)
Step 5/5 : COPY src/ ./src/
 ---> c3d4e5f6a7b8  (코드만 업데이트)
real    0m3s

# 시간 절약: 132초 → 3초 (44배 빠름!)
```

**배운 점**:
- 💡 **팁 1**: 변경 빈도가 낮은 것부터 위에 배치 (package.json → 소스 코드)
- 💡 **팁 2**: `COPY . .`은 최대한 피하고 필요한 파일만 선택적으로 복사
- 💡 **팁 3**: `npm install` 대신 `npm ci` 사용 (더 빠르고 재현 가능)
- 💡 **팁 4**: 빌드 후 `---> Using cache` 메시지 확인 습관화

---

### 시나리오 3: "컨테이너에서 파일 수정했는데 사라졌어요!" (Copy-on-Write 오해)

**상황**: 컨테이너에서 설정 파일을 수정했는데 재시작하면 사라짐

```bash
# 컨테이너 실행
$ docker run -d --name mynginx nginx

# 컨테이너 내부에서 설정 파일 수정
$ docker exec mynginx bash -c "echo 'Modified' > /etc/nginx/nginx.conf"

# 수정 확인
$ docker exec mynginx cat /etc/nginx/nginx.conf
Modified  ✅

# 컨테이너 재시작
$ docker restart mynginx

# 설정 확인
$ docker exec mynginx cat /etc/nginx/nginx.conf
[원본 nginx 설정...]  ❌ 수정 사항이 사라짐!
```

**왜 이런 일이 발생하는가**:
```
Docker 레이어 구조:
┌─────────────────────┐
│ Container Layer     │  읽기/쓰기 (임시!)
│ - 수정된 파일       │  ← 여기에 저장됨
│ - 새로 생성된 파일  │  ← 컨테이너 삭제 시 사라짐!
├─────────────────────┤
│ Image Layers        │  읽기 전용 (영구)
│ - nginx.conf (원본) │  ← 재시작 시 이걸 사용
└─────────────────────┘

문제:
1. 컨테이너에서 파일 수정 → Container Layer에 복사 (Copy-on-Write)
2. 컨테이너 재시작 → Container Layer는 유지됨 ✅
3. 컨테이너 삭제 후 재생성 → Container Layer 삭제됨! ❌
4. 새 컨테이너 → 원본 이미지 레이어만 사용
```

**주니어의 실수**:
```bash
# ❌ 잘못된 방법: 런타임에 설정 변경
$ docker run -d --name myapp myapp:latest
$ docker exec myapp bash -c "echo 'production' > /app/config.txt"
# → 재배포 시 설정 사라짐!

# ❌ 임시 방편: 컨테이너를 계속 유지
$ docker commit myapp myapp:v2  # 안티패턴!
# → 이미지가 비대해지고, 재현성 없음
```

**해결책 1: 빌드 타임에 설정 포함**:
```dockerfile
# ✅ Dockerfile에 설정 포함
FROM nginx:alpine

# 커스텀 설정 파일 복사 (이미지 레이어로 고정)
COPY custom-nginx.conf /etc/nginx/nginx.conf
COPY app.conf /etc/nginx/conf.d/

# 이제 영구적으로 저장됨!
```

**해결책 2: 볼륨 마운트 사용**:
```bash
# ✅ 호스트 파일을 마운트
$ docker run -d \
  --name mynginx \
  -v ./custom-nginx.conf:/etc/nginx/nginx.conf:ro \
  nginx

# 이제 호스트에서 수정하면 컨테이너에 즉시 반영
$ vim custom-nginx.conf
$ docker exec mynginx nginx -s reload
```

**해결책 3: ConfigMap/Secret (Kubernetes)**:
```yaml
# ✅ Kubernetes 환경
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
data:
  nginx.conf: |
    # 설정 내용...
---
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: nginx
    image: nginx
    volumeMounts:
    - name: config
      mountPath: /etc/nginx/nginx.conf
      subPath: nginx.conf
  volumes:
  - name: config
    configMap:
      name: nginx-config
```

**배운 점**:
- 💡 **팁 1**: 컨테이너 내부 수정은 임시적! 영구 저장 필요 시 이미지 빌드 또는 볼륨 사용
- 💡 **팁 2**: `docker commit`은 안티패턴 (재현성 없고 비대해짐)
- 💡 **팁 3**: 설정 파일은 빌드 타임(Dockerfile) 또는 볼륨으로 관리
- 💡 **팁 4**: 불변 인프라(Immutable Infrastructure) 원칙 준수

**비교표**:
| 방법 | 영구성 | 재현성 | 관리성 | 추천도 |
|------|--------|--------|--------|--------|
| 런타임 수정 | ❌ | ❌ | ❌ | ⭐☆☆☆☆ |
| docker commit | △ | ❌ | ❌ | ⭐☆☆☆☆ |
| Dockerfile COPY | ✅ | ✅ | ✅ | ⭐⭐⭐⭐⭐ |
| 볼륨 마운트 | ✅ | ✅ | ✅ | ⭐⭐⭐⭐⭐ |

---

### 시나리오 4: "디스크가 가득 찼어요!" (레이어 정리 안 함)

**상황**: Docker 사용 중 디스크 공간이 부족해짐

```bash
# 어느 날 갑자기...
$ docker build -t myapp .
ERROR: failed to solve: write /var/lib/docker/...: no space left on device

# 디스크 확인
$ df -h
Filesystem      Size  Used  Avail Use% Mounted on
/dev/sda1       100G  98G   2G   98%  /

# Docker가 차지하는 공간
$ sudo du -sh /var/lib/docker/
85G    /var/lib/docker/
```

**왜 이런 일이 발생하는가**:
```
Docker는 다음을 자동으로 삭제하지 않음:

1. 중지된 컨테이너
   $ docker ps -a
   (수십 개의 Exited 컨테이너들)

2. 태그 없는 이미지 (dangling images)
   $ docker images -f "dangling=true"
   <none>    <none>    500MB
   <none>    <none>    800MB
   (빌드 실패 시 생성된 중간 레이어들)

3. 사용하지 않는 볼륨
   $ docker volume ls
   (삭제된 컨테이너의 볼륨들)

4. 빌드 캐시
   $ docker system df
   Build Cache    45GB

5. overlay2 레이어 중복
   $ sudo du -sh /var/lib/docker/overlay2/
   60GB
```

**주니어의 실수**:
```bash
# ❌ 이미지를 계속 빌드만 함 (정리 안 함)
$ docker build -t myapp:v1 .
$ docker build -t myapp:v2 .
$ docker build -t myapp:v3 .
...
$ docker build -t myapp:v50 .
# → 50개 이미지가 모두 저장됨!

# ❌ 테스트 컨테이너를 --rm 없이 실행
$ docker run myapp test1
$ docker run myapp test2
$ docker run myapp test3
...
# → 모든 컨테이너가 Exited 상태로 남음

# ❌ 빌드 실패를 반복
$ docker build -t myapp .
ERROR: ...
$ docker build -t myapp .
ERROR: ...
# → 중간 레이어가 계속 쌓임
```

**해결책 1: 즉시 정리**:
```bash
# ✅ 모든 사용하지 않는 것 삭제 (가장 강력)
$ docker system prune -a --volumes
WARNING! This will remove:
  - all stopped containers
  - all networks not used by at least one container
  - all images without at least one container associated to them
  - all build cache
  - all volumes not used by at least one container

Are you sure? [y/N] y

Deleted Containers: 42
Deleted Images: 67
Deleted Networks: 5
Deleted Volumes: 12
Total reclaimed space: 73.5GB  🎉

# 결과 확인
$ docker system df
TYPE            TOTAL   ACTIVE   SIZE
Images          5       3        2.1GB
Containers      3       3        100MB
Local Volumes   2       2        500MB
Build Cache     0       0        0B
```

**해결책 2: 선택적 정리**:
```bash
# ✅ 중지된 컨테이너만 삭제
$ docker container prune
Deleted Containers: 15
Total reclaimed space: 2.5GB

# ✅ dangling 이미지만 삭제
$ docker image prune
Deleted Images: 23
Total reclaimed space: 15.3GB

# ✅ 사용하지 않는 볼륨 삭제
$ docker volume prune
Deleted Volumes: 8
Total reclaimed space: 8.2GB

# ✅ 빌드 캐시 삭제
$ docker builder prune
Deleted build cache: 35GB
```

**해결책 3: 예방 습관**:
```bash
# ✅ 테스트 컨테이너는 --rm 사용
$ docker run --rm myapp npm test
# → 종료 시 자동 삭제

# ✅ 이전 이미지 태그 덮어쓰기
$ docker build -t myapp:latest .
# → 같은 태그 사용 (이전 이미지는 <none>으로 변경)

# ✅ 정기적인 정리 스크립트
$ crontab -e
# 매주 일요일 새벽 3시에 정리
0 3 * * 0 docker system prune -f --volumes

# ✅ 디스크 사용량 모니터링
$ docker system df -v
# 어떤 이미지/컨테이너가 공간을 많이 차지하는지 확인
```

**해결책 4: 빌드 최적화로 예방**:
```dockerfile
# ✅ 이미지 크기 자체를 줄이기
FROM node:16-alpine  # ubuntu 대신 alpine

# ✅ 불필요한 파일 제거
RUN apk add --no-cache \
    git \
    python3 \
 && rm -rf /var/cache/apk/*  # 캐시 삭제

# ✅ 멀티스테이지 빌드
FROM golang:1.18 AS builder
RUN go build -o app

FROM alpine:latest
COPY --from=builder /app/app .
# → 빌드 도구는 최종 이미지에 포함 안 됨
```

**배운 점**:
- 💡 **팁 1**: 개발 중에는 매주 `docker system prune -a` 실행
- 💡 **팁 2**: 프로덕션에서는 신중하게 선택적 정리 (`-a` 플래그 주의)
- 💡 **팁 3**: 테스트 컨테이너는 항상 `--rm` 플래그 사용
- 💡 **팁 4**: `docker system df`로 주기적으로 모니터링
- 💡 **팁 5**: CI/CD 파이프라인에 정리 단계 포함

**정리 명령어 치트시트**:
```bash
# 안전한 정리 (사용 중인 것은 제외)
docker container prune  # 중지된 컨테이너
docker image prune      # dangling 이미지
docker volume prune     # 사용 안 하는 볼륨
docker network prune    # 사용 안 하는 네트워크

# 전체 정리 (주의!)
docker system prune -a --volumes  # 모든 것 삭제

# 강제 정리 (확인 안 함)
docker system prune -f

# 공간 확인
docker system df        # 요약
docker system df -v     # 상세
```

---

## ❓ FAQ

<details>
<summary><strong>Q1: 레이어는 최대 몇 개까지 만들 수 있나요?</strong></summary>

**A**: 이론적으로는 제한이 없지만, 실무에서는 **10-20개 이내**를 권장합니다.

**상세 설명**:
- Docker는 레이어 수에 하드 리밋이 없음
- 하지만 레이어가 많을수록:
  - 이미지 pull/push 시간 증가 (각 레이어마다 네트워크 요청)
  - 파일 시스템 오버헤드 증가 (OverlayFS 검색 시간)
  - 빌드 복잡도 증가

**예시**:
```dockerfile
# ❌ 나쁜 예: 레이어 너무 많음 (50개!)
FROM ubuntu
RUN apt-get update
RUN apt-get install -y curl
RUN apt-get install -y git
RUN apt-get install -y vim
... (50개 RUN 명령어)

# ✅ 좋은 예: 레이어 최소화 (5개)
FROM ubuntu
RUN apt-get update && \
    apt-get install -y \
        curl \
        git \
        vim && \
    rm -rf /var/lib/apt/lists/*
```

**실무 팁**:
💡 Dockerfile 명령어를 기능별로 그룹화하여 5-15개 레이어로 유지

**측정 방법**:
```bash
$ docker history myapp:latest | wc -l
18  # 18개 레이어 (적당함)
```

</details>

<details>
<summary><strong>Q2: 같은 이미지로 만든 100개 컨테이너는 디스크를 100배 사용하나요?</strong></summary>

**A**: **아니오!** 이미지 레이어는 공유되므로 추가 디스크는 거의 사용하지 않습니다.

**상세 설명**:
```
1개 이미지 (500MB) + 100개 컨테이너 = ?

❌ 예상: 500MB × 100 = 50GB
✅ 실제: 500MB (이미지) + 100MB (100개 컨테이너 레이어)
       = 약 600MB (99% 절약!)

이유:
┌─────────────────────┐
│ 이미지 레이어 500MB │ ← 100개 컨테이너가 공유!
└─────────────────────┘
    ↑ ↑ ↑ ... ↑ ↑
    │ │ │     │ │
    C1 C2 C3...C99 C100
    (각 1MB)
```

**실제 테스트**:
```bash
# nginx 이미지 크기
$ docker images nginx
nginx   latest   141MB

# 100개 컨테이너 실행
$ for i in {1..100}; do
    docker run -d --name nginx$i nginx
  done

# 실제 디스크 사용량
$ docker system df
Images        1       141MB
Containers    100     50MB   # 100개인데 50MB만!

# 이유: 컨테이너 레이어는 거의 비어있음 (변경 사항 없음)
```

**실무 팁**:
💡 같은 베이스 이미지를 사용하는 마이크로서비스 아키텍처에서 엄청난 공간 절약 효과!

</details>

<details>
<summary><strong>Q3: 파일을 삭제해도 이미지 크기가 줄어들지 않는 이유는?</strong></summary>

**A**: 레이어는 **추가만 가능(Append-only)**하고 수정/삭제가 불가능하기 때문입니다.

**상세 설명**:
```dockerfile
# ❌ 잘못된 이해
FROM ubuntu
RUN wget https://example.com/bigfile.zip  # 100MB 추가
RUN unzip bigfile.zip                     # 100MB 압축 해제
RUN rm bigfile.zip                        # 삭제했으니 100MB 감소?

# 실제 레이어 구조:
Layer 1: ubuntu (50MB)
Layer 2: + bigfile.zip (100MB)     ← 여전히 존재!
Layer 3: + 압축 해제된 파일 (100MB)
Layer 4: + .wh.bigfile.zip (0B)    ← 삭제 표시만 (Whiteout)

최종 이미지: 50 + 100 + 100 = 250MB (bigfile.zip 포함!)
```

**해결책**:
```dockerfile
# ✅ 같은 레이어에서 다운로드 → 사용 → 삭제
FROM ubuntu
RUN wget https://example.com/bigfile.zip && \
    unzip bigfile.zip && \
    rm bigfile.zip  # 같은 RUN 명령어 안에서 삭제!

# 레이어 구조:
Layer 1: ubuntu (50MB)
Layer 2: + 압축 해제된 파일만 (100MB)

최종 이미지: 50 + 100 = 150MB (100MB 절약!)
```

**실무 팁**:
💡 **파일 다운로드 → 사용 → 삭제는 반드시 한 줄로!** (&&로 연결)

**검증 방법**:
```bash
$ docker history myapp:latest
# SIZE 컬럼에서 각 레이어 크기 확인
```

</details>

<details>
<summary><strong>Q4: 빌드 캐시를 강제로 무시하고 싶을 때는?</strong></summary>

**A**: `--no-cache` 플래그를 사용하면 모든 레이어를 처음부터 다시 빌드합니다.

**사용 상황**:
1. 외부 패키지 최신 버전 다운로드 필요
2. 베이스 이미지 업데이트 확인
3. 빌드 캐시가 손상됨
4. 재현 가능한 빌드 확인 (CI/CD)

**명령어**:
```bash
# 전체 캐시 무시
$ docker build --no-cache -t myapp:latest .

# 특정 레이어부터 캐시 무시
$ docker build --cache-from=myapp:v1 -t myapp:v2 .

# 외부 리소스만 새로 다운로드 (부분 캐시 무시)
$ docker build --pull -t myapp:latest .
# → FROM 이미지만 강제로 최신으로 pull
```

**예시**:
```dockerfile
FROM node:16-alpine

WORKDIR /app

# 이 부분은 매번 최신 버전을 받고 싶음
RUN npm install -g some-tool@latest

COPY . .
```

```bash
# ❌ 캐시 사용 (오래된 버전 유지)
$ docker build -t myapp .
# → some-tool은 이전 버전 그대로

# ✅ 캐시 무시 (최신 버전 다운로드)
$ docker build --no-cache -t myapp .
# → some-tool 최신 버전 설치
```

**실무 팁**:
💡 개발 중: 캐시 활용 (빠른 빌드)
💡 프로덕션 배포: `--no-cache` 사용 (재현성 보장)

**CI/CD 예시**:
```yaml
# GitHub Actions
- name: Build Docker image
  run: docker build --no-cache -t $IMAGE_NAME .
```

</details>

<details>
<summary><strong>Q5: OverlayFS 말고 다른 스토리지 드라이버를 사용해야 할 때는?</strong></summary>

**A**: 대부분의 경우 **OverlayFS로 충분**하지만, 특정 상황에서는 다른 드라이버가 필요합니다.

**상세 설명**:

| 상황 | 추천 드라이버 | 이유 |
|------|---------------|------|
| **일반적인 경우** | overlay2 | 성능 최고, 안정성 우수 |
| **커널 3.x** | aufs | overlay2 미지원 |
| **ZFS 파일 시스템** | zfs | Native 지원 |
| **Btrfs 파일 시스템** | btrfs | Native 지원 |
| **RHEL/CentOS 7** | devicemapper | 기본값 (overlay2로 변경 권장) |
| **Windows 컨테이너** | windowsfilter | Windows 전용 |

**현재 드라이버 확인**:
```bash
$ docker info | grep "Storage Driver"
Storage Driver: overlay2
```

**드라이버 변경** (주의: 기존 컨테이너/이미지 삭제됨!):
```bash
# 1. Docker 중지
$ sudo systemctl stop docker

# 2. 설정 파일 수정
$ sudo vim /etc/docker/daemon.json
{
  "storage-driver": "overlay2"
}

# 3. Docker 재시작
$ sudo systemctl start docker

# 4. 확인
$ docker info | grep "Storage Driver"
```

**실무 팁**:
💡 특별한 이유가 없으면 **overlay2 그대로 사용** (99% 케이스)
💡 커널 버전 확인: `uname -r` (4.0 이상이면 overlay2 가능)

**성능 비교**:
```
파일 읽기 속도 (상대적):
overlay2:    ⭐⭐⭐⭐⭐ (100%)
aufs:        ⭐⭐⭐⭐  (85%)
devicemapper:⭐⭐⭐   (70%)
btrfs:       ⭐⭐⭐⭐  (80%)
```

</details>

<details>
<summary><strong>Q6: 멀티스테이지 빌드는 언제 사용해야 하나요?</strong></summary>

**A**: **컴파일/빌드가 필요한 언어**(Go, Java, Rust 등)나 **개발 도구가 프로덕션에 불필요한 경우** 필수입니다.

**상세 설명**:

**사용해야 하는 경우**:
1. Go, Rust, C/C++ 등 컴파일 언어
2. Java, Gradle/Maven 빌드 도구
3. Node.js에서 TypeScript 컴파일
4. React/Vue 빌드 후 정적 파일만 배포
5. Python에서 Cython 컴파일

**예시 1: Go 애플리케이션**
```dockerfile
# ❌ 멀티스테이지 없이 (800MB!)
FROM golang:1.18
WORKDIR /app
COPY . .
RUN go build -o myapp
CMD ["./myapp"]
# → Go 컴파일러, SDK 모두 포함

# ✅ 멀티스테이지 (15MB!)
FROM golang:1.18 AS builder
WORKDIR /app
COPY . .
RUN go build -o myapp

FROM alpine:latest
WORKDIR /app
COPY --from=builder /app/myapp .
CMD ["./myapp"]
# → 실행 파일만 포함
```

**예시 2: React 앱**
```dockerfile
# ❌ 멀티스테이지 없이 (1.2GB!)
FROM node:16
WORKDIR /app
COPY . .
RUN npm install
RUN npm run build
CMD ["npm", "start"]
# → node_modules, 개발 도구 모두 포함

# ✅ 멀티스테이지 (25MB!)
FROM node:16 AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/build /usr/share/nginx/html
# → 빌드된 정적 파일만 포함
```

**실무 팁**:
💡 **빌드 도구가 런타임에 필요 없으면 멀티스테이지 필수!**

**이미지 크기 비교**:
| 언어 | 단일 스테이지 | 멀티 스테이지 | 절약 |
|------|---------------|---------------|------|
| Go | 800MB | 15MB | **98%** |
| Java | 600MB | 150MB | **75%** |
| Node.js | 1.2GB | 50MB | **96%** |
| Rust | 2GB | 10MB | **99%** |

</details>

<details>
<summary><strong>Q7: 레이어 수를 줄이는 게 항상 좋은가요?</strong></summary>

**A**: **아니오!** 캐시 효율과 가독성을 고려해야 합니다. 무조건 줄이는 것보다 **전략적으로 그룹화**하는 게 중요합니다.

**상세 설명**:

**❌ 너무 레이어를 줄인 경우 (비효율적)**:
```dockerfile
FROM node:16-alpine
WORKDIR /app

# 모든 것을 한 레이어로 (나쁜 예!)
COPY . . && \
  npm install && \
  echo "Done"

# 문제:
# - package.json만 바뀌어도 COPY . .부터 다시 실행
# - 소스 코드만 바뀌어도 npm install 다시 실행
# - 캐시 효율 0%
```

**✅ 전략적으로 그룹화 (효율적)**:
```dockerfile
FROM node:16-alpine

WORKDIR /app

# 레이어 1: 의존성 정의 (거의 안 바뀜)
COPY package*.json ./

# 레이어 2: 의존성 설치 (package.json 변경 시만 재실행)
RUN npm ci --only=production

# 레이어 3: 소스 코드 (자주 바뀜)
COPY src/ ./src/

# 레이어 4: 시작 명령 (메타데이터만, 0B)
CMD ["node", "src/server.js"]

# 전략:
# - 변경 빈도별로 분리 (자주 바뀌는 것은 뒤로)
# - 시간이 오래 걸리는 작업(npm install)은 캐시 활용
# - 총 4개 레이어 (적당함)
```

**레이어 그룹화 전략**:
```
변경 빈도:
낮음 ────────────────────────> 높음

[베이스]  [시스템]  [의존성]  [설정]  [코드]
Layer 1   Layer 2   Layer 3   Layer 4  Layer 5

예시:
ubuntu → apt-get → npm install → 환경변수 → 소스코드
(재사용) (월 1회)  (주 1회)      (일 1회)  (시간마다)
```

**실무 가이드라인**:
| 항목 | 권장 레이어 수 | 이유 |
|------|----------------|------|
| **베이스 이미지** | 1개 | FROM |
| **시스템 패키지** | 1-2개 | apt-get, apk 등 그룹화 |
| **언어 런타임** | 1개 | Node.js, Python 등 |
| **의존성** | 1-2개 | npm install, pip install |
| **애플리케이션 코드** | 1-3개 | 설정 → 라이브러리 → 메인 코드 |
| **메타데이터** | n개 | CMD, EXPOSE 등 (0B) |
| **총합** | **5-10개** | 캐시 효율 + 가독성 균형 |

**실무 팁**:
💡 **레이어 수보다 캐시 전략이 더 중요!**
💡 시간이 오래 걸리는 작업(설치)은 별도 레이어로 분리
💡 자주 바뀌는 코드는 마지막에 배치

</details>

---

## 💼 면접 질문 리스트

### 📘 주니어/신입 개발자용 (5-7개)

<details>
<summary><strong>1. Docker 이미지의 레이어란 무엇이며, 왜 필요한가요?</strong></summary>

**모범 답안 포인트**
- Docker 이미지는 여러 개의 읽기 전용 레이어로 구성됨
- Dockerfile의 각 명령어(RUN, COPY 등)가 새로운 레이어를 생성
- 레이어 재사용으로 저장 공간 절약 및 빌드 속도 향상
- 불변성(Immutability) 보장으로 안정성 확보

**예시 답변**
> "Docker 이미지의 레이어는 Dockerfile의 각 명령어가 만드는 읽기 전용 파일 시스템 계층입니다. 예를 들어 `FROM ubuntu`, `RUN apt-get update`, `COPY app.js` 각각이 별도의 레이어를 생성합니다. 이러한 레이어 구조는 여러 이미지가 같은 베이스 레이어를 공유할 수 있게 하여 디스크 공간을 절약하고, 변경되지 않은 레이어는 캐시를 활용하여 빌드 시간을 단축시킵니다. 또한 레이어가 불변이기 때문에 이미지의 일관성과 재현성을 보장할 수 있습니다."

**꼬리 질문**
- Q: 레이어는 최대 몇 개까지 만들 수 있나요?
- A: 이론적으로는 제한이 없지만 실무에서는 10-20개 이내로 유지하는 것이 좋습니다. 레이어가 너무 많으면 이미지 pull/push 속도가 느려지고 파일 시스템 오버헤드가 증가합니다.

**실무 연관**
- 마이크로서비스 아키텍처에서 수십 개 서비스가 같은 베이스 이미지를 공유하면 수 GB의 저장 공간을 절약할 수 있음
- CI/CD 파이프라인에서 빌드 캐시 활용 시 빌드 시간을 수 분에서 수 초로 단축 가능

</details>

<details>
<summary><strong>2. Dockerfile에서 RUN 명령어를 여러 개 쓰는 것과 &&로 연결하는 것의 차이는?</strong></summary>

**모범 답안 포인트**
- 각 RUN은 별도의 레이어를 생성
- &&로 연결하면 하나의 레이어만 생성
- 임시 파일 삭제는 반드시 같은 RUN 명령어 안에서
- 레이어 수가 적을수록 이미지 크기 감소

**예시 답변**
> "RUN 명령어를 여러 번 사용하면 각각이 별도의 레이어를 만들지만, &&로 연결하면 하나의 레이어로 합쳐집니다. 중요한 차이는 파일 삭제 시 나타나는데, 예를 들어 `RUN wget file.zip`와 `RUN rm file.zip`을 분리하면 첫 번째 레이어에 file.zip이 영구적으로 남아 이미지 크기가 줄지 않습니다. 하지만 `RUN wget file.zip && unzip file.zip && rm file.zip`처럼 한 줄로 작성하면 최종 레이어에는 압축 해제된 파일만 포함되어 이미지 크기가 크게 줄어듭니다."

**꼬리 질문**
- Q: 그럼 모든 RUN 명령어를 하나로 합치는 게 가장 좋은가요?
- A: 아닙니다. 빌드 캐시 효율을 고려해야 합니다. 자주 변경되지 않는 시스템 패키지 설치는 하나의 RUN으로, 애플리케이션 의존성은 별도 RUN으로 분리하는 것이 좋습니다.

**실무 연관**
- 프로덕션 이미지 최적화 시 필수 기법
- 이미지 크기가 1GB에서 100MB로 줄어드는 사례 흔함

</details>

<details>
<summary><strong>3. Docker 빌드 캐시는 어떻게 작동하며, 언제 무효화되나요?</strong></summary>

**모범 답안 포인트**
- 각 레이어는 체크섬으로 식별됨
- 이전 빌드의 레이어와 동일하면 캐시 사용
- 한 레이어가 변경되면 그 이후 모든 레이어 무효화
- COPY/ADD는 파일 내용의 체크섬으로 판단

**예시 답변**
> "Docker는 Dockerfile의 각 명령어를 순차적으로 실행하며, 각 레이어의 체크섬을 계산하여 이전 빌드와 비교합니다. 명령어와 파일 내용이 동일하면 캐시된 레이어를 재사용하지만, 한 레이어라도 변경되면 그 이후의 모든 레이어가 무효화되어 재빌드됩니다. 예를 들어 `COPY package.json`과 `RUN npm install` 후 `COPY src/`가 있을 때, 소스 코드만 변경되면 npm install은 캐시를 사용하지만, package.json이 변경되면 npm install부터 다시 실행됩니다."

**꼬리 질문**
- Q: 빌드 캐시를 강제로 무시하려면?
- A: `docker build --no-cache` 플래그를 사용하면 모든 레이어를 처음부터 다시 빌드합니다. CI/CD에서 재현 가능한 빌드를 보장할 때 사용합니다.

**실무 연관**
- 개발 중 코드 수정 후 빌드 시간을 수 분에서 수 초로 단축
- package.json과 소스 코드 복사 순서 최적화가 핵심

</details>

<details>
<summary><strong>4. Copy-on-Write란 무엇이며 Docker에서 어떻게 사용되나요?</strong></summary>

**모범 답안 포인트**
- "읽기는 공유, 쓰기는 복사" 전략
- 컨테이너에서 파일 수정 시 Upper Layer로 복사 후 수정
- 원본 이미지 레이어는 읽기 전용으로 보호됨
- 여러 컨테이너가 같은 이미지 레이어 공유 가능

**예시 답변**
> "Copy-on-Write는 파일을 읽을 때는 원본을 공유하고, 수정할 때만 복사본을 만드는 효율적인 전략입니다. Docker에서는 이미지 레이어를 여러 컨테이너가 읽기 전용으로 공유하며, 컨테이너가 파일을 수정하려 할 때 해당 파일만 컨테이너의 쓰기 가능 레이어로 복사한 뒤 수정합니다. 예를 들어 nginx 이미지로 100개 컨테이너를 실행해도 이미지는 한 번만 저장되고, 각 컨테이너가 설정 파일을 수정하면 그 파일만 개별적으로 복사됩니다."

**꼬리 질문**
- Q: 큰 파일을 수정하면 성능에 영향이 있나요?
- A: 네, 1GB 파일을 처음 수정할 때는 전체 파일이 복사되어 수십 초가 걸릴 수 있습니다. 이런 경우 볼륨 마운트를 사용하는 것이 좋습니다.

**실무 연관**
- 대용량 데이터베이스 파일이나 로그 파일은 볼륨으로 관리
- 컨테이너 내부 수정은 임시적이므로 영구 데이터는 볼륨 사용

</details>

<details>
<summary><strong>5. .dockerignore 파일의 역할과 중요성은?</strong></summary>

**모범 답안 포인트**
- 빌드 컨텍스트에서 제외할 파일/디렉토리 지정
- 불필요한 파일 전송 방지로 빌드 속도 향상
- 민감한 정보(.env 등) 이미지에 포함되는 것 방지
- .gitignore와 유사한 문법

**예시 답변**
> ".dockerignore는 Docker 빌드 시 빌드 컨텍스트에서 제외할 파일을 지정하는 파일입니다. node_modules, .git, 로그 파일 등 불필요한 파일을 제외하면 빌드 컨텍스트 전송 시간이 크게 단축됩니다. 예를 들어 1.5GB의 프로젝트 디렉토리에서 node_modules와 .git을 제외하면 50MB만 전송되어 빌드 시작 시간이 30초에서 1초로 줄어듭니다. 또한 .env.local 같은 민감한 파일이 이미지에 포함되는 것을 방지하는 보안적 역할도 합니다."

**꼬리 질문**
- Q: .dockerignore에 무엇을 넣어야 하나요?
- A: node_modules(재설치 필요), .git(불필요), *.log(로그 파일), test/(테스트 코드), .env.local(로컬 설정) 등이 일반적입니다.

**실무 연관**
- 모든 프로젝트에 .dockerignore 필수
- CI/CD에서 빌드 시간 단축에 큰 영향

</details>

<details>
<summary><strong>6. Union File System (OverlayFS)는 무엇이며 어떤 역할을 하나요?</strong></summary>

**모범 답안 포인트**
- 여러 디렉토리를 하나로 합쳐서 보여주는 파일 시스템
- Upper Layer (컨테이너, R/W) + Lower Layers (이미지, R/O)
- Merged 뷰로 통합된 파일 시스템 제공
- Whiteout 파일로 삭제 표시

**예시 답변**
> "Union File System은 여러 개의 독립적인 파일 시스템 레이어를 하나의 통합된 뷰로 보여주는 기술입니다. Docker는 OverlayFS를 기본으로 사용하며, 읽기 전용인 이미지 레이어들(Lower Layers)과 읽기/쓰기 가능한 컨테이너 레이어(Upper Layer)를 합쳐서 하나의 파일 시스템(Merged)으로 제공합니다. 마치 투명한 필름을 여러 장 겹쳐놓은 것처럼 작동하며, 컨테이너 내부에서는 하나의 통합된 파일 시스템으로 보입니다."

**꼬리 질문**
- Q: 파일을 삭제하면 어떻게 되나요?
- A: 실제로 삭제되지 않고 Upper Layer에 Whiteout 파일(.wh.파일명)이 생성되어 삭제된 것처럼 보이게 합니다. 원본은 Lower Layer에 그대로 남아있습니다.

**실무 연관**
- Docker의 핵심 기술로 레이어 공유의 기반
- 대부분의 경우 기본 설정(overlay2) 그대로 사용

</details>

<details>
<summary><strong>7. 멀티스테이지 빌드는 언제 사용하며 어떤 장점이 있나요?</strong></summary>

**모범 답안 포인트**
- 빌드 단계와 실행 단계를 분리
- 빌드 도구는 최종 이미지에 포함되지 않음
- 이미지 크기를 크게 줄일 수 있음 (80-99%)
- Go, Java, Rust 등 컴파일 언어에 필수

**예시 답변**
> "멀티스테이지 빌드는 Dockerfile에 여러 개의 FROM 문을 사용하여 빌드 단계와 실행 단계를 분리하는 기법입니다. 첫 번째 스테이지에서 컴파일러나 빌드 도구로 애플리케이션을 빌드하고, 두 번째 스테이지에서는 빌드된 결과물만 가져와 실행합니다. 예를 들어 Go 애플리케이션의 경우 golang:1.18 이미지로 빌드하면 800MB이지만, 멀티스테이지로 alpine에 실행 파일만 복사하면 15MB로 줄어듭니다. 이는 보안성도 향상시키는데, 최종 이미지에 컴파일러나 빌드 도구가 없어 공격 표면이 줄어들기 때문입니다."

**꼬리 질문**
- Q: Node.js나 Python 같은 인터프리터 언어에서도 유용한가요?
- A: 네, 특히 프론트엔드 빌드(React, Vue)에서 매우 유용합니다. 빌드 단계에서 npm install과 빌드를 수행하고, 실행 단계에서는 nginx로 정적 파일만 서빙하면 이미지 크기를 95% 이상 줄일 수 있습니다.

**실무 연관**
- 프로덕션 이미지 최적화의 핵심 기법
- Kubernetes 환경에서 이미지 pull 시간 단축

</details>

---

### 📗 중급 개발자용 (3-5개)

<details>
<summary><strong>1. Docker 이미지 레이어의 내부 구조와 저장 방식을 설명하고, overlay2의 LowerDir, UpperDir, MergedDir, WorkDir의 역할을 설명하세요.</strong></summary>

**모범 답안 포인트**
- 각 레이어는 /var/lib/docker/overlay2/에 디렉토리로 저장
- LowerDir: 읽기 전용 이미지 레이어들 (콜론으로 구분, 여러 개)
- UpperDir: 읽기/쓰기 컨테이너 레이어 (변경 사항 저장)
- MergedDir: 통합된 최종 뷰 (컨테이너 내부에서 보이는 것)
- WorkDir: OverlayFS 내부 작업용 (원자적 연산)

**예시 답변**
> "Docker의 overlay2 스토리지 드라이버는 /var/lib/docker/overlay2/ 디렉토리에 각 레이어를 저장합니다. LowerDir는 이미지의 읽기 전용 레이어들을 콜론으로 구분한 경로 목록이며, 여러 컨테이너가 공유합니다. UpperDir는 컨테이너별 읽기/쓰기 레이어로, 컨테이너에서의 모든 변경 사항이 여기에 저장됩니다. MergedDir는 Lower와 Upper를 합친 최종 뷰로, 컨테이너의 루트 파일 시스템이 되며 마운트됩니다. WorkDir는 OverlayFS가 내부적으로 파일 복사나 삭제 같은 원자적 연산을 수행할 때 사용하는 임시 작업 공간입니다. 이 구조 덕분에 파일 수정 시 Copy-on-Write가 효율적으로 작동하고, 여러 컨테이너가 안전하게 레이어를 공유할 수 있습니다."

**실무 예시**
```bash
$ docker inspect mycontainer | grep -A 10 GraphDriver
"GraphDriver": {
    "Data": {
        "LowerDir": "/var/lib/docker/overlay2/abc.../diff:/var/lib/docker/overlay2/def.../diff",
        "MergedDir": "/var/lib/docker/overlay2/xyz.../merged",
        "UpperDir": "/var/lib/docker/overlay2/xyz.../diff",
        "WorkDir": "/var/lib/docker/overlay2/xyz.../work"
    }
}

# UpperDir 내용 확인
$ sudo ls /var/lib/docker/overlay2/xyz.../diff/
etc/  tmp/  var/  # 컨테이너에서 변경된 파일들만
```

**꼬리 질문**
- Q: WorkDir가 왜 필요한가요?
- A: 파일 수정이나 삭제 시 원자적(atomic) 연산을 보장하기 위해서입니다. 예를 들어 큰 파일을 복사할 때 WorkDir에서 먼저 작업한 후 완료되면 UpperDir로 이동시켜 중간 실패 시 일관성을 유지합니다.

**실무 연관**
- 컨테이너 디버깅 시 UpperDir를 직접 조사하여 변경 사항 추적
- 디스크 공간 문제 발생 시 overlay2 디렉토리 크기 분석

</details>

<details>
<summary><strong>2. 프로덕션 환경에서 이미지 크기 최적화 전략을 단계별로 설명하고, 각 단계의 예상 개선 효과를 수치로 제시하세요.</strong></summary>

**모범 답안 포인트**
- 경량 베이스 이미지 선택 (alpine, distroless)
- 멀티스테이지 빌드로 빌드 도구 제거
- RUN 명령어 체이닝과 캐시 정리
- .dockerignore로 빌드 컨텍스트 최적화
- 불필요한 파일 제거 (문서, 테스트)

**예시 답변**
> "프로덕션 이미지 최적화는 다음 5단계로 진행합니다. 1단계: 베이스 이미지를 ubuntu(72MB)에서 alpine(7MB)으로 변경하여 90% 감소. 2단계: 멀티스테이지 빌드 적용으로 빌드 도구 제거, Go 기준 800MB에서 15MB로 98% 감소. 3단계: RUN 명령어를 체이닝하고 `apt-get clean && rm -rf /var/lib/apt/lists/*`로 패키지 캐시 삭제, 추가 30-50MB 절약. 4단계: .dockerignore에 node_modules, .git, test 추가로 빌드 컨텍스트 1.5GB를 50MB로 감소. 5단계: 프로덕션 의존성만 설치(`npm ci --only=production`)로 개발 의존성 제거, 추가 100-200MB 절약. 실제 프로젝트에서 이 전략으로 1.2GB 이미지를 80MB로 줄인 경험이 있으며, 이는 Kubernetes 환경에서 이미지 pull 시간을 5분에서 20초로 단축시켰습니다."

**실무 예시**
```dockerfile
# Before: 1.2GB
FROM node:16
COPY . .
RUN npm install
CMD ["node", "server.js"]

# After: 80MB (93% 감소)
FROM node:16-alpine AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

FROM node:16-alpine
WORKDIR /app
COPY --from=builder /app/node_modules ./node_modules
COPY src/ ./src/
USER node
CMD ["node", "src/server.js"]
```

**꼬리 질문**
- Q: distroless 이미지는 언제 사용하나요?
- A: 최대 보안이 필요한 경우입니다. distroless는 쉘도 없어 공격 표면이 최소화되지만, 디버깅이 어렵습니다. 프로덕션 환경에서 Java, Go, Python 애플리케이션에 주로 사용합니다.

**실무 연관**
- 클라우드 환경에서 이미지 pull 비용 및 시간 절감
- 보안 취약점 스캔 대상 감소

</details>

<details>
<summary><strong>3. Docker 빌드 캐시 전략을 최적화하기 위한 Dockerfile 작성 원칙과, 대규모 프로젝트에서 빌드 시간을 최소화하는 방법을 설명하세요.</strong></summary>

**모범 답안 포인트**
- 변경 빈도에 따라 레이어 순서 배치 (낮음 → 높음)
- 의존성 파일과 소스 코드 COPY 분리
- BuildKit 활용 (병렬 빌드, 캐시 마운트)
- 외부 캐시 활용 (--cache-from, registry)
- CI/CD에서 레이어 캐싱 전략

**예시 답변**
> "빌드 캐시 최적화의 핵심은 변경 빈도가 낮은 것부터 높은 순서로 배치하는 것입니다. 1) 베이스 이미지와 시스템 패키지 설치를 상단에 배치 (월 1회 변경). 2) 의존성 정의 파일(package.json, requirements.txt)만 먼저 COPY하고 설치 (주 1회 변경). 3) 소스 코드는 마지막에 COPY (시간마다 변경). BuildKit을 활성화(`DOCKER_BUILDKIT=1`)하면 병렬 빌드와 캐시 마운트 기능으로 속도가 2-3배 향상됩니다. CI/CD 환경에서는 `--cache-from` 옵션으로 이전 빌드의 레이어를 레지스트리에서 가져와 첫 빌드도 캐시를 활용할 수 있습니다. 실제 프로젝트에서 이 전략으로 평균 빌드 시간을 10분에서 1분으로 단축했으며, 코드만 수정 시에는 10초 내로 빌드가 완료됩니다."

**실무 예시**
```dockerfile
# BuildKit 캐시 마운트 활용
# syntax=docker/dockerfile:1
FROM node:16-alpine

# 1단계: 시스템 패키지 (거의 안 바뀜)
RUN apk add --no-cache python3 make g++

# 2단계: 의존성 파일만 먼저 복사
WORKDIR /app
COPY package*.json ./

# 3단계: npm 캐시 마운트로 재다운로드 방지
RUN --mount=type=cache,target=/root/.npm \
    npm ci --only=production

# 4단계: 소스 코드 (자주 바뀜)
COPY src/ ./src/

CMD ["node", "src/server.js"]
```

```bash
# CI/CD에서 캐시 활용
docker build \
  --cache-from myapp:latest \
  --build-arg BUILDKIT_INLINE_CACHE=1 \
  -t myapp:new .
docker push myapp:new
```

**꼬리 질문**
- Q: monorepo에서 여러 마이크로서비스를 빌드할 때 캐시 전략은?
- A: 공통 의존성은 별도 베이스 이미지로 만들어 공유하고, 각 서비스는 해당 베이스 이미지를 FROM으로 사용합니다. 또한 BuildKit의 `--mount=type=bind`로 필요한 파일만 선택적으로 바인드하여 빌드 컨텍스트를 최소화합니다.

**실무 연관**
- CI/CD 파이프라인 속도 최적화
- 개발자 경험(DX) 향상: 빠른 피드백 루프

</details>

<details>
<summary><strong>4. Copy-on-Write의 성능 특성을 이해하고, 대용량 데이터 처리 시 볼륨과 바인드 마운트 중 어떤 것을 선택해야 하는지 판단 기준을 제시하세요.</strong></summary>

**모범 답안 포인트**
- CoW는 작은 파일에는 효율적이지만 큰 파일은 느림
- 볼륨: Docker가 관리, 성능 최고, 백업 쉬움
- 바인드 마운트: 호스트 경로 직접 연결, 개발 시 편리
- 읽기 전용 데이터는 이미지에, 쓰기 많은 데이터는 볼륨에

**예시 답변**
> "Copy-on-Write는 파일 크기에 따라 성능이 크게 달라집니다. 1KB 파일은 0.5ms에 복사되지만 1GB 파일은 50초가 걸립니다. 따라서 대용량 데이터베이스 파일이나 로그 파일은 반드시 볼륨을 사용해야 합니다. 볼륨과 바인드 마운트의 선택 기준은: 1) 프로덕션 데이터(DB, 로그)는 볼륨 사용 - Docker가 백업/복원을 관리하고 성능이 최적화됨. 2) 개발 중 소스 코드 동기화는 바인드 마운트 - 호스트에서 수정 즉시 컨테이너에 반영. 3) 정적 설정 파일은 이미지에 COPY - 불변성 보장. 4) 자주 변경되는 설정은 ConfigMap/Secret(k8s) 또는 볼륨. 실제 PostgreSQL 컨테이너에서 데이터 디렉토리를 볼륨으로 마운트하면 IOPS가 2-3배 향상됩니다."

**실무 예시**
```bash
# ❌ CoW 사용 (느림)
$ docker run -d --name db postgres
# → 큰 DB 파일 수정 시 Copy-up 발생, 매우 느림

# ✅ 볼륨 사용 (빠름)
$ docker volume create pgdata
$ docker run -d \
  --name db \
  -v pgdata:/var/lib/postgresql/data \
  postgres
# → 직접 쓰기, Copy-up 없음

# 개발 시 바인드 마운트
$ docker run -d \
  --name app \
  -v $(pwd)/src:/app/src \
  myapp
# → 호스트에서 코드 수정 시 즉시 반영
```

**꼬리 질문**
- Q: tmpfs는 언제 사용하나요?
- A: 임시 파일이나 캐시 데이터에 사용합니다. 메모리에 저장되어 매우 빠르지만 컨테이너 재시작 시 사라집니다. 예: `--tmpfs /tmp:rw,size=1g,mode=1777`

**실무 연관**
- 데이터베이스 컨테이너 성능 최적화
- 로그 수집 파이프라인 설계

</details>

<details>
<summary><strong>5. Docker 이미지 레이어의 보안 취약점 스캔 및 관리 전략을 설명하고, 공급망 보안(Supply Chain Security)을 강화하는 방법을 제시하세요.</strong></summary>

**모범 답안 포인트**
- 이미지 스캔 도구 (Trivy, Clair, Snyk)
- 베이스 이미지 선택 시 보안 고려 (공식 이미지, 최소 패키지)
- 이미지 서명 및 검증 (Docker Content Trust, Notary)
- 정기적인 베이스 이미지 업데이트
- SBOM(Software Bill of Materials) 생성

**예시 답변**
> "이미지 보안은 빌드, 스캔, 배포 단계에서 관리합니다. 1) 빌드 시: distroless나 alpine 같은 최소 베이스 이미지 사용으로 공격 표면 최소화. 멀티스테이지 빌드로 빌드 도구 제거. 2) 스캔: CI/CD 파이프라인에 Trivy 통합 (`trivy image myapp:latest --severity HIGH,CRITICAL --exit-code 1`)로 심각한 취약점 발견 시 빌드 실패. 3) 레지스트리: Harbor나 AWS ECR에서 자동 스캔 활성화. 4) 서명: Docker Content Trust 활성화(`export DOCKER_CONTENT_TRUST=1`)로 서명된 이미지만 pull 허용. 5) 관리: Renovate Bot으로 베이스 이미지 자동 업데이트 PR 생성. 실제 프로젝트에서 이 전략으로 CVE 수를 200개에서 5개로 줄였으며, 모든 취약점이 LOW 등급으로 유지됩니다."

**실무 예시**
```yaml
# CI/CD 파이프라인 (GitHub Actions)
- name: Build image
  run: docker build -t myapp:${{ github.sha }} .

- name: Scan image
  run: |
    trivy image \
      --severity HIGH,CRITICAL \
      --exit-code 1 \
      myapp:${{ github.sha }}

- name: Sign image
  run: |
    export DOCKER_CONTENT_TRUST=1
    docker push myapp:${{ github.sha }}

# Dockerfile 보안 강화
FROM gcr.io/distroless/nodejs18-debian11
COPY --from=builder /app /app
USER nonroot:nonroot
CMD ["/app/server.js"]
```

**꼬리 질문**
- Q: 레이어별로 취약점을 분리해서 볼 수 있나요?
- A: 네, Trivy는 `--format json`으로 레이어별 취약점 정보를 제공합니다. 이를 통해 어느 레이어에서 취약점이 발생했는지 추적하여 베이스 이미지 변경이나 패키지 업데이트를 결정할 수 있습니다.

**실무 연관**
- 규제 준수 (PCI-DSS, SOC2) 요구사항 충족
- 제로 트러스트 아키텍처 구현

</details>

---

## 🎉 축하합니다!

**이제 여러분은**:
✅ Docker 이미지의 레이어 구조와 작동 원리를 완벽히 이해했습니다
✅ Union File System (OverlayFS)의 메커니즘을 설명할 수 있습니다
✅ 이미지 크기를 90% 이상 최적화할 수 있습니다
✅ 빌드 캐시를 활용하여 빌드 시간을 수십 배 단축할 수 있습니다
✅ Copy-on-Write를 이해하고 적절한 저장소 전략을 선택할 수 있습니다
✅ 실무에서 발생하는 레이어 관련 문제를 해결할 수 있습니다
✅ 면접에서 레이어와 파일 시스템 질문에 자신 있게 답변할 수 있습니다

**다음 단계**:
- [ ] 다음 장 (격리 기술과 생명주기)으로 진행
- [ ] 실습 과제 완료하여 레이어 최적화 연습
- [ ] 면접 질문 복습하여 답변 준비
- [ ] 본인 프로젝트의 Dockerfile 최적화 적용

**실전 과제**:
```bash
# 1. 본인의 프로젝트에 .dockerignore 추가
# 2. 멀티스테이지 빌드 적용
# 3. 빌드 전후 이미지 크기 비교
$ docker images
BEFORE  myapp  1.2GB
AFTER   myapp  150MB  (87% 감소!)

# 4. 빌드 시간 측정
$ time docker build -t myapp .
BEFORE: 3m 20s
AFTER:  20s (캐시 활용 시)

# 5. GitHub에 최적화 결과 공유!
```

---

## ✅ 섹션 요약

### 핵심 개념 정리

```
📦 이미지 레이어:
   - Dockerfile 명령어 = 레이어
   - 읽기 전용, 불변
   - 레이어 재사용으로 공간 절약
   - 빌드 캐시 활용

🎨 Copy-on-Write:
   - 읽기: 원본에서 직접
   - 쓰기: 복사 후 수정
   - 원본 보호

🏗️ OverlayFS:
   - Upper (컨테이너, R/W)
   - Lower (이미지, R/O)
   - Merged (통합 뷰)
   - Whiteout (삭제 표시)
```

### 최적화 체크리스트

```
✅ Dockerfile 최적화:
- [ ] RUN 명령어 체이닝
- [ ] 파일 복사 순서 최적화
- [ ] .dockerignore 사용
- [ ] 멀티스테이지 빌드

✅ 런타임 최적화:
- [ ] 대용량 파일은 볼륨 사용
- [ ] 자주 수정되는 파일은 볼륨 사용
- [ ] 임시 파일은 tmpfs 사용
- [ ] 정기적인 정리 (prune)
```

### 다음 섹션 예고

```
섹션 2-3: 격리 기술과 생명주기
- 2.5 네임스페이스 (Namespace) - 프로세스 격리
- 2.6 컨트롤 그룹 (cgroups) - 리소스 제한
- 2.7 컨테이너 생명주기 - 상태 관리
```

### 실습 과제

```bash
# 1. 레이어 구조 확인
$ docker history nginx:latest
$ docker inspect nginx:latest

# 2. 레이어 캐싱 테스트
$ docker build -t test1 .
$ # 코드 한 줄 수정
$ docker build -t test2 .
$ # 캐시 사용 확인!

# 3. OverlayFS 구조 확인
$ docker run -d --name test nginx
$ docker inspect test | grep -A 10 GraphDriver

# 4. Copy-on-Write 테스트
$ docker exec test sh -c "echo 'modified' >> /etc/nginx/nginx.conf"
$ # UpperDir에서 변경 사항 확인

# 5. 정리
$ docker system df          # 공간 사용량 확인
$ docker system prune -a    # 정리

# 축하합니다! 레이어와 파일 시스템을 마스터했습니다! 🎉
```

---

**다음 섹션에서 만나요!** 👋